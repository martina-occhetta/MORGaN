{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # Use notebook-friendly tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# from src.explainability.gnn_explainer import GNNExplainer\n",
    "from main_transductive import pretrain\n",
    "from src.utils import set_random_seed, create_optimizer, WBLogger\n",
    "from src.datasets.data_util import load_dataset, load_processed_graph\n",
    "from src.models import build_model, PreModel\n",
    "from src.evaluation import node_classification_evaluation\n",
    "from src.utils import build_args, load_best_configs  # if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Config settings\n",
    "# ----------------------\n",
    "# Choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 0\n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hyperparameters\n",
    "dataset_name    = \"CPDB_cdgps\" \n",
    "max_epoch       = 100           # Total training epochs\n",
    "max_epoch_f     = 200           \n",
    "num_hidden      = 64\n",
    "num_layers      = 3\n",
    "encoder_type    = \"rgcn\"     \n",
    "decoder_type    = \"rgcn\"    \n",
    "replace_rate    = 0.05\n",
    "num_edge_types  = 6\n",
    "in_drop         = 0.2\n",
    "attn_drop       = 0.1\n",
    "mask_rate       = 0.5\n",
    "drop_edge_rate  = 0.0\n",
    "alpha_l         = 3\n",
    "num_heads       = 4\n",
    "activation      = \"prelu\"          \n",
    "optimizer       = \"adam\"            \n",
    "loss_fn         = \"sce\"      \n",
    "lr              = 0.01\n",
    "weight_decay    = 1e-3\n",
    "lr_f            = 0.005              \n",
    "weight_decay_f  = 1e-4\n",
    "linear_prob     = False\n",
    "load_model      = False              # Set True to load a checkpoint\n",
    "save_model      = True              # Set True to save trained model\n",
    "logs            = True              # Set True to use WBLogger\n",
    "use_scheduler   = True              # Set True to use a learning rate scheduler\n",
    "weight_decomposition = {'type': 'basis', 'num_bases': 2}\n",
    "vertical_stacking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Create a Namespace for Args\n",
    "# ----------------------\n",
    "\n",
    "args = Namespace(\n",
    "    device         = device,\n",
    "    seeds          = [seed],\n",
    "    dataset        = dataset_name,\n",
    "    max_epoch      = max_epoch,\n",
    "    max_epoch_f    = max_epoch_f,\n",
    "    num_hidden     = num_hidden,\n",
    "    num_layers     = num_layers,\n",
    "    encoder        = encoder_type,\n",
    "    decoder        = decoder_type,\n",
    "    activation     = activation,\n",
    "    in_drop        = in_drop,\n",
    "    attn_drop      = attn_drop,\n",
    "    mask_rate      = mask_rate,\n",
    "    drop_edge_rate = drop_edge_rate,\n",
    "    alpha_l        = alpha_l,\n",
    "    num_heads      = num_heads,\n",
    "    weight_decomposition = weight_decomposition,\n",
    "    vertical_stacking = vertical_stacking,\n",
    "    replace_rate   = replace_rate,\n",
    "    num_edge_types = num_edge_types,\n",
    "    optimizer      = optimizer,\n",
    "    loss_fn        = loss_fn,\n",
    "    lr             = lr,\n",
    "    weight_decay   = weight_decay,\n",
    "    lr_f           = lr_f,\n",
    "    weight_decay_f = weight_decay_f,\n",
    "    linear_prob    = linear_prob,\n",
    "    load_model     = load_model,\n",
    "    save_model     = save_model,\n",
    "    logging        = logs,\n",
    "    scheduler      = use_scheduler,\n",
    "    num_features   = 6, \n",
    "    num_out_heads  = 1,\n",
    "    residual = False,\n",
    "    norm = None,\n",
    "    negative_slope = 0.2,\n",
    "    concat_hidden = False,\n",
    "    #return_hidden = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreModel(\n",
       "  (encoder): RGCN(\n",
       "    (rgcn_layers): ModuleList(\n",
       "      (0-2): 3 x RGCNConv(64, 64)\n",
       "    )\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): RGCN(\n",
       "    (rgcn_layers): ModuleList(\n",
       "      (0): RGCNConv(64, 64)\n",
       "    )\n",
       "    (activation): PReLU(num_parameters=1)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (encoder_to_decoder): Linear(in_features=64, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Load Dataset and Build Model\n",
    "# ----------------------\n",
    "#graph, (num_features, num_classes) = load_dataset(dataset_name)\n",
    "graph = load_processed_graph(f'../data/real/multidim_graph/6d/{dataset_name}_multiomics.pt')\n",
    "num_features = graph.x.shape[1]\n",
    "num_classes = graph.y.max().item() + 1\n",
    "\n",
    "args.num_features = num_features  \n",
    "\n",
    "model = build_model(args)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../checkpoints/emb_extraction_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'num_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      9\u001b[39m explainer = Explainer(\n\u001b[32m     10\u001b[39m     model=model,\n\u001b[32m     11\u001b[39m     algorithm=GNNExplainer(epochs=\u001b[32m100\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     ),\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m node_index = \u001b[32m10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m explanation = \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/torch_geometric/explain/explainer.py:196\u001b[39m, in \u001b[36mExplainer.__call__\u001b[39m\u001b[34m(self, x, edge_index, target, index, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m         warnings.warn(\n\u001b[32m    194\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should not be provided for the explanation \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.explanation_type.value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     prediction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.get_target(prediction)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/torch_geometric/explain/explainer.py:115\u001b[39m, in \u001b[36mExplainer.get_prediction\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.model.eval()\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m.model.train(training)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/notebooks/../src/models/edcoder.py:240\u001b[39m, in \u001b[36mPreModel.forward\u001b[39m\u001b[34m(self, graph, x, num_edge_types)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, x, num_edge_types=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# ---- attribute reconstruction ----\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmask_attr_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_edge_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     loss_item = {\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: loss.item()}\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, loss_item\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/notebooks/../src/models/edcoder.py:245\u001b[39m, in \u001b[36mPreModel.mask_attr_prediction\u001b[39m\u001b[34m(self, graph, x, num_edge_types)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmask_attr_prediction\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, x, num_edge_types=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     pre_use_g, use_x, (mask_nodes, keep_nodes) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding_mask_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mask_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._drop_edge_rate > \u001b[32m0\u001b[39m:\n\u001b[32m    248\u001b[39m         use_g, masked_edges = drop_edge(pre_use_g, \u001b[38;5;28mself\u001b[39m._drop_edge_rate, return_edges = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/notebooks/../src/models/edcoder.py:208\u001b[39m, in \u001b[36mPreModel.encoding_mask_noise\u001b[39m\u001b[34m(self, graph, x, mask_rate)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencoding_mask_noise\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, x, mask_rate=\u001b[32m0.3\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     num_nodes = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_nodes\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m#num_nodes = x.shape[0]\u001b[39;00m\n\u001b[32m    210\u001b[39m     perm = torch.randperm(num_nodes, device=x.device)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'num_nodes'"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()  # set model to evaluation mode\n",
    "\n",
    "# Select the node(s) for which you want to explain the prediction.\n",
    "# For example, to explain prediction for a single node:\n",
    "target_node = 20  # replace with your desired node index\n",
    "\n",
    "# Alternatively, if you want to loop over a list of nodes:\n",
    "# target_nodes = [42, 105]\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=100),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "node_index = 10\n",
    "explanation = explainer(x=graph.x, edge_index=graph.edge_index, index=node_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
