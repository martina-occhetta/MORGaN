{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models\n",
    "\n",
    "Two models, with no graph structure\n",
    "1. Simple logistic regression. Following Otto's (?) suggestion. How does very simple model perform?\n",
    "\n",
    "ans: better than graph transformer. lol\n",
    "\n",
    "2. MLP classifier. Classifier model, no graph structure / network info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import h5py\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**SMG data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_graph(PATH, LABEL_PATH, ppi, seed=42):\n",
    "    f = h5py.File(f'{PATH}/{ppi}_multiomics.h5', 'r')\n",
    "    # Build edge indices from the network matrix\n",
    "    network = f['network'][:]\n",
    "    src, dst = np.nonzero(network)\n",
    "    edge_index = torch.tensor(np.vstack((src, dst)), dtype=torch.long)\n",
    "\n",
    "    # Load node features and assign a node \"name\" attribute if desired\n",
    "    features = f['features'][:]\n",
    "    x = torch.from_numpy(features)\n",
    "    num_nodes = x.size(0)\n",
    "    node_name = f['gene_names'][...,-1].astype(str)\n",
    "\n",
    "    # Retrieve gene names and create a mapping: gene name -> node index\n",
    "    gene_name = f['gene_names'][...,-1].astype(str)\n",
    "    gene_map = {g: i for i, g in enumerate(gene_name)}  # gene name -> node index\n",
    "\n",
    "    # Originally, the code combined several label arrays but then reads a health.tsv.\n",
    "    # Here we read the health.tsv file and extract the symbols.\n",
    "    # Ensure that PATH is defined in your environment.\n",
    "    label_df = pd.read_csv(LABEL_PATH, sep='\\t').astype(str) # TODO fix this for druggable gene prediction\n",
    "    label_symbols = label_df['symbol'].tolist()\n",
    "\n",
    "    # Determine positive nodes: indices that appear in both the health.tsv and gene_name list\n",
    "    mask = [gene_map[g] for g in sorted(list(set(label_symbols) & set(gene_name)))]\n",
    "\n",
    "    # Randomly select negative samples from those nodes not in the positive mask.\n",
    "    np.random.seed(seed)\n",
    "    all_indices = set(range(len(gene_name)))\n",
    "    negative_candidates = sorted(list(all_indices - set(mask)))\n",
    "    neg_sample_size = min(len(mask), len(gene_name) - len(mask))\n",
    "    neg_mask = np.random.choice(negative_candidates, size=neg_sample_size, replace=False).tolist()\n",
    "\n",
    "    print(\"Negative mask indices:\", neg_mask)\n",
    "\n",
    "    # Create a label vector (1 for positive, 0 for negative)\n",
    "    y = torch.zeros(len(gene_name), dtype=torch.float)\n",
    "    y[mask] = 1\n",
    "    y = y.unsqueeze(1)  # shape: [num_nodes, 1]\n",
    "\n",
    "    # Combine positive and negative indices for the split\n",
    "    final_mask = mask + neg_mask\n",
    "    final_labels = y[final_mask].squeeze(1).numpy()  # converting to numpy for stratification\n",
    "\n",
    "    # Split indices into train, test, and validation sets using stratification\n",
    "    train_idx, test_idx, _, _ = train_test_split(final_mask, final_labels, test_size=0.2,\n",
    "                                                    shuffle=True, stratify=final_labels, random_state=seed)\n",
    "    train_idx, val_idx, _, _ = train_test_split(train_idx, y[train_idx].numpy().squeeze(1),\n",
    "                                                test_size=0.2, shuffle=True,\n",
    "                                                stratify=y[train_idx].numpy().squeeze(1), random_state=seed)\n",
    "\n",
    "    # Create boolean masks for all nodes\n",
    "    train_mask = torch.zeros(len(gene_name), dtype=torch.bool)\n",
    "    test_mask = torch.zeros(len(gene_name), dtype=torch.bool)\n",
    "    val_mask = torch.zeros(len(gene_name), dtype=torch.bool)\n",
    "    train_mask[train_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "\n",
    "    # Add self-loops to the edge_index\n",
    "    edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "\n",
    "    # Build the PyTorch Geometric data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    data.train_mask = train_mask.unsqueeze(1)  # unsqueeze if you want to mimic the original shape\n",
    "    data.test_mask = test_mask.unsqueeze(1)\n",
    "    data.val_mask = val_mask.unsqueeze(1)\n",
    "    data.name = node_name  # optional: storing node names\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative mask indices: [8999, 13560, 10056, 5238, 4400, 10126, 7257, 9287, 1328, 10029, 3798, 1343, 4006, 10315, 12558, 6469, 8637, 6127, 3586, 785, 5161, 5253, 2224, 7950, 7645, 12498, 12624, 9395, 13098, 9368, 7476, 3001, 6913, 2409, 2090, 3433, 4462, 5038, 4739, 5096, 10199, 4624, 7788, 7438, 542, 10380, 4442, 3545, 4161, 3051, 10863, 11284, 11717, 3395, 12867, 7054, 8812, 12216, 6740, 1955, 5830, 7993, 6318, 11760, 6879, 13045, 7607, 2732, 501, 11409, 8966, 12040, 13196, 10590, 4523, 12691, 3070, 2058, 2204, 5668, 12618, 4245, 4588, 537, 387, 8507, 4056, 12163, 4326, 11298]\n",
      "Negative mask indices: [5243, 2450, 5909, 8874, 5635, 1343, 9229, 8495, 8700, 2673, 6224, 11148, 7952, 2444, 12904, 6947, 2322, 10057, 38, 9950, 1331, 4230, 881, 8834, 13602, 11429, 10796, 12282, 2504, 6762, 9169, 3298, 12296, 8425, 11250, 5144, 3068, 7362, 10595, 10015, 4886, 8878, 7636, 5285, 1828, 6509, 12316, 11240, 11162, 6636, 3643, 3846, 13532, 3633, 4301, 11960, 11194, 4740, 2250, 3970, 4268, 7221, 96, 6515, 7184, 11714, 12061, 1143, 691, 7796, 9600, 2996, 6769, 216, 4966, 1662, 10998, 6583, 343, 4144, 1359, 5412, 8245, 8824, 9890, 1184, 9994, 4291, 2476, 6378]\n",
      "Negative mask indices: [7948, 9045, 7132, 13499, 10268, 13360, 883, 6335, 9684, 666, 12611, 12444, 3875, 7701, 13076, 12541, 10269, 4467, 7785, 2814, 7807, 6748, 7723, 3896, 4667, 10460, 5956, 9971, 108, 13619, 7450, 7197, 11023, 3343, 1688, 4675, 2884, 7658, 1321, 756, 9943, 12985, 7668, 9477, 13133, 6465, 8189, 4198, 2209, 8288, 12125, 7021, 7126, 11507, 12671, 10326, 12661, 4036, 5459, 2749, 2219, 11019, 6701, 1625, 12852, 12540, 9085, 8778, 9535, 6418, 10398, 4111, 12775, 9627, 11799, 4287, 7856, 241, 7409, 4709, 766, 410, 13172, 878, 10698, 4662, 2358, 13618, 4274, 3289]\n",
      "Negative mask indices: [10724, 761, 15598, 2672, 2137, 15276, 10716, 5110, 15083, 16508, 3559, 7717, 6660, 8104, 15049, 279, 12791, 16863, 9801, 15386, 10376, 7736, 8318, 4177, 2850, 16292, 2011, 586, 15939, 16542, 12513, 3675, 9520, 14561, 10584, 10008, 10209, 16017, 2875, 155, 14474, 9561, 1103, 11400, 10197, 2018, 11507, 7341, 7087, 4156, 13235, 467, 14761, 9465, 12665, 12, 8, 11558, 13563, 15244, 13092, 3640, 6039, 14669, 11476, 4702, 16189, 6184, 6883, 496, 2116, 5200, 15796, 8398, 11291, 11210, 13657, 1252, 4356, 10735, 12440, 7224, 3788, 12648, 14796, 8186, 784, 9046, 5518, 16261, 143, 13851]\n",
      "Negative mask indices: [1343, 6400, 13418, 8985, 9923, 10230, 16381, 15981, 16913, 13078, 1317, 15835, 14025, 3544, 14407, 15789, 3876, 15046, 14716, 14334, 16706, 5480, 9206, 9561, 8145, 2557, 1233, 16745, 1377, 6645, 12414, 2836, 6042, 7010, 1306, 12158, 12344, 16575, 14199, 15150, 4326, 9329, 276, 234, 2526, 8793, 1585, 5081, 4187, 1130, 2404, 12180, 16280, 3655, 7447, 8236, 15839, 3215, 8991, 8210, 3134, 1649, 8695, 11413, 15371, 15938, 15376, 11111, 13278, 13706, 10036, 7796, 12075, 15912, 9579, 8049, 11491, 7767, 5903, 7106, 9408, 13964, 15258, 10209, 8645, 3020, 4414, 5176, 1778, 15423, 14658, 15080]\n",
      "Negative mask indices: [14192, 4980, 5409, 14133, 16124, 4274, 4789, 12364, 861, 2262, 7016, 6348, 12541, 5818, 8156, 1423, 6953, 12406, 3647, 6818, 13132, 9589, 11530, 142, 14605, 2421, 9094, 11841, 3673, 2851, 8928, 12974, 11334, 8178, 14115, 8173, 7156, 695, 12089, 13078, 13024, 1483, 16064, 11765, 10411, 2784, 8242, 5349, 10599, 15811, 2174, 1178, 8579, 16704, 8168, 16841, 9516, 2092, 2153, 3070, 13239, 11317, 6364, 4573, 5732, 6658, 15584, 8944, 6452, 7423, 10272, 10604, 9394, 7950, 2266, 14007, 7071, 13321, 6958, 4890, 16399, 4707, 5661, 9714, 1247, 3011, 496, 169, 70, 9005, 2904, 9091]\n",
      "Negative mask indices: [1106, 5923, 7396, 11155, 6766, 134, 5467, 1931, 2567, 7365, 10668, 7026, 5517, 8532, 10525, 11163, 2864, 10746, 6039, 5628, 6355, 7574, 6337, 11827, 7185, 1488, 11555, 11468, 10914, 584, 1978, 5276, 2710, 6659, 8467, 7212, 8242, 18, 5349, 7101, 1841, 5625, 6344, 5382, 6034, 6105, 9381, 884, 4427, 9919, 12095, 10596, 1155, 4447, 4432, 3074, 6962, 3390, 10438, 12001, 3865, 3719, 8325, 3514, 11124, 10814, 3064, 8285, 3512, 1547, 6059, 632, 7017, 2284, 3918, 1003, 2534, 1767, 5612, 10081, 8344, 5249, 2851, 4079]\n",
      "Negative mask indices: [10217, 1177, 2645, 6971, 8002, 9990, 6574, 6050, 7844, 35, 483, 3969, 10896, 10406, 7821, 9598, 6204, 1305, 6681, 7300, 7915, 1300, 302, 826, 11959, 11782, 5295, 1309, 398, 9453, 5547, 10323, 17, 11264, 1265, 3358, 482, 8613, 2413, 5666, 5835, 432, 354, 8873, 9674, 12091, 8965, 2860, 6593, 8175, 2573, 10540, 2467, 822, 1559, 10405, 10877, 4843, 7696, 3361, 7572, 4321, 11014, 7089, 2731, 5748, 8789, 9188, 3740, 758, 3451, 5269, 6254, 10982, 6276, 8894, 7119, 9429, 4662, 5933, 135, 1823, 1086, 829]\n",
      "Negative mask indices: [9811, 1256, 3632, 9267, 4102, 3298, 4439, 175, 5483, 9922, 6103, 1041, 6714, 6422, 2977, 9304, 3406, 4418, 1641, 10040, 4400, 10344, 10581, 4282, 12039, 10949, 11396, 9657, 10295, 6292, 1437, 4202, 10761, 8307, 6820, 3052, 407, 11194, 3726, 8212, 5057, 6512, 10120, 3861, 757, 1043, 1951, 8361, 3022, 10288, 8232, 11531, 8478, 8525, 4606, 8767, 7273, 935, 1214, 5239, 2879, 11563, 9150, 3671, 6356, 1717, 10119, 9594, 12083, 2648, 32, 8083, 9962, 7946, 11097, 6425, 9896, 4813, 9379, 1765, 12071, 4383, 9441, 9910]\n",
      "Negative mask indices: [14498, 4890, 3988, 14778, 7788, 469, 7500, 14193, 262, 75, 5594, 9144, 18252, 10496, 13225, 3346, 5333, 17053, 3226, 1662, 8656, 16325, 2396, 11396, 11493, 2445, 4302, 11247, 10517, 17393, 7723, 17890, 6239, 3012, 3309, 7813, 6015, 9671, 313, 15306, 17063, 33, 4944, 584, 4386, 6605, 5203, 1359, 15234, 818, 10769, 10897, 4073, 2541, 5055, 18982, 17159, 17484, 9354, 15473, 1493, 5929, 10268, 17958, 5654, 3209, 14673, 10469, 17367, 6107, 7734, 11841, 7707, 18352, 7540, 8242, 9072, 10040, 18614, 14241, 19032, 16288, 18127, 8462, 5334, 5383, 19123, 12842, 9744, 1455, 17321, 8607, 4080, 9672, 7828]\n",
      "Negative mask indices: [12052, 829, 5513, 1599, 5138, 12743, 5065, 18146, 5049, 9840, 4554, 2429, 10813, 9484, 11813, 5296, 10308, 2808, 6245, 17295, 19122, 875, 14658, 17510, 10733, 17313, 73, 6479, 1625, 629, 14150, 12188, 12035, 1266, 7499, 11742, 9490, 11945, 18486, 574, 11768, 5559, 5525, 15774, 15352, 6324, 18667, 13600, 6950, 15285, 11080, 13347, 12446, 7526, 11039, 19599, 4, 2163, 6702, 1354, 171, 9832, 8398, 15979, 11952, 4177, 1064, 7478, 204, 16229, 11480, 18259, 879, 16702, 13732, 4953, 14076, 14868, 12300, 1376, 18494, 9794, 10776, 8793, 3394, 10720, 1543, 10630, 15706, 3422, 10298, 18278, 9028, 15514, 10655]\n",
      "Negative mask indices: [918, 9397, 12536, 8830, 3978, 6354, 811, 17362, 5905, 821, 8340, 6060, 5406, 5499, 16282, 3780, 13596, 128, 2936, 11225, 5543, 2537, 3142, 19362, 12265, 14773, 9090, 12928, 2310, 4304, 853, 12514, 12696, 7715, 1384, 5742, 12009, 1821, 11328, 3962, 3579, 11149, 12649, 6228, 1081, 18322, 13653, 18972, 16541, 9086, 5699, 5757, 8632, 494, 5583, 9651, 6580, 17489, 10674, 11366, 3413, 13749, 9344, 13262, 1817, 11014, 11897, 8977, 8916, 14334, 5225, 7610, 5587, 2987, 16535, 14362, 13574, 9695, 11005, 9456, 7671, 4787, 18210, 6686, 238, 12306, 12492, 13593, 3324, 2247, 3865, 795, 14411, 12721, 2729]\n",
      "Negative mask indices: [5460, 7979, 9000, 4069, 7529, 7768, 3708, 5239, 4250, 7643, 3569, 1223, 12848, 7055, 9002, 2615, 4443, 11043, 3647, 8051, 8898, 10805, 5086, 3923, 11256, 5063, 3406, 3401, 9191, 8377, 5873, 3125, 1381, 3509, 12429, 6570, 12558, 10130, 533, 498, 12665, 9097, 7591, 317, 506, 5343, 135, 5874, 7488, 6437, 464, 6734, 10081, 1589, 5156, 5880, 2323, 3301, 7531, 3280, 5793, 7698, 3958, 8635, 11085, 5267, 11861, 4836, 12546, 1158, 4683, 2808, 12289, 2284, 2953, 3206, 7147, 866, 9061, 4076, 13067, 6496, 2644, 9116, 6265, 11749, 3228]\n",
      "Negative mask indices: [1838, 3716, 9957, 342, 144, 8937, 9701, 5790, 7964, 8421, 8792, 10239, 235, 3142, 1567, 1994, 2118, 3309, 1929, 7367, 8278, 868, 7528, 6412, 8009, 6387, 752, 5290, 5134, 8887, 8978, 226, 9522, 10624, 3497, 3498, 12167, 4764, 8975, 8531, 3664, 4188, 4697, 485, 5281, 6227, 12591, 1219, 12844, 10249, 7944, 6080, 491, 403, 12322, 1189, 4274, 6866, 4906, 6339, 1817, 9631, 10647, 11716, 5751, 11897, 4499, 6894, 8598, 1092, 12913, 9850, 5870, 12887, 9463, 583, 4701, 2608, 1265, 3739, 12025, 4564, 6181, 11198, 4273, 8534, 2619]\n",
      "Negative mask indices: [1127, 1726, 7910, 2634, 7641, 12782, 2911, 5779, 493, 11112, 10014, 5850, 4815, 4200, 647, 739, 7817, 9322, 3355, 5009, 11988, 10226, 5924, 10428, 996, 2933, 12214, 7511, 2593, 2772, 10251, 3324, 10311, 2702, 3426, 6295, 2450, 10592, 6701, 766, 345, 1221, 9764, 4764, 10218, 10655, 4796, 13117, 7565, 8882, 386, 7702, 10399, 13153, 12245, 10474, 10244, 4328, 2973, 12416, 1577, 3104, 12586, 11002, 5725, 11412, 3325, 7414, 3438, 4363, 7759, 7881, 2606, 11712, 409, 8613, 8691, 3952, 10497, 33, 9106, 2184, 9125, 889, 7220, 11909, 6786]\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/real/smg_data/'\n",
    "LABEL_PATH = '../data/real/smg_data/health.tsv'\n",
    "ppis = ['CPDB', 'IRefIndex', 'IRefIndex_2015', 'PCNet', 'STRINGdb']#'Multinet',\n",
    "\n",
    "data = {}\n",
    "seeds = [0,1,2]\n",
    "\n",
    "for ppi in ppis:\n",
    "    for seed in seeds:\n",
    "        data[ppi, seed] = load_h5_graph(PATH, LABEL_PATH, ppi, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CPDB',\n",
       "  0): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('CPDB',\n",
       "  1): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('CPDB',\n",
       "  2): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('IRefIndex',\n",
       "  0): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex',\n",
       "  1): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex',\n",
       "  2): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex_2015',\n",
       "  0): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('IRefIndex_2015',\n",
       "  1): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('IRefIndex_2015',\n",
       "  2): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('PCNet',\n",
       "  0): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('PCNet',\n",
       "  1): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('PCNet',\n",
       "  2): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('STRINGdb',\n",
       "  0): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179]),\n",
       " ('STRINGdb',\n",
       "  1): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179]),\n",
       " ('STRINGdb',\n",
       "  2): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, clf.predict(X_test)) * 100\n",
    "        # Get predictions and predicted probabilities for the positive class\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    aupr = average_precision_score(y_test, y_prob)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"F1 score: {f1:.4f}\")\n",
    "    \n",
    "    print(f\"Logistic regression model accuracy: {acc:.2f}%\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"AUPR: {aupr:.4f}\")\n",
    "    \n",
    "    return acc, auc, aupr, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPDB data\n",
      "F1 score: 0.7097\n",
      "Logistic regression model accuracy: 75.00%\n",
      "AUC: 0.7284\n",
      "AUPR: 0.8129\n",
      "Training on CPDB data\n",
      "F1 score: 0.4828\n",
      "Logistic regression model accuracy: 58.33%\n",
      "AUC: 0.7130\n",
      "AUPR: 0.7160\n",
      "Training on CPDB data\n",
      "F1 score: 0.5405\n",
      "Logistic regression model accuracy: 52.78%\n",
      "AUC: 0.6049\n",
      "AUPR: 0.7182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bty416/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/bty416/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/bty416/Library/CloudStorage/OneDrive-QueenMary,UniversityofLondon/martina/01_PhD/05_Projects/04_Druggable-genes/SMG-DG/.dg_env/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "log_reg_results = {}\n",
    "\n",
    "\n",
    "for ppi in ['CPDB']:\n",
    "    for seed in [0,1,2]:\n",
    "        mask_train = data[ppi,seed].train_mask.squeeze()  \n",
    "        mask_test = data[ppi,seed].test_mask.squeeze()\n",
    "\n",
    "        X_train = data[ppi,seed].x[mask_train].numpy()  \n",
    "        y_train = data[ppi,seed].y[mask_train].numpy()\n",
    "        X_test = data[ppi,seed].x[mask_test].numpy()  \n",
    "        y_test = data[ppi,seed].y[mask_test].numpy()\n",
    "\n",
    "        print(f\"Training on {ppi} data\")\n",
    "        \n",
    "        log_reg_results[ppi,seed] = log_reg(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CPDB', 0): (75.0,\n",
       "  np.float64(0.7283950617283951),\n",
       "  np.float64(0.8128956046413354),\n",
       "  np.float64(0.7096774193548387)),\n",
       " ('CPDB', 1): (58.333333333333336,\n",
       "  np.float64(0.712962962962963),\n",
       "  np.float64(0.7160144957997348),\n",
       "  np.float64(0.4827586206896552)),\n",
       " ('CPDB', 2): (52.77777777777778,\n",
       "  np.float64(0.6049382716049383),\n",
       "  np.float64(0.7181861391971391),\n",
       "  np.float64(0.5405405405405406))}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 62.04%\n",
      "Standard Deviation Accuracy: 9.44\n",
      "Mean AUC: 0.6821\n",
      "Standard Deviation AUC: 0.0549\n",
      "Mean AUPR: 0.7490\n",
      "Standard Deviation AUPR: 0.0452\n",
      "Mean F1: 0.5777\n",
      "Standard Deviation F1: 0.0963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract metric values\n",
    "accuracies = [val[0] for val in log_reg_results.values()]\n",
    "aucs = [val[1] for val in log_reg_results.values()]\n",
    "auprs = [val[2] for val in log_reg_results.values()]\n",
    "f1s = [val[3] for val in log_reg_results.values()]\n",
    "# Calculate means\n",
    "mean_acc = np.mean(accuracies)\n",
    "mean_auc = np.mean(aucs)\n",
    "mean_aupr = np.mean(auprs)\n",
    "mean_f1 = np.mean(f1s)\n",
    "# Calculate standard deviations\n",
    "std_acc = np.std(accuracies)\n",
    "std_auc = np.std(aucs)\n",
    "std_aupr = np.std(auprs)\n",
    "std_f1 = np.std(f1s)\n",
    "print(f\"Mean Accuracy: {mean_acc:.2f}%\")\n",
    "print(f\"Standard Deviation Accuracy: {std_acc:.2f}\")\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")\n",
    "print(f\"Standard Deviation AUC: {std_auc:.4f}\")\n",
    "print(f\"Mean AUPR: {mean_aupr:.4f}\")\n",
    "print(f\"Standard Deviation AUPR: {std_aupr:.4f}\")\n",
    "print(f\"Mean F1: {mean_f1:.4f}\")\n",
    "print(f\"Standard Deviation F1: {std_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_cv(X_train, y_train, X_test=None, y_test=None, cv=10):\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    print(f\"Logistic Regression CV Mean Accuracy: {scores.mean()*100:.2f}% (±{scores.std()*100:.2f}%)\")\n",
    "    print(f\"Logistic Regression CV Median Accuracy: {np.median(scores)*100:.2f}% (±{scores.std()*100:.2f}%)\")\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CPDB data with CV\n",
      "Logistic Regression CV Mean Accuracy: 70.30% (±12.89%)\n",
      "Logistic Regression CV Median Accuracy: 72.73% (±12.89%)\n",
      "Evaluating IRefIndex data with CV\n",
      "Logistic Regression CV Mean Accuracy: 75.91% (±10.95%)\n",
      "Logistic Regression CV Median Accuracy: 74.24% (±10.95%)\n",
      "Evaluating IRefIndex_2015 data with CV\n",
      "Logistic Regression CV Mean Accuracy: 69.00% (±12.64%)\n",
      "Logistic Regression CV Median Accuracy: 66.82% (±12.64%)\n",
      "Evaluating PCNet data with CV\n",
      "Logistic Regression CV Mean Accuracy: 72.05% (±9.20%)\n",
      "Logistic Regression CV Median Accuracy: 75.00% (±9.20%)\n",
      "Evaluating STRINGdb data with CV\n",
      "Logistic Regression CV Mean Accuracy: 71.89% (±10.47%)\n",
      "Logistic Regression CV Median Accuracy: 72.73% (±10.47%)\n"
     ]
    }
   ],
   "source": [
    "log_reg_cv_results = {}\n",
    "for ppi in ppis:\n",
    "    mask_train = data[ppi,42].train_mask.squeeze()  \n",
    "    mask_test = data[ppi,42].test_mask.squeeze()\n",
    "\n",
    "    X_train = data[ppi,42].x[mask_train].numpy()  \n",
    "    y_train = data[ppi,42].y[mask_train].numpy().ravel()\n",
    "    # X_test = data[ppi].x[mask_test].numpy()  \n",
    "    # y_test = data[ppi].y[mask_test].numpy()\n",
    "    print(f\"Evaluating {ppi} data with CV\")\n",
    "    log_reg_cv_results[ppi,42] = log_reg_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_grid_search(X, y):\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"Best params:\", grid_search.best_params_)\n",
    "    print(f\"Best CV Accuracy: {grid_search.best_score_*100:.2f}%\")\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search on CPDB data\n",
      "Best params: {'C': 0.1}\n",
      "Best CV Accuracy: 71.14%\n",
      "Grid search on IRefIndex data\n",
      "Best params: {'C': 10}\n",
      "Best CV Accuracy: 78.48%\n",
      "Grid search on IRefIndex_2015 data\n",
      "Best params: {'C': 1}\n",
      "Best CV Accuracy: 69.00%\n",
      "Grid search on PCNet data\n",
      "Best params: {'C': 1}\n",
      "Best CV Accuracy: 72.05%\n",
      "Grid search on STRINGdb data\n",
      "Best params: {'C': 10}\n",
      "Best CV Accuracy: 76.44%\n"
     ]
    }
   ],
   "source": [
    "log_reg_grid_results = {}\n",
    "for ppi in ppis:\n",
    "    mask_train = data[ppi,42].train_mask.squeeze()  \n",
    "    mask_test = data[ppi,42].test_mask.squeeze()\n",
    "\n",
    "    X_train = data[ppi,42].x[mask_train].numpy()  \n",
    "    y_train = data[ppi,42].y[mask_train].numpy().ravel()\n",
    "    print(f\"Grid search on {ppi} data\")\n",
    "    log_reg_grid_results[ppi,42] = log_reg_grid_search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, X_test, y_train, y_test, lr=0.001, decay = 5e-4, hidden_size=64, n_epochs = 100):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "    model = MLP(X_train.shape[1], hidden_size, 2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        acc = accuracy_score(y_train, predictions)\n",
    "        auroc = roc_auc_score(y_train, predictions)\n",
    "        aupr = average_precision_score(y_train, predictions)\n",
    "        f1 = f1_score(y_train, predictions)\n",
    "        print(f\"Epoch {epoch} - Loss: {loss.item()} - Accuracy: {acc:.3f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_acc = accuracy_score(y_test, predicted)\n",
    "        test_auroc = roc_auc_score(y_test, predicted)\n",
    "        test_aupr = average_precision_score(y_test, predicted)\n",
    "        test_f1 = f1_score(y_test, predicted)\n",
    "        print(f\"MLP model test accuracy: {acc:.3f}\")\n",
    "\n",
    "    return model, test_acc, test_auroc, test_aupr, test_f1, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.6946852803230286 - Accuracy: 0.496\n",
      "Epoch 1 - Loss: 0.6918052434921265 - Accuracy: 0.522\n",
      "Epoch 2 - Loss: 0.69182950258255 - Accuracy: 0.513\n",
      "Epoch 3 - Loss: 0.6921141743659973 - Accuracy: 0.487\n",
      "Epoch 4 - Loss: 0.6898582577705383 - Accuracy: 0.530\n",
      "Epoch 5 - Loss: 0.6902645826339722 - Accuracy: 0.539\n",
      "Epoch 6 - Loss: 0.6883981227874756 - Accuracy: 0.557\n",
      "Epoch 7 - Loss: 0.689025342464447 - Accuracy: 0.609\n",
      "Epoch 8 - Loss: 0.6899604201316833 - Accuracy: 0.548\n",
      "Epoch 9 - Loss: 0.6855391263961792 - Accuracy: 0.635\n",
      "Epoch 10 - Loss: 0.6856611967086792 - Accuracy: 0.626\n",
      "Epoch 11 - Loss: 0.6859285831451416 - Accuracy: 0.635\n",
      "Epoch 12 - Loss: 0.6857849955558777 - Accuracy: 0.565\n",
      "Epoch 13 - Loss: 0.6809494495391846 - Accuracy: 0.635\n",
      "Epoch 14 - Loss: 0.6795617341995239 - Accuracy: 0.600\n",
      "Epoch 15 - Loss: 0.6832281947135925 - Accuracy: 0.557\n",
      "Epoch 16 - Loss: 0.6820057034492493 - Accuracy: 0.600\n",
      "Epoch 17 - Loss: 0.6807754039764404 - Accuracy: 0.652\n",
      "Epoch 18 - Loss: 0.6772734522819519 - Accuracy: 0.626\n",
      "Epoch 19 - Loss: 0.6741604208946228 - Accuracy: 0.626\n",
      "Epoch 20 - Loss: 0.6719741821289062 - Accuracy: 0.661\n",
      "Epoch 21 - Loss: 0.6731067299842834 - Accuracy: 0.609\n",
      "Epoch 22 - Loss: 0.6688441634178162 - Accuracy: 0.635\n",
      "Epoch 23 - Loss: 0.6669721007347107 - Accuracy: 0.661\n",
      "Epoch 24 - Loss: 0.6631825566291809 - Accuracy: 0.696\n",
      "Epoch 25 - Loss: 0.663948118686676 - Accuracy: 0.652\n",
      "Epoch 26 - Loss: 0.6607514023780823 - Accuracy: 0.617\n",
      "Epoch 27 - Loss: 0.6561729311943054 - Accuracy: 0.687\n",
      "Epoch 28 - Loss: 0.6542404294013977 - Accuracy: 0.678\n",
      "Epoch 29 - Loss: 0.6605633497238159 - Accuracy: 0.652\n",
      "Epoch 30 - Loss: 0.649105966091156 - Accuracy: 0.704\n",
      "Epoch 31 - Loss: 0.6528383493423462 - Accuracy: 0.661\n",
      "Epoch 32 - Loss: 0.6470679640769958 - Accuracy: 0.696\n",
      "Epoch 33 - Loss: 0.6475945115089417 - Accuracy: 0.687\n",
      "Epoch 34 - Loss: 0.6405693888664246 - Accuracy: 0.704\n",
      "Epoch 35 - Loss: 0.6438353061676025 - Accuracy: 0.704\n",
      "Epoch 36 - Loss: 0.6244893074035645 - Accuracy: 0.739\n",
      "Epoch 37 - Loss: 0.6260238885879517 - Accuracy: 0.748\n",
      "Epoch 38 - Loss: 0.6338407397270203 - Accuracy: 0.730\n",
      "Epoch 39 - Loss: 0.6215000748634338 - Accuracy: 0.722\n",
      "Epoch 40 - Loss: 0.6238619089126587 - Accuracy: 0.696\n",
      "Epoch 41 - Loss: 0.6212399005889893 - Accuracy: 0.730\n",
      "Epoch 42 - Loss: 0.613185465335846 - Accuracy: 0.748\n",
      "Epoch 43 - Loss: 0.6066794991493225 - Accuracy: 0.757\n",
      "Epoch 44 - Loss: 0.6001133918762207 - Accuracy: 0.765\n",
      "Epoch 45 - Loss: 0.5993019342422485 - Accuracy: 0.774\n",
      "Epoch 46 - Loss: 0.5957149863243103 - Accuracy: 0.748\n",
      "Epoch 47 - Loss: 0.5784120559692383 - Accuracy: 0.809\n",
      "Epoch 48 - Loss: 0.5829018354415894 - Accuracy: 0.791\n",
      "Epoch 49 - Loss: 0.5772334933280945 - Accuracy: 0.783\n",
      "Epoch 50 - Loss: 0.5732300877571106 - Accuracy: 0.757\n",
      "Epoch 51 - Loss: 0.5652003884315491 - Accuracy: 0.800\n",
      "Epoch 52 - Loss: 0.5626257061958313 - Accuracy: 0.800\n",
      "Epoch 53 - Loss: 0.5513216257095337 - Accuracy: 0.817\n",
      "Epoch 54 - Loss: 0.5440357327461243 - Accuracy: 0.817\n",
      "Epoch 55 - Loss: 0.5401718020439148 - Accuracy: 0.791\n",
      "Epoch 56 - Loss: 0.5342045426368713 - Accuracy: 0.809\n",
      "Epoch 57 - Loss: 0.5175443887710571 - Accuracy: 0.835\n",
      "Epoch 58 - Loss: 0.5145218968391418 - Accuracy: 0.826\n",
      "Epoch 59 - Loss: 0.5144176483154297 - Accuracy: 0.843\n",
      "Epoch 60 - Loss: 0.5081542730331421 - Accuracy: 0.826\n",
      "Epoch 61 - Loss: 0.48910078406333923 - Accuracy: 0.852\n",
      "Epoch 62 - Loss: 0.4983130395412445 - Accuracy: 0.835\n",
      "Epoch 63 - Loss: 0.4905618727207184 - Accuracy: 0.817\n",
      "Epoch 64 - Loss: 0.4782077372074127 - Accuracy: 0.826\n",
      "Epoch 65 - Loss: 0.47328484058380127 - Accuracy: 0.826\n",
      "Epoch 66 - Loss: 0.4720306098461151 - Accuracy: 0.835\n",
      "Epoch 67 - Loss: 0.4537827670574188 - Accuracy: 0.852\n",
      "Epoch 68 - Loss: 0.439843088388443 - Accuracy: 0.852\n",
      "Epoch 69 - Loss: 0.4590533673763275 - Accuracy: 0.835\n",
      "Epoch 70 - Loss: 0.4225288927555084 - Accuracy: 0.861\n",
      "Epoch 71 - Loss: 0.44626444578170776 - Accuracy: 0.852\n",
      "Epoch 72 - Loss: 0.4272972047328949 - Accuracy: 0.852\n",
      "Epoch 73 - Loss: 0.4209662973880768 - Accuracy: 0.861\n",
      "Epoch 74 - Loss: 0.42083269357681274 - Accuracy: 0.852\n",
      "Epoch 75 - Loss: 0.4152536690235138 - Accuracy: 0.843\n",
      "Epoch 76 - Loss: 0.4034680128097534 - Accuracy: 0.835\n",
      "Epoch 77 - Loss: 0.3864745795726776 - Accuracy: 0.852\n",
      "Epoch 78 - Loss: 0.3610469400882721 - Accuracy: 0.904\n",
      "Epoch 79 - Loss: 0.39439547061920166 - Accuracy: 0.835\n",
      "Epoch 80 - Loss: 0.3818623721599579 - Accuracy: 0.843\n",
      "Epoch 81 - Loss: 0.3796613812446594 - Accuracy: 0.861\n",
      "Epoch 82 - Loss: 0.38094279170036316 - Accuracy: 0.835\n",
      "Epoch 83 - Loss: 0.3653000593185425 - Accuracy: 0.878\n",
      "Epoch 84 - Loss: 0.36066973209381104 - Accuracy: 0.870\n",
      "Epoch 85 - Loss: 0.3762979209423065 - Accuracy: 0.904\n",
      "Epoch 86 - Loss: 0.3619665205478668 - Accuracy: 0.852\n",
      "Epoch 87 - Loss: 0.3211011588573456 - Accuracy: 0.913\n",
      "Epoch 88 - Loss: 0.34344810247421265 - Accuracy: 0.913\n",
      "Epoch 89 - Loss: 0.3414642810821533 - Accuracy: 0.852\n",
      "Epoch 90 - Loss: 0.3162119388580322 - Accuracy: 0.896\n",
      "Epoch 91 - Loss: 0.3097430467605591 - Accuracy: 0.896\n",
      "Epoch 92 - Loss: 0.29676851630210876 - Accuracy: 0.896\n",
      "Epoch 93 - Loss: 0.28744980692863464 - Accuracy: 0.922\n",
      "Epoch 94 - Loss: 0.29503849148750305 - Accuracy: 0.913\n",
      "Epoch 95 - Loss: 0.2951238453388214 - Accuracy: 0.887\n",
      "Epoch 96 - Loss: 0.2925109267234802 - Accuracy: 0.887\n",
      "Epoch 97 - Loss: 0.28675782680511475 - Accuracy: 0.896\n",
      "Epoch 98 - Loss: 0.30971676111221313 - Accuracy: 0.878\n",
      "Epoch 99 - Loss: 0.25098106265068054 - Accuracy: 0.922\n",
      "MLP model test accuracy: 0.922\n",
      "Epoch 0 - Loss: 0.6906114220619202 - Accuracy: 0.556\n",
      "Epoch 1 - Loss: 0.6930840015411377 - Accuracy: 0.479\n",
      "Epoch 2 - Loss: 0.6929111480712891 - Accuracy: 0.513\n",
      "Epoch 3 - Loss: 0.6896114945411682 - Accuracy: 0.564\n",
      "Epoch 4 - Loss: 0.6891860961914062 - Accuracy: 0.590\n",
      "Epoch 5 - Loss: 0.6918195486068726 - Accuracy: 0.479\n",
      "Epoch 6 - Loss: 0.6852039694786072 - Accuracy: 0.632\n",
      "Epoch 7 - Loss: 0.6860483884811401 - Accuracy: 0.598\n",
      "Epoch 8 - Loss: 0.6807225942611694 - Accuracy: 0.658\n",
      "Epoch 9 - Loss: 0.6850500106811523 - Accuracy: 0.590\n",
      "Epoch 10 - Loss: 0.6821635365486145 - Accuracy: 0.650\n",
      "Epoch 11 - Loss: 0.6796469688415527 - Accuracy: 0.624\n",
      "Epoch 12 - Loss: 0.6792798042297363 - Accuracy: 0.658\n",
      "Epoch 13 - Loss: 0.6765934824943542 - Accuracy: 0.650\n",
      "Epoch 14 - Loss: 0.6795916557312012 - Accuracy: 0.573\n",
      "Epoch 15 - Loss: 0.6732435822486877 - Accuracy: 0.675\n",
      "Epoch 16 - Loss: 0.6701838374137878 - Accuracy: 0.709\n",
      "Epoch 17 - Loss: 0.669975757598877 - Accuracy: 0.650\n",
      "Epoch 18 - Loss: 0.6692600250244141 - Accuracy: 0.692\n",
      "Epoch 19 - Loss: 0.665566623210907 - Accuracy: 0.624\n",
      "Epoch 20 - Loss: 0.663701057434082 - Accuracy: 0.684\n",
      "Epoch 21 - Loss: 0.6620579361915588 - Accuracy: 0.667\n",
      "Epoch 22 - Loss: 0.6649276614189148 - Accuracy: 0.632\n",
      "Epoch 23 - Loss: 0.6538182497024536 - Accuracy: 0.769\n",
      "Epoch 24 - Loss: 0.6539727449417114 - Accuracy: 0.726\n",
      "Epoch 25 - Loss: 0.6503447890281677 - Accuracy: 0.735\n",
      "Epoch 26 - Loss: 0.6448206901550293 - Accuracy: 0.709\n",
      "Epoch 27 - Loss: 0.646671712398529 - Accuracy: 0.744\n",
      "Epoch 28 - Loss: 0.6402472853660583 - Accuracy: 0.744\n",
      "Epoch 29 - Loss: 0.6373209953308105 - Accuracy: 0.769\n",
      "Epoch 30 - Loss: 0.6349279880523682 - Accuracy: 0.761\n",
      "Epoch 31 - Loss: 0.625769853591919 - Accuracy: 0.752\n",
      "Epoch 32 - Loss: 0.6282448172569275 - Accuracy: 0.709\n",
      "Epoch 33 - Loss: 0.6267910003662109 - Accuracy: 0.752\n",
      "Epoch 34 - Loss: 0.6195138692855835 - Accuracy: 0.744\n",
      "Epoch 35 - Loss: 0.6145222783088684 - Accuracy: 0.761\n",
      "Epoch 36 - Loss: 0.6111088991165161 - Accuracy: 0.812\n",
      "Epoch 37 - Loss: 0.602656900882721 - Accuracy: 0.778\n",
      "Epoch 38 - Loss: 0.597935676574707 - Accuracy: 0.795\n",
      "Epoch 39 - Loss: 0.5930231213569641 - Accuracy: 0.769\n",
      "Epoch 40 - Loss: 0.5880668759346008 - Accuracy: 0.803\n",
      "Epoch 41 - Loss: 0.5837181210517883 - Accuracy: 0.761\n",
      "Epoch 42 - Loss: 0.585387647151947 - Accuracy: 0.778\n",
      "Epoch 43 - Loss: 0.5812268257141113 - Accuracy: 0.786\n",
      "Epoch 44 - Loss: 0.5648199915885925 - Accuracy: 0.803\n",
      "Epoch 45 - Loss: 0.556168794631958 - Accuracy: 0.761\n",
      "Epoch 46 - Loss: 0.5485432147979736 - Accuracy: 0.838\n",
      "Epoch 47 - Loss: 0.5537887811660767 - Accuracy: 0.778\n",
      "Epoch 48 - Loss: 0.5412534475326538 - Accuracy: 0.803\n",
      "Epoch 49 - Loss: 0.5422471761703491 - Accuracy: 0.803\n",
      "Epoch 50 - Loss: 0.5309523940086365 - Accuracy: 0.786\n",
      "Epoch 51 - Loss: 0.5309796333312988 - Accuracy: 0.829\n",
      "Epoch 52 - Loss: 0.5272330045700073 - Accuracy: 0.786\n",
      "Epoch 53 - Loss: 0.511078417301178 - Accuracy: 0.778\n",
      "Epoch 54 - Loss: 0.5164320468902588 - Accuracy: 0.803\n",
      "Epoch 55 - Loss: 0.49109336733818054 - Accuracy: 0.855\n",
      "Epoch 56 - Loss: 0.49615681171417236 - Accuracy: 0.795\n",
      "Epoch 57 - Loss: 0.49861860275268555 - Accuracy: 0.803\n",
      "Epoch 58 - Loss: 0.4787982404232025 - Accuracy: 0.812\n",
      "Epoch 59 - Loss: 0.48462221026420593 - Accuracy: 0.821\n",
      "Epoch 60 - Loss: 0.47672799229621887 - Accuracy: 0.812\n",
      "Epoch 61 - Loss: 0.4551858901977539 - Accuracy: 0.838\n",
      "Epoch 62 - Loss: 0.46037155389785767 - Accuracy: 0.855\n",
      "Epoch 63 - Loss: 0.44661810994148254 - Accuracy: 0.855\n",
      "Epoch 64 - Loss: 0.4467361569404602 - Accuracy: 0.846\n",
      "Epoch 65 - Loss: 0.4355238974094391 - Accuracy: 0.846\n",
      "Epoch 66 - Loss: 0.43207794427871704 - Accuracy: 0.812\n",
      "Epoch 67 - Loss: 0.42111265659332275 - Accuracy: 0.846\n",
      "Epoch 68 - Loss: 0.4409261643886566 - Accuracy: 0.795\n",
      "Epoch 69 - Loss: 0.4144459664821625 - Accuracy: 0.821\n",
      "Epoch 70 - Loss: 0.42570239305496216 - Accuracy: 0.821\n",
      "Epoch 71 - Loss: 0.39136138558387756 - Accuracy: 0.855\n",
      "Epoch 72 - Loss: 0.40845009684562683 - Accuracy: 0.838\n",
      "Epoch 73 - Loss: 0.3932664096355438 - Accuracy: 0.872\n",
      "Epoch 74 - Loss: 0.40107497572898865 - Accuracy: 0.863\n",
      "Epoch 75 - Loss: 0.35952869057655334 - Accuracy: 0.846\n",
      "Epoch 76 - Loss: 0.3856982886791229 - Accuracy: 0.846\n",
      "Epoch 77 - Loss: 0.3754298985004425 - Accuracy: 0.863\n",
      "Epoch 78 - Loss: 0.35434967279434204 - Accuracy: 0.855\n",
      "Epoch 79 - Loss: 0.3709133267402649 - Accuracy: 0.846\n",
      "Epoch 80 - Loss: 0.3531874418258667 - Accuracy: 0.872\n",
      "Epoch 81 - Loss: 0.34506580233573914 - Accuracy: 0.897\n",
      "Epoch 82 - Loss: 0.35025516152381897 - Accuracy: 0.855\n",
      "Epoch 83 - Loss: 0.3472089171409607 - Accuracy: 0.880\n",
      "Epoch 84 - Loss: 0.335073322057724 - Accuracy: 0.855\n",
      "Epoch 85 - Loss: 0.3147847652435303 - Accuracy: 0.863\n",
      "Epoch 86 - Loss: 0.3131541311740875 - Accuracy: 0.855\n",
      "Epoch 87 - Loss: 0.3162806034088135 - Accuracy: 0.897\n",
      "Epoch 88 - Loss: 0.3305424749851227 - Accuracy: 0.880\n",
      "Epoch 89 - Loss: 0.32636910676956177 - Accuracy: 0.863\n",
      "Epoch 90 - Loss: 0.2875259518623352 - Accuracy: 0.906\n",
      "Epoch 91 - Loss: 0.30300062894821167 - Accuracy: 0.863\n",
      "Epoch 92 - Loss: 0.29021474719047546 - Accuracy: 0.897\n",
      "Epoch 93 - Loss: 0.3126428425312042 - Accuracy: 0.880\n",
      "Epoch 94 - Loss: 0.2856331169605255 - Accuracy: 0.906\n",
      "Epoch 95 - Loss: 0.2739482522010803 - Accuracy: 0.889\n",
      "Epoch 96 - Loss: 0.27167385816574097 - Accuracy: 0.906\n",
      "Epoch 97 - Loss: 0.2708559036254883 - Accuracy: 0.880\n",
      "Epoch 98 - Loss: 0.273943692445755 - Accuracy: 0.872\n",
      "Epoch 99 - Loss: 0.2623909115791321 - Accuracy: 0.897\n",
      "MLP model test accuracy: 0.897\n",
      "Epoch 0 - Loss: 0.7061622738838196 - Accuracy: 0.495\n",
      "Epoch 1 - Loss: 0.7059441804885864 - Accuracy: 0.495\n",
      "Epoch 2 - Loss: 0.7046254277229309 - Accuracy: 0.495\n",
      "Epoch 3 - Loss: 0.7018927335739136 - Accuracy: 0.495\n",
      "Epoch 4 - Loss: 0.7016756534576416 - Accuracy: 0.495\n",
      "Epoch 5 - Loss: 0.7019312381744385 - Accuracy: 0.495\n",
      "Epoch 6 - Loss: 0.6975222229957581 - Accuracy: 0.495\n",
      "Epoch 7 - Loss: 0.6969031691551208 - Accuracy: 0.495\n",
      "Epoch 8 - Loss: 0.6950218677520752 - Accuracy: 0.495\n",
      "Epoch 9 - Loss: 0.6955882906913757 - Accuracy: 0.495\n",
      "Epoch 10 - Loss: 0.6921879649162292 - Accuracy: 0.495\n",
      "Epoch 11 - Loss: 0.6911382079124451 - Accuracy: 0.495\n",
      "Epoch 12 - Loss: 0.691052258014679 - Accuracy: 0.505\n",
      "Epoch 13 - Loss: 0.6858076453208923 - Accuracy: 0.505\n",
      "Epoch 14 - Loss: 0.6860007047653198 - Accuracy: 0.523\n",
      "Epoch 15 - Loss: 0.6842136979103088 - Accuracy: 0.542\n",
      "Epoch 16 - Loss: 0.6799813508987427 - Accuracy: 0.542\n",
      "Epoch 17 - Loss: 0.6790772676467896 - Accuracy: 0.570\n",
      "Epoch 18 - Loss: 0.6790996789932251 - Accuracy: 0.607\n",
      "Epoch 19 - Loss: 0.6753602027893066 - Accuracy: 0.607\n",
      "Epoch 20 - Loss: 0.6770840883255005 - Accuracy: 0.654\n",
      "Epoch 21 - Loss: 0.675250768661499 - Accuracy: 0.617\n",
      "Epoch 22 - Loss: 0.6709060072898865 - Accuracy: 0.682\n",
      "Epoch 23 - Loss: 0.6664236187934875 - Accuracy: 0.748\n",
      "Epoch 24 - Loss: 0.6665936708450317 - Accuracy: 0.682\n",
      "Epoch 25 - Loss: 0.6663153767585754 - Accuracy: 0.664\n",
      "Epoch 26 - Loss: 0.6611698865890503 - Accuracy: 0.766\n",
      "Epoch 27 - Loss: 0.6654228568077087 - Accuracy: 0.636\n",
      "Epoch 28 - Loss: 0.6625490784645081 - Accuracy: 0.710\n",
      "Epoch 29 - Loss: 0.6547808647155762 - Accuracy: 0.720\n",
      "Epoch 30 - Loss: 0.6508659720420837 - Accuracy: 0.654\n",
      "Epoch 31 - Loss: 0.6441748738288879 - Accuracy: 0.710\n",
      "Epoch 32 - Loss: 0.6537938117980957 - Accuracy: 0.692\n",
      "Epoch 33 - Loss: 0.6425541043281555 - Accuracy: 0.692\n",
      "Epoch 34 - Loss: 0.6462457776069641 - Accuracy: 0.664\n",
      "Epoch 35 - Loss: 0.6442314982414246 - Accuracy: 0.673\n",
      "Epoch 36 - Loss: 0.6377976536750793 - Accuracy: 0.645\n",
      "Epoch 37 - Loss: 0.6319283246994019 - Accuracy: 0.664\n",
      "Epoch 38 - Loss: 0.6260128021240234 - Accuracy: 0.636\n",
      "Epoch 39 - Loss: 0.6211995482444763 - Accuracy: 0.682\n",
      "Epoch 40 - Loss: 0.6202978491783142 - Accuracy: 0.682\n",
      "Epoch 41 - Loss: 0.6107137799263 - Accuracy: 0.748\n",
      "Epoch 42 - Loss: 0.6166255474090576 - Accuracy: 0.664\n",
      "Epoch 43 - Loss: 0.6091175079345703 - Accuracy: 0.710\n",
      "Epoch 44 - Loss: 0.6093372702598572 - Accuracy: 0.710\n",
      "Epoch 45 - Loss: 0.5983542203903198 - Accuracy: 0.748\n",
      "Epoch 46 - Loss: 0.6011362075805664 - Accuracy: 0.738\n",
      "Epoch 47 - Loss: 0.5912147164344788 - Accuracy: 0.794\n",
      "Epoch 48 - Loss: 0.5842684507369995 - Accuracy: 0.794\n",
      "Epoch 49 - Loss: 0.5815726518630981 - Accuracy: 0.804\n",
      "Epoch 50 - Loss: 0.5749495029449463 - Accuracy: 0.785\n",
      "Epoch 51 - Loss: 0.5763641595840454 - Accuracy: 0.804\n",
      "Epoch 52 - Loss: 0.5822312831878662 - Accuracy: 0.766\n",
      "Epoch 53 - Loss: 0.5609588623046875 - Accuracy: 0.785\n",
      "Epoch 54 - Loss: 0.5704019069671631 - Accuracy: 0.766\n",
      "Epoch 55 - Loss: 0.5510637760162354 - Accuracy: 0.776\n",
      "Epoch 56 - Loss: 0.5528907179832458 - Accuracy: 0.785\n",
      "Epoch 57 - Loss: 0.5437305569648743 - Accuracy: 0.794\n",
      "Epoch 58 - Loss: 0.5450863838195801 - Accuracy: 0.832\n",
      "Epoch 59 - Loss: 0.5427499413490295 - Accuracy: 0.794\n",
      "Epoch 60 - Loss: 0.5431836843490601 - Accuracy: 0.804\n",
      "Epoch 61 - Loss: 0.522642195224762 - Accuracy: 0.785\n",
      "Epoch 62 - Loss: 0.5318954586982727 - Accuracy: 0.794\n",
      "Epoch 63 - Loss: 0.5335541367530823 - Accuracy: 0.804\n",
      "Epoch 64 - Loss: 0.5099520683288574 - Accuracy: 0.832\n",
      "Epoch 65 - Loss: 0.5182715058326721 - Accuracy: 0.804\n",
      "Epoch 66 - Loss: 0.5073797702789307 - Accuracy: 0.804\n",
      "Epoch 67 - Loss: 0.5057395100593567 - Accuracy: 0.813\n",
      "Epoch 68 - Loss: 0.5044386386871338 - Accuracy: 0.813\n",
      "Epoch 69 - Loss: 0.49583977460861206 - Accuracy: 0.785\n",
      "Epoch 70 - Loss: 0.4858028292655945 - Accuracy: 0.832\n",
      "Epoch 71 - Loss: 0.48441454768180847 - Accuracy: 0.813\n",
      "Epoch 72 - Loss: 0.4884696304798126 - Accuracy: 0.813\n",
      "Epoch 73 - Loss: 0.47905439138412476 - Accuracy: 0.813\n",
      "Epoch 74 - Loss: 0.4595692753791809 - Accuracy: 0.841\n",
      "Epoch 75 - Loss: 0.4692324697971344 - Accuracy: 0.822\n",
      "Epoch 76 - Loss: 0.46028271317481995 - Accuracy: 0.822\n",
      "Epoch 77 - Loss: 0.4434088170528412 - Accuracy: 0.832\n",
      "Epoch 78 - Loss: 0.43768471479415894 - Accuracy: 0.822\n",
      "Epoch 79 - Loss: 0.4475577771663666 - Accuracy: 0.841\n",
      "Epoch 80 - Loss: 0.4385213851928711 - Accuracy: 0.832\n",
      "Epoch 81 - Loss: 0.4219682216644287 - Accuracy: 0.832\n",
      "Epoch 82 - Loss: 0.4207622706890106 - Accuracy: 0.832\n",
      "Epoch 83 - Loss: 0.422497034072876 - Accuracy: 0.832\n",
      "Epoch 84 - Loss: 0.41027355194091797 - Accuracy: 0.841\n",
      "Epoch 85 - Loss: 0.39295801520347595 - Accuracy: 0.850\n",
      "Epoch 86 - Loss: 0.40966176986694336 - Accuracy: 0.850\n",
      "Epoch 87 - Loss: 0.3947470784187317 - Accuracy: 0.860\n",
      "Epoch 88 - Loss: 0.3920843303203583 - Accuracy: 0.850\n",
      "Epoch 89 - Loss: 0.39558666944503784 - Accuracy: 0.822\n",
      "Epoch 90 - Loss: 0.3739999532699585 - Accuracy: 0.897\n",
      "Epoch 91 - Loss: 0.3814258873462677 - Accuracy: 0.860\n",
      "Epoch 92 - Loss: 0.3684313893318176 - Accuracy: 0.879\n",
      "Epoch 93 - Loss: 0.36731234192848206 - Accuracy: 0.907\n",
      "Epoch 94 - Loss: 0.36479949951171875 - Accuracy: 0.869\n",
      "Epoch 95 - Loss: 0.37893345952033997 - Accuracy: 0.841\n",
      "Epoch 96 - Loss: 0.37624290585517883 - Accuracy: 0.850\n",
      "Epoch 97 - Loss: 0.35409316420555115 - Accuracy: 0.888\n",
      "Epoch 98 - Loss: 0.34075644612312317 - Accuracy: 0.879\n",
      "Epoch 99 - Loss: 0.355430543422699 - Accuracy: 0.879\n",
      "MLP model test accuracy: 0.879\n",
      "Epoch 0 - Loss: 0.6941638588905334 - Accuracy: 0.488\n",
      "Epoch 1 - Loss: 0.694481372833252 - Accuracy: 0.471\n",
      "Epoch 2 - Loss: 0.6930862665176392 - Accuracy: 0.488\n",
      "Epoch 3 - Loss: 0.6911417245864868 - Accuracy: 0.562\n",
      "Epoch 4 - Loss: 0.6900407075881958 - Accuracy: 0.595\n",
      "Epoch 5 - Loss: 0.6885848045349121 - Accuracy: 0.620\n",
      "Epoch 6 - Loss: 0.6901264786720276 - Accuracy: 0.661\n",
      "Epoch 7 - Loss: 0.689186692237854 - Accuracy: 0.579\n",
      "Epoch 8 - Loss: 0.6868783235549927 - Accuracy: 0.661\n",
      "Epoch 9 - Loss: 0.686093270778656 - Accuracy: 0.694\n",
      "Epoch 10 - Loss: 0.6880860924720764 - Accuracy: 0.545\n",
      "Epoch 11 - Loss: 0.6829802989959717 - Accuracy: 0.653\n",
      "Epoch 12 - Loss: 0.6857362985610962 - Accuracy: 0.529\n",
      "Epoch 13 - Loss: 0.6845487356185913 - Accuracy: 0.620\n",
      "Epoch 14 - Loss: 0.6825281381607056 - Accuracy: 0.603\n",
      "Epoch 15 - Loss: 0.6817463040351868 - Accuracy: 0.653\n",
      "Epoch 16 - Loss: 0.6804056167602539 - Accuracy: 0.636\n",
      "Epoch 17 - Loss: 0.6803406476974487 - Accuracy: 0.595\n",
      "Epoch 18 - Loss: 0.6775972247123718 - Accuracy: 0.661\n",
      "Epoch 19 - Loss: 0.6778773069381714 - Accuracy: 0.628\n",
      "Epoch 20 - Loss: 0.674974262714386 - Accuracy: 0.653\n",
      "Epoch 21 - Loss: 0.6731023788452148 - Accuracy: 0.702\n",
      "Epoch 22 - Loss: 0.6712947487831116 - Accuracy: 0.686\n",
      "Epoch 23 - Loss: 0.6689296960830688 - Accuracy: 0.711\n",
      "Epoch 24 - Loss: 0.6689989566802979 - Accuracy: 0.702\n",
      "Epoch 25 - Loss: 0.6663691997528076 - Accuracy: 0.661\n",
      "Epoch 26 - Loss: 0.6629319190979004 - Accuracy: 0.686\n",
      "Epoch 27 - Loss: 0.6601815819740295 - Accuracy: 0.678\n",
      "Epoch 28 - Loss: 0.659966766834259 - Accuracy: 0.727\n",
      "Epoch 29 - Loss: 0.6552616953849792 - Accuracy: 0.711\n",
      "Epoch 30 - Loss: 0.6504358053207397 - Accuracy: 0.686\n",
      "Epoch 31 - Loss: 0.6470596194267273 - Accuracy: 0.736\n",
      "Epoch 32 - Loss: 0.6436946988105774 - Accuracy: 0.752\n",
      "Epoch 33 - Loss: 0.6360856890678406 - Accuracy: 0.760\n",
      "Epoch 34 - Loss: 0.6374999284744263 - Accuracy: 0.793\n",
      "Epoch 35 - Loss: 0.6295871138572693 - Accuracy: 0.785\n",
      "Epoch 36 - Loss: 0.6279105544090271 - Accuracy: 0.744\n",
      "Epoch 37 - Loss: 0.633888304233551 - Accuracy: 0.727\n",
      "Epoch 38 - Loss: 0.61564701795578 - Accuracy: 0.818\n",
      "Epoch 39 - Loss: 0.6185254454612732 - Accuracy: 0.744\n",
      "Epoch 40 - Loss: 0.6127188205718994 - Accuracy: 0.760\n",
      "Epoch 41 - Loss: 0.6028727293014526 - Accuracy: 0.810\n",
      "Epoch 42 - Loss: 0.6074249148368835 - Accuracy: 0.777\n",
      "Epoch 43 - Loss: 0.5941104292869568 - Accuracy: 0.760\n",
      "Epoch 44 - Loss: 0.5853950381278992 - Accuracy: 0.777\n",
      "Epoch 45 - Loss: 0.5895237922668457 - Accuracy: 0.769\n",
      "Epoch 46 - Loss: 0.5820325613021851 - Accuracy: 0.769\n",
      "Epoch 47 - Loss: 0.5726850628852844 - Accuracy: 0.793\n",
      "Epoch 48 - Loss: 0.5574173331260681 - Accuracy: 0.810\n",
      "Epoch 49 - Loss: 0.563923180103302 - Accuracy: 0.793\n",
      "Epoch 50 - Loss: 0.5545074939727783 - Accuracy: 0.785\n",
      "Epoch 51 - Loss: 0.5438238382339478 - Accuracy: 0.802\n",
      "Epoch 52 - Loss: 0.5470438599586487 - Accuracy: 0.810\n",
      "Epoch 53 - Loss: 0.542288601398468 - Accuracy: 0.769\n",
      "Epoch 54 - Loss: 0.5255712866783142 - Accuracy: 0.818\n",
      "Epoch 55 - Loss: 0.5136984586715698 - Accuracy: 0.818\n",
      "Epoch 56 - Loss: 0.5207974910736084 - Accuracy: 0.826\n",
      "Epoch 57 - Loss: 0.5129117369651794 - Accuracy: 0.793\n",
      "Epoch 58 - Loss: 0.5024908781051636 - Accuracy: 0.826\n",
      "Epoch 59 - Loss: 0.5076704621315002 - Accuracy: 0.810\n",
      "Epoch 60 - Loss: 0.48318007588386536 - Accuracy: 0.843\n",
      "Epoch 61 - Loss: 0.48286283016204834 - Accuracy: 0.810\n",
      "Epoch 62 - Loss: 0.47372451424598694 - Accuracy: 0.835\n",
      "Epoch 63 - Loss: 0.46703100204467773 - Accuracy: 0.835\n",
      "Epoch 64 - Loss: 0.46217823028564453 - Accuracy: 0.843\n",
      "Epoch 65 - Loss: 0.46958911418914795 - Accuracy: 0.835\n",
      "Epoch 66 - Loss: 0.45771440863609314 - Accuracy: 0.835\n",
      "Epoch 67 - Loss: 0.45421165227890015 - Accuracy: 0.826\n",
      "Epoch 68 - Loss: 0.4504014849662781 - Accuracy: 0.826\n",
      "Epoch 69 - Loss: 0.4350975751876831 - Accuracy: 0.851\n",
      "Epoch 70 - Loss: 0.42321744561195374 - Accuracy: 0.843\n",
      "Epoch 71 - Loss: 0.4304702877998352 - Accuracy: 0.835\n",
      "Epoch 72 - Loss: 0.41704216599464417 - Accuracy: 0.835\n",
      "Epoch 73 - Loss: 0.4042450785636902 - Accuracy: 0.868\n",
      "Epoch 74 - Loss: 0.41175252199172974 - Accuracy: 0.876\n",
      "Epoch 75 - Loss: 0.40480750799179077 - Accuracy: 0.843\n",
      "Epoch 76 - Loss: 0.4205065965652466 - Accuracy: 0.851\n",
      "Epoch 77 - Loss: 0.38663098216056824 - Accuracy: 0.851\n",
      "Epoch 78 - Loss: 0.38394513726234436 - Accuracy: 0.860\n",
      "Epoch 79 - Loss: 0.3718224763870239 - Accuracy: 0.876\n",
      "Epoch 80 - Loss: 0.3702557682991028 - Accuracy: 0.843\n",
      "Epoch 81 - Loss: 0.36102622747421265 - Accuracy: 0.884\n",
      "Epoch 82 - Loss: 0.37653788924217224 - Accuracy: 0.868\n",
      "Epoch 83 - Loss: 0.3744603991508484 - Accuracy: 0.876\n",
      "Epoch 84 - Loss: 0.3569518029689789 - Accuracy: 0.868\n",
      "Epoch 85 - Loss: 0.35914546251296997 - Accuracy: 0.851\n",
      "Epoch 86 - Loss: 0.3514571785926819 - Accuracy: 0.860\n",
      "Epoch 87 - Loss: 0.33669114112854004 - Accuracy: 0.893\n",
      "Epoch 88 - Loss: 0.32768598198890686 - Accuracy: 0.901\n",
      "Epoch 89 - Loss: 0.3373297154903412 - Accuracy: 0.876\n",
      "Epoch 90 - Loss: 0.3331764340400696 - Accuracy: 0.876\n",
      "Epoch 91 - Loss: 0.3363046944141388 - Accuracy: 0.884\n",
      "Epoch 92 - Loss: 0.31244608759880066 - Accuracy: 0.876\n",
      "Epoch 93 - Loss: 0.32380929589271545 - Accuracy: 0.860\n",
      "Epoch 94 - Loss: 0.32390469312667847 - Accuracy: 0.868\n",
      "Epoch 95 - Loss: 0.3175974488258362 - Accuracy: 0.876\n",
      "Epoch 96 - Loss: 0.31875738501548767 - Accuracy: 0.884\n",
      "Epoch 97 - Loss: 0.31569904088974 - Accuracy: 0.884\n",
      "Epoch 98 - Loss: 0.29393792152404785 - Accuracy: 0.901\n",
      "Epoch 99 - Loss: 0.29460495710372925 - Accuracy: 0.893\n",
      "MLP model test accuracy: 0.893\n",
      "Epoch 0 - Loss: 0.6947572231292725 - Accuracy: 0.486\n",
      "Epoch 1 - Loss: 0.6939085721969604 - Accuracy: 0.523\n",
      "Epoch 2 - Loss: 0.6931759119033813 - Accuracy: 0.495\n",
      "Epoch 3 - Loss: 0.6929614543914795 - Accuracy: 0.514\n",
      "Epoch 4 - Loss: 0.6920706033706665 - Accuracy: 0.495\n",
      "Epoch 5 - Loss: 0.6909037828445435 - Accuracy: 0.514\n",
      "Epoch 6 - Loss: 0.6896881461143494 - Accuracy: 0.505\n",
      "Epoch 7 - Loss: 0.6910549998283386 - Accuracy: 0.514\n",
      "Epoch 8 - Loss: 0.690051257610321 - Accuracy: 0.532\n",
      "Epoch 9 - Loss: 0.6903714537620544 - Accuracy: 0.550\n",
      "Epoch 10 - Loss: 0.6887669563293457 - Accuracy: 0.514\n",
      "Epoch 11 - Loss: 0.6891939043998718 - Accuracy: 0.595\n",
      "Epoch 12 - Loss: 0.6883938908576965 - Accuracy: 0.595\n",
      "Epoch 13 - Loss: 0.6846678256988525 - Accuracy: 0.613\n",
      "Epoch 14 - Loss: 0.6839526295661926 - Accuracy: 0.613\n",
      "Epoch 15 - Loss: 0.6851415634155273 - Accuracy: 0.550\n",
      "Epoch 16 - Loss: 0.6878972053527832 - Accuracy: 0.541\n",
      "Epoch 17 - Loss: 0.6835581660270691 - Accuracy: 0.604\n",
      "Epoch 18 - Loss: 0.6821121573448181 - Accuracy: 0.622\n",
      "Epoch 19 - Loss: 0.6796651482582092 - Accuracy: 0.685\n",
      "Epoch 20 - Loss: 0.6795501112937927 - Accuracy: 0.613\n",
      "Epoch 21 - Loss: 0.678249716758728 - Accuracy: 0.658\n",
      "Epoch 22 - Loss: 0.6761676073074341 - Accuracy: 0.658\n",
      "Epoch 23 - Loss: 0.673958420753479 - Accuracy: 0.658\n",
      "Epoch 24 - Loss: 0.6775751709938049 - Accuracy: 0.613\n",
      "Epoch 25 - Loss: 0.6759212613105774 - Accuracy: 0.667\n",
      "Epoch 26 - Loss: 0.6720925569534302 - Accuracy: 0.694\n",
      "Epoch 27 - Loss: 0.6687338352203369 - Accuracy: 0.685\n",
      "Epoch 28 - Loss: 0.6699612736701965 - Accuracy: 0.694\n",
      "Epoch 29 - Loss: 0.6662834286689758 - Accuracy: 0.721\n",
      "Epoch 30 - Loss: 0.6649690866470337 - Accuracy: 0.739\n",
      "Epoch 31 - Loss: 0.6644927263259888 - Accuracy: 0.694\n",
      "Epoch 32 - Loss: 0.658286452293396 - Accuracy: 0.703\n",
      "Epoch 33 - Loss: 0.6579117774963379 - Accuracy: 0.775\n",
      "Epoch 34 - Loss: 0.6552607417106628 - Accuracy: 0.730\n",
      "Epoch 35 - Loss: 0.651573121547699 - Accuracy: 0.721\n",
      "Epoch 36 - Loss: 0.6547582745552063 - Accuracy: 0.712\n",
      "Epoch 37 - Loss: 0.6479979753494263 - Accuracy: 0.757\n",
      "Epoch 38 - Loss: 0.6425064206123352 - Accuracy: 0.757\n",
      "Epoch 39 - Loss: 0.6417213082313538 - Accuracy: 0.757\n",
      "Epoch 40 - Loss: 0.6402705311775208 - Accuracy: 0.784\n",
      "Epoch 41 - Loss: 0.6297534108161926 - Accuracy: 0.820\n",
      "Epoch 42 - Loss: 0.6309905648231506 - Accuracy: 0.766\n",
      "Epoch 43 - Loss: 0.6245777606964111 - Accuracy: 0.784\n",
      "Epoch 44 - Loss: 0.6232684254646301 - Accuracy: 0.811\n",
      "Epoch 45 - Loss: 0.6201061606407166 - Accuracy: 0.766\n",
      "Epoch 46 - Loss: 0.6220354437828064 - Accuracy: 0.739\n",
      "Epoch 47 - Loss: 0.6118205785751343 - Accuracy: 0.793\n",
      "Epoch 48 - Loss: 0.6011182069778442 - Accuracy: 0.793\n",
      "Epoch 49 - Loss: 0.6013173460960388 - Accuracy: 0.793\n",
      "Epoch 50 - Loss: 0.5901787281036377 - Accuracy: 0.829\n",
      "Epoch 51 - Loss: 0.5908238887786865 - Accuracy: 0.811\n",
      "Epoch 52 - Loss: 0.5869312882423401 - Accuracy: 0.820\n",
      "Epoch 53 - Loss: 0.5822070240974426 - Accuracy: 0.811\n",
      "Epoch 54 - Loss: 0.5752094984054565 - Accuracy: 0.793\n",
      "Epoch 55 - Loss: 0.560533344745636 - Accuracy: 0.838\n",
      "Epoch 56 - Loss: 0.5472837686538696 - Accuracy: 0.865\n",
      "Epoch 57 - Loss: 0.5465494990348816 - Accuracy: 0.838\n",
      "Epoch 58 - Loss: 0.5527447462081909 - Accuracy: 0.847\n",
      "Epoch 59 - Loss: 0.5456579923629761 - Accuracy: 0.838\n",
      "Epoch 60 - Loss: 0.5317151546478271 - Accuracy: 0.865\n",
      "Epoch 61 - Loss: 0.5158852338790894 - Accuracy: 0.865\n",
      "Epoch 62 - Loss: 0.5097138285636902 - Accuracy: 0.874\n",
      "Epoch 63 - Loss: 0.5195926427841187 - Accuracy: 0.811\n",
      "Epoch 64 - Loss: 0.49632659554481506 - Accuracy: 0.874\n",
      "Epoch 65 - Loss: 0.4892342984676361 - Accuracy: 0.865\n",
      "Epoch 66 - Loss: 0.48299771547317505 - Accuracy: 0.865\n",
      "Epoch 67 - Loss: 0.474563866853714 - Accuracy: 0.865\n",
      "Epoch 68 - Loss: 0.4826659560203552 - Accuracy: 0.874\n",
      "Epoch 69 - Loss: 0.46155697107315063 - Accuracy: 0.865\n",
      "Epoch 70 - Loss: 0.46123194694519043 - Accuracy: 0.856\n",
      "Epoch 71 - Loss: 0.45600560307502747 - Accuracy: 0.874\n",
      "Epoch 72 - Loss: 0.42961597442626953 - Accuracy: 0.892\n",
      "Epoch 73 - Loss: 0.43944352865219116 - Accuracy: 0.856\n",
      "Epoch 74 - Loss: 0.42386025190353394 - Accuracy: 0.901\n",
      "Epoch 75 - Loss: 0.4197255074977875 - Accuracy: 0.910\n",
      "Epoch 76 - Loss: 0.4033319056034088 - Accuracy: 0.901\n",
      "Epoch 77 - Loss: 0.4001758098602295 - Accuracy: 0.874\n",
      "Epoch 78 - Loss: 0.39902254939079285 - Accuracy: 0.910\n",
      "Epoch 79 - Loss: 0.39871057868003845 - Accuracy: 0.874\n",
      "Epoch 80 - Loss: 0.39390137791633606 - Accuracy: 0.883\n",
      "Epoch 81 - Loss: 0.3786466121673584 - Accuracy: 0.901\n",
      "Epoch 82 - Loss: 0.37964922189712524 - Accuracy: 0.856\n",
      "Epoch 83 - Loss: 0.36243608593940735 - Accuracy: 0.892\n",
      "Epoch 84 - Loss: 0.3573017418384552 - Accuracy: 0.910\n",
      "Epoch 85 - Loss: 0.35188359022140503 - Accuracy: 0.910\n",
      "Epoch 86 - Loss: 0.3375958502292633 - Accuracy: 0.937\n",
      "Epoch 87 - Loss: 0.3417453467845917 - Accuracy: 0.892\n",
      "Epoch 88 - Loss: 0.33006057143211365 - Accuracy: 0.910\n",
      "Epoch 89 - Loss: 0.31831681728363037 - Accuracy: 0.919\n",
      "Epoch 90 - Loss: 0.3209869861602783 - Accuracy: 0.892\n",
      "Epoch 91 - Loss: 0.3285757601261139 - Accuracy: 0.883\n",
      "Epoch 92 - Loss: 0.3270958960056305 - Accuracy: 0.901\n",
      "Epoch 93 - Loss: 0.30424764752388 - Accuracy: 0.910\n",
      "Epoch 94 - Loss: 0.31587445735931396 - Accuracy: 0.856\n",
      "Epoch 95 - Loss: 0.3043190836906433 - Accuracy: 0.910\n",
      "Epoch 96 - Loss: 0.2931428849697113 - Accuracy: 0.901\n",
      "Epoch 97 - Loss: 0.2903296947479248 - Accuracy: 0.919\n",
      "Epoch 98 - Loss: 0.2782804071903229 - Accuracy: 0.919\n",
      "Epoch 99 - Loss: 0.28728365898132324 - Accuracy: 0.865\n",
      "MLP model test accuracy: 0.865\n"
     ]
    }
   ],
   "source": [
    "mlp_results = {}\n",
    "for ppi in ppis:\n",
    "    mask_train = data[ppi,0].train_mask.squeeze()  \n",
    "    mask_test = data[ppi,0].test_mask.squeeze()\n",
    "\n",
    "    X_train = torch.tensor(data[ppi,0].x[mask_train].numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor([y.item() for yz in data[ppi,0].y[mask_train] for y in yz], dtype=torch.long)\n",
    "    X_test = torch.tensor(data[ppi,0].x[mask_test].numpy(), dtype=torch.float32)  \n",
    "    y_test = torch.tensor([y.item() for yz in data[ppi,0].y[mask_test] for y in yz], dtype=torch.long)\n",
    "\n",
    "    # data[ppi].x = torch.tensor(data[ppi].x, dtype=torch.float32)\n",
    "    # labels = torch.tensor([y.item() for yz in data[ppi].y for y in yz], dtype=torch.long)\n",
    "\n",
    "    #labels = torch.tensor(labels, dtype=torch.long)\n",
    "    model, test_acc, test_auroc, test_aupr, test_f1, test_pred = train_mlp(X_train, X_test, y_train, y_test)\n",
    "    mlp_results[ppi] = (model, test_acc, test_f1, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPDB': (MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  0.75,\n",
       "  np.float64(0.7272727272727273),\n",
       "  tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "          0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])),\n",
       " 'IRefIndex': (MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  0.7027027027027027,\n",
       "  np.float64(0.6666666666666666),\n",
       "  tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "          0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0])),\n",
       " 'IRefIndex_2015': (MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  0.8235294117647058,\n",
       "  np.float64(0.8333333333333334),\n",
       "  tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "          1, 0, 0, 0, 1, 1, 0, 0, 1, 0])),\n",
       " 'PCNet': (MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  0.6578947368421053,\n",
       "  np.float64(0.6486486486486487),\n",
       "  tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0])),\n",
       " 'STRINGdb': (MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  0.7142857142857143,\n",
       "  np.float64(0.7222222222222222),\n",
       "  tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "          1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0]))}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CPDB',\n",
       "  0): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('CPDB',\n",
       "  1): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('CPDB',\n",
       "  2): Data(x=[13627, 64], edge_index=[2, 518005], y=[13627, 1], train_mask=[13627, 1], test_mask=[13627, 1], val_mask=[13627, 1], name=[13627]),\n",
       " ('IRefIndex',\n",
       "  0): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex',\n",
       "  1): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex',\n",
       "  2): Data(x=[17013, 64], edge_index=[2, 760150], y=[17013, 1], train_mask=[17013, 1], test_mask=[17013, 1], val_mask=[17013, 1], name=[17013]),\n",
       " ('IRefIndex_2015',\n",
       "  0): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('IRefIndex_2015',\n",
       "  1): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('IRefIndex_2015',\n",
       "  2): Data(x=[12129, 64], edge_index=[2, 195747], y=[12129, 1], train_mask=[12129, 1], test_mask=[12129, 1], val_mask=[12129, 1], name=[12129]),\n",
       " ('PCNet',\n",
       "  0): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('PCNet',\n",
       "  1): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('PCNet',\n",
       "  2): Data(x=[19781, 64], edge_index=[2, 5469229], y=[19781, 1], train_mask=[19781, 1], test_mask=[19781, 1], val_mask=[19781, 1], name=[19781]),\n",
       " ('STRINGdb',\n",
       "  0): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179]),\n",
       " ('STRINGdb',\n",
       "  1): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179]),\n",
       " ('STRINGdb',\n",
       "  2): Data(x=[13179, 64], edge_index=[2, 686278], y=[13179, 1], train_mask=[13179, 1], test_mask=[13179, 1], val_mask=[13179, 1], name=[13179])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [13179] at index 0 does not match the shape of the indexed tensor [13627, 64] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mCPDB\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m].train_mask\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train = torch.tensor(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCPDB\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_train\u001b[49m\u001b[43m]\u001b[49m.numpy(), dtype=torch.float32)\n\u001b[32m      3\u001b[39m X_train\n",
      "\u001b[31mIndexError\u001b[39m: The shape of the mask [13179] at index 0 does not match the shape of the indexed tensor [13627, 64] at index 0"
     ]
    }
   ],
   "source": [
    "data['CPDB', 0].train_mask\n",
    "X_train = torch.tensor(data['CPDB', 0].x[mask_train].numpy(), dtype=torch.float32)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MLP experiments on ('CPDB', 0) data\n",
      "Epoch 0 - Loss: 0.6976980566978455 - Accuracy: 0.504\n",
      "Epoch 1 - Loss: 0.6935251355171204 - Accuracy: 0.504\n",
      "Epoch 2 - Loss: 0.6956667900085449 - Accuracy: 0.504\n",
      "Epoch 3 - Loss: 0.695032000541687 - Accuracy: 0.504\n",
      "Epoch 4 - Loss: 0.6931697726249695 - Accuracy: 0.504\n",
      "Epoch 5 - Loss: 0.6926687359809875 - Accuracy: 0.504\n",
      "Epoch 6 - Loss: 0.6914736032485962 - Accuracy: 0.504\n",
      "Epoch 7 - Loss: 0.6930235624313354 - Accuracy: 0.504\n",
      "Epoch 8 - Loss: 0.6906492710113525 - Accuracy: 0.513\n",
      "Epoch 9 - Loss: 0.6907798647880554 - Accuracy: 0.539\n",
      "Epoch 10 - Loss: 0.6886951327323914 - Accuracy: 0.530\n",
      "Epoch 11 - Loss: 0.6923489570617676 - Accuracy: 0.513\n",
      "Epoch 12 - Loss: 0.6893332004547119 - Accuracy: 0.539\n",
      "Epoch 13 - Loss: 0.6877790093421936 - Accuracy: 0.609\n",
      "Epoch 14 - Loss: 0.6873703002929688 - Accuracy: 0.600\n",
      "Epoch 15 - Loss: 0.6878857016563416 - Accuracy: 0.591\n",
      "Epoch 16 - Loss: 0.6869164109230042 - Accuracy: 0.574\n",
      "Epoch 17 - Loss: 0.6856655478477478 - Accuracy: 0.643\n",
      "Epoch 18 - Loss: 0.6868208646774292 - Accuracy: 0.600\n",
      "Epoch 19 - Loss: 0.6834731101989746 - Accuracy: 0.643\n",
      "Epoch 20 - Loss: 0.6861076951026917 - Accuracy: 0.643\n",
      "Epoch 21 - Loss: 0.6831183433532715 - Accuracy: 0.617\n",
      "Epoch 22 - Loss: 0.6832894086837769 - Accuracy: 0.643\n",
      "Epoch 23 - Loss: 0.6824449896812439 - Accuracy: 0.661\n",
      "Epoch 24 - Loss: 0.6813828349113464 - Accuracy: 0.670\n",
      "Epoch 25 - Loss: 0.680774986743927 - Accuracy: 0.652\n",
      "Epoch 26 - Loss: 0.6749283671379089 - Accuracy: 0.774\n",
      "Epoch 27 - Loss: 0.6775878071784973 - Accuracy: 0.678\n",
      "Epoch 28 - Loss: 0.6765445470809937 - Accuracy: 0.670\n",
      "Epoch 29 - Loss: 0.6728368401527405 - Accuracy: 0.687\n",
      "Epoch 30 - Loss: 0.6740806102752686 - Accuracy: 0.643\n",
      "Epoch 31 - Loss: 0.6721683144569397 - Accuracy: 0.670\n",
      "Epoch 32 - Loss: 0.6686027646064758 - Accuracy: 0.748\n",
      "Epoch 33 - Loss: 0.6693120002746582 - Accuracy: 0.678\n",
      "Epoch 34 - Loss: 0.6616309881210327 - Accuracy: 0.757\n",
      "Epoch 35 - Loss: 0.661933422088623 - Accuracy: 0.722\n",
      "Epoch 36 - Loss: 0.6600688099861145 - Accuracy: 0.800\n",
      "Epoch 37 - Loss: 0.6525772213935852 - Accuracy: 0.722\n",
      "Epoch 38 - Loss: 0.655363142490387 - Accuracy: 0.722\n",
      "Epoch 39 - Loss: 0.652133584022522 - Accuracy: 0.739\n",
      "Epoch 40 - Loss: 0.6475683450698853 - Accuracy: 0.748\n",
      "Epoch 41 - Loss: 0.6434255838394165 - Accuracy: 0.783\n",
      "Epoch 42 - Loss: 0.6412909030914307 - Accuracy: 0.809\n",
      "Epoch 43 - Loss: 0.6367732286453247 - Accuracy: 0.739\n",
      "Epoch 44 - Loss: 0.6353679299354553 - Accuracy: 0.774\n",
      "Epoch 45 - Loss: 0.6250414848327637 - Accuracy: 0.783\n",
      "Epoch 46 - Loss: 0.6279245018959045 - Accuracy: 0.722\n",
      "Epoch 47 - Loss: 0.6201964616775513 - Accuracy: 0.800\n",
      "Epoch 48 - Loss: 0.6167569756507874 - Accuracy: 0.800\n",
      "Epoch 49 - Loss: 0.6168835759162903 - Accuracy: 0.765\n",
      "Epoch 50 - Loss: 0.6045074462890625 - Accuracy: 0.809\n",
      "Epoch 51 - Loss: 0.5921496748924255 - Accuracy: 0.783\n",
      "Epoch 52 - Loss: 0.589673638343811 - Accuracy: 0.791\n",
      "Epoch 53 - Loss: 0.5965969562530518 - Accuracy: 0.791\n",
      "Epoch 54 - Loss: 0.5910469889640808 - Accuracy: 0.826\n",
      "Epoch 55 - Loss: 0.5768744945526123 - Accuracy: 0.826\n",
      "Epoch 56 - Loss: 0.5772694945335388 - Accuracy: 0.826\n",
      "Epoch 57 - Loss: 0.5612073540687561 - Accuracy: 0.843\n",
      "Epoch 58 - Loss: 0.5565764904022217 - Accuracy: 0.817\n",
      "Epoch 59 - Loss: 0.5464892983436584 - Accuracy: 0.861\n",
      "Epoch 60 - Loss: 0.5552789568901062 - Accuracy: 0.800\n",
      "Epoch 61 - Loss: 0.5336697697639465 - Accuracy: 0.852\n",
      "Epoch 62 - Loss: 0.5260481238365173 - Accuracy: 0.843\n",
      "Epoch 63 - Loss: 0.5187299847602844 - Accuracy: 0.843\n",
      "Epoch 64 - Loss: 0.5039548277854919 - Accuracy: 0.826\n",
      "Epoch 65 - Loss: 0.517646312713623 - Accuracy: 0.835\n",
      "Epoch 66 - Loss: 0.5027811527252197 - Accuracy: 0.852\n",
      "Epoch 67 - Loss: 0.48855334520339966 - Accuracy: 0.817\n",
      "Epoch 68 - Loss: 0.48611119389533997 - Accuracy: 0.861\n",
      "Epoch 69 - Loss: 0.4742331802845001 - Accuracy: 0.852\n",
      "Epoch 70 - Loss: 0.4805423319339752 - Accuracy: 0.843\n",
      "Epoch 71 - Loss: 0.4693673551082611 - Accuracy: 0.852\n",
      "Epoch 72 - Loss: 0.4618244469165802 - Accuracy: 0.835\n",
      "Epoch 73 - Loss: 0.4599299132823944 - Accuracy: 0.861\n",
      "Epoch 74 - Loss: 0.4372873604297638 - Accuracy: 0.861\n",
      "Epoch 75 - Loss: 0.4454541802406311 - Accuracy: 0.878\n",
      "Epoch 76 - Loss: 0.4245116710662842 - Accuracy: 0.861\n",
      "Epoch 77 - Loss: 0.4152401387691498 - Accuracy: 0.870\n",
      "Epoch 78 - Loss: 0.3989991843700409 - Accuracy: 0.896\n",
      "Epoch 79 - Loss: 0.4093111753463745 - Accuracy: 0.843\n",
      "Epoch 80 - Loss: 0.39134106040000916 - Accuracy: 0.878\n",
      "Epoch 81 - Loss: 0.3743686378002167 - Accuracy: 0.870\n",
      "Epoch 82 - Loss: 0.38528433442115784 - Accuracy: 0.843\n",
      "Epoch 83 - Loss: 0.3659418523311615 - Accuracy: 0.852\n",
      "Epoch 84 - Loss: 0.3618193566799164 - Accuracy: 0.878\n",
      "Epoch 85 - Loss: 0.39725571870803833 - Accuracy: 0.852\n",
      "Epoch 86 - Loss: 0.3564999997615814 - Accuracy: 0.913\n",
      "Epoch 87 - Loss: 0.356133371591568 - Accuracy: 0.870\n",
      "Epoch 88 - Loss: 0.3563205301761627 - Accuracy: 0.852\n",
      "Epoch 89 - Loss: 0.36327704787254333 - Accuracy: 0.878\n",
      "Epoch 90 - Loss: 0.33679765462875366 - Accuracy: 0.878\n",
      "Epoch 91 - Loss: 0.32602548599243164 - Accuracy: 0.913\n",
      "Epoch 92 - Loss: 0.3289242684841156 - Accuracy: 0.878\n",
      "Epoch 93 - Loss: 0.3096770942211151 - Accuracy: 0.896\n",
      "Epoch 94 - Loss: 0.29326340556144714 - Accuracy: 0.904\n",
      "Epoch 95 - Loss: 0.3154958188533783 - Accuracy: 0.887\n",
      "Epoch 96 - Loss: 0.29399386048316956 - Accuracy: 0.904\n",
      "Epoch 97 - Loss: 0.31742703914642334 - Accuracy: 0.887\n",
      "Epoch 98 - Loss: 0.2856479585170746 - Accuracy: 0.887\n",
      "Epoch 99 - Loss: 0.28283143043518066 - Accuracy: 0.896\n",
      "MLP model test accuracy: 0.896\n",
      "Running MLP experiments on ('CPDB', 1) data\n",
      "Epoch 0 - Loss: 0.6946350932121277 - Accuracy: 0.487\n",
      "Epoch 1 - Loss: 0.6942728161811829 - Accuracy: 0.522\n",
      "Epoch 2 - Loss: 0.6950118541717529 - Accuracy: 0.487\n",
      "Epoch 3 - Loss: 0.6943226456642151 - Accuracy: 0.504\n",
      "Epoch 4 - Loss: 0.6920073628425598 - Accuracy: 0.504\n",
      "Epoch 5 - Loss: 0.6911789178848267 - Accuracy: 0.487\n",
      "Epoch 6 - Loss: 0.6908214688301086 - Accuracy: 0.530\n",
      "Epoch 7 - Loss: 0.6892878413200378 - Accuracy: 0.565\n",
      "Epoch 8 - Loss: 0.6871877908706665 - Accuracy: 0.522\n",
      "Epoch 9 - Loss: 0.6888918280601501 - Accuracy: 0.574\n",
      "Epoch 10 - Loss: 0.6858803629875183 - Accuracy: 0.583\n",
      "Epoch 11 - Loss: 0.6854813098907471 - Accuracy: 0.626\n",
      "Epoch 12 - Loss: 0.6885856986045837 - Accuracy: 0.574\n",
      "Epoch 13 - Loss: 0.684327244758606 - Accuracy: 0.574\n",
      "Epoch 14 - Loss: 0.6845327019691467 - Accuracy: 0.626\n",
      "Epoch 15 - Loss: 0.6844819188117981 - Accuracy: 0.626\n",
      "Epoch 16 - Loss: 0.6838365197181702 - Accuracy: 0.661\n",
      "Epoch 17 - Loss: 0.6836838722229004 - Accuracy: 0.617\n",
      "Epoch 18 - Loss: 0.6789650917053223 - Accuracy: 0.696\n",
      "Epoch 19 - Loss: 0.6762005090713501 - Accuracy: 0.678\n",
      "Epoch 20 - Loss: 0.6776973605155945 - Accuracy: 0.696\n",
      "Epoch 21 - Loss: 0.67656409740448 - Accuracy: 0.704\n",
      "Epoch 22 - Loss: 0.676535427570343 - Accuracy: 0.670\n",
      "Epoch 23 - Loss: 0.6735562682151794 - Accuracy: 0.687\n",
      "Epoch 24 - Loss: 0.672465980052948 - Accuracy: 0.730\n",
      "Epoch 25 - Loss: 0.6683332324028015 - Accuracy: 0.713\n",
      "Epoch 26 - Loss: 0.6693472862243652 - Accuracy: 0.696\n",
      "Epoch 27 - Loss: 0.6663491129875183 - Accuracy: 0.748\n",
      "Epoch 28 - Loss: 0.661510705947876 - Accuracy: 0.730\n",
      "Epoch 29 - Loss: 0.6569089889526367 - Accuracy: 0.765\n",
      "Epoch 30 - Loss: 0.6564541459083557 - Accuracy: 0.757\n",
      "Epoch 31 - Loss: 0.652754008769989 - Accuracy: 0.774\n",
      "Epoch 32 - Loss: 0.6530902981758118 - Accuracy: 0.800\n",
      "Epoch 33 - Loss: 0.6519058346748352 - Accuracy: 0.748\n",
      "Epoch 34 - Loss: 0.6435214877128601 - Accuracy: 0.757\n",
      "Epoch 35 - Loss: 0.6423860788345337 - Accuracy: 0.765\n",
      "Epoch 36 - Loss: 0.6333017945289612 - Accuracy: 0.791\n",
      "Epoch 37 - Loss: 0.6310245394706726 - Accuracy: 0.791\n",
      "Epoch 38 - Loss: 0.6266207098960876 - Accuracy: 0.800\n",
      "Epoch 39 - Loss: 0.6231347918510437 - Accuracy: 0.835\n",
      "Epoch 40 - Loss: 0.6182811856269836 - Accuracy: 0.817\n",
      "Epoch 41 - Loss: 0.616012692451477 - Accuracy: 0.791\n",
      "Epoch 42 - Loss: 0.6094038486480713 - Accuracy: 0.817\n",
      "Epoch 43 - Loss: 0.6083456873893738 - Accuracy: 0.826\n",
      "Epoch 44 - Loss: 0.5969855189323425 - Accuracy: 0.835\n",
      "Epoch 45 - Loss: 0.5919327735900879 - Accuracy: 0.800\n",
      "Epoch 46 - Loss: 0.587109386920929 - Accuracy: 0.791\n",
      "Epoch 47 - Loss: 0.5823958516120911 - Accuracy: 0.817\n",
      "Epoch 48 - Loss: 0.5728995203971863 - Accuracy: 0.826\n",
      "Epoch 49 - Loss: 0.5647273659706116 - Accuracy: 0.826\n",
      "Epoch 50 - Loss: 0.5580587387084961 - Accuracy: 0.852\n",
      "Epoch 51 - Loss: 0.5633814334869385 - Accuracy: 0.826\n",
      "Epoch 52 - Loss: 0.5592317581176758 - Accuracy: 0.826\n",
      "Epoch 53 - Loss: 0.5451938509941101 - Accuracy: 0.826\n",
      "Epoch 54 - Loss: 0.5409641861915588 - Accuracy: 0.826\n",
      "Epoch 55 - Loss: 0.5389388799667358 - Accuracy: 0.800\n",
      "Epoch 56 - Loss: 0.5299624800682068 - Accuracy: 0.843\n",
      "Epoch 57 - Loss: 0.5215367674827576 - Accuracy: 0.809\n",
      "Epoch 58 - Loss: 0.5093033909797668 - Accuracy: 0.826\n",
      "Epoch 59 - Loss: 0.5017173290252686 - Accuracy: 0.835\n",
      "Epoch 60 - Loss: 0.49474722146987915 - Accuracy: 0.861\n",
      "Epoch 61 - Loss: 0.49869635701179504 - Accuracy: 0.835\n",
      "Epoch 62 - Loss: 0.49825572967529297 - Accuracy: 0.817\n",
      "Epoch 63 - Loss: 0.4915187954902649 - Accuracy: 0.843\n",
      "Epoch 64 - Loss: 0.4795433580875397 - Accuracy: 0.835\n",
      "Epoch 65 - Loss: 0.4757917523384094 - Accuracy: 0.843\n",
      "Epoch 66 - Loss: 0.4648985266685486 - Accuracy: 0.861\n",
      "Epoch 67 - Loss: 0.45165976881980896 - Accuracy: 0.843\n",
      "Epoch 68 - Loss: 0.4508366882801056 - Accuracy: 0.861\n",
      "Epoch 69 - Loss: 0.44196707010269165 - Accuracy: 0.887\n",
      "Epoch 70 - Loss: 0.43096208572387695 - Accuracy: 0.826\n",
      "Epoch 71 - Loss: 0.44151926040649414 - Accuracy: 0.852\n",
      "Epoch 72 - Loss: 0.427016019821167 - Accuracy: 0.852\n",
      "Epoch 73 - Loss: 0.42058438062667847 - Accuracy: 0.861\n",
      "Epoch 74 - Loss: 0.40926218032836914 - Accuracy: 0.852\n",
      "Epoch 75 - Loss: 0.41407665610313416 - Accuracy: 0.852\n",
      "Epoch 76 - Loss: 0.41339102387428284 - Accuracy: 0.861\n",
      "Epoch 77 - Loss: 0.40148431062698364 - Accuracy: 0.878\n",
      "Epoch 78 - Loss: 0.4003588557243347 - Accuracy: 0.861\n",
      "Epoch 79 - Loss: 0.37758001685142517 - Accuracy: 0.870\n",
      "Epoch 80 - Loss: 0.39630866050720215 - Accuracy: 0.852\n",
      "Epoch 81 - Loss: 0.3729467988014221 - Accuracy: 0.861\n",
      "Epoch 82 - Loss: 0.38864538073539734 - Accuracy: 0.861\n",
      "Epoch 83 - Loss: 0.3812035024166107 - Accuracy: 0.870\n",
      "Epoch 84 - Loss: 0.3612702190876007 - Accuracy: 0.870\n",
      "Epoch 85 - Loss: 0.34812459349632263 - Accuracy: 0.887\n",
      "Epoch 86 - Loss: 0.3544703722000122 - Accuracy: 0.878\n",
      "Epoch 87 - Loss: 0.34970948100090027 - Accuracy: 0.852\n",
      "Epoch 88 - Loss: 0.3264088034629822 - Accuracy: 0.896\n",
      "Epoch 89 - Loss: 0.3403013348579407 - Accuracy: 0.861\n",
      "Epoch 90 - Loss: 0.3360958695411682 - Accuracy: 0.887\n",
      "Epoch 91 - Loss: 0.3187982439994812 - Accuracy: 0.896\n",
      "Epoch 92 - Loss: 0.30954572558403015 - Accuracy: 0.904\n",
      "Epoch 93 - Loss: 0.31952980160713196 - Accuracy: 0.887\n",
      "Epoch 94 - Loss: 0.3192337453365326 - Accuracy: 0.904\n",
      "Epoch 95 - Loss: 0.307136595249176 - Accuracy: 0.896\n",
      "Epoch 96 - Loss: 0.31150513887405396 - Accuracy: 0.896\n",
      "Epoch 97 - Loss: 0.3053324818611145 - Accuracy: 0.913\n",
      "Epoch 98 - Loss: 0.3064279854297638 - Accuracy: 0.878\n",
      "Epoch 99 - Loss: 0.2912856340408325 - Accuracy: 0.904\n",
      "MLP model test accuracy: 0.904\n",
      "Running MLP experiments on ('CPDB', 2) data\n",
      "Epoch 0 - Loss: 0.6936860680580139 - Accuracy: 0.504\n",
      "Epoch 1 - Loss: 0.6937758326530457 - Accuracy: 0.504\n",
      "Epoch 2 - Loss: 0.6931958794593811 - Accuracy: 0.496\n",
      "Epoch 3 - Loss: 0.6913691759109497 - Accuracy: 0.504\n",
      "Epoch 4 - Loss: 0.6927785277366638 - Accuracy: 0.496\n",
      "Epoch 5 - Loss: 0.690438449382782 - Accuracy: 0.513\n",
      "Epoch 6 - Loss: 0.6913177371025085 - Accuracy: 0.504\n",
      "Epoch 7 - Loss: 0.6879361867904663 - Accuracy: 0.504\n",
      "Epoch 8 - Loss: 0.6901618242263794 - Accuracy: 0.513\n",
      "Epoch 9 - Loss: 0.6898362040519714 - Accuracy: 0.496\n",
      "Epoch 10 - Loss: 0.6877301335334778 - Accuracy: 0.557\n",
      "Epoch 11 - Loss: 0.6861007809638977 - Accuracy: 0.548\n",
      "Epoch 12 - Loss: 0.6862674355506897 - Accuracy: 0.557\n",
      "Epoch 13 - Loss: 0.6852417588233948 - Accuracy: 0.591\n",
      "Epoch 14 - Loss: 0.6856417655944824 - Accuracy: 0.591\n",
      "Epoch 15 - Loss: 0.6854821443557739 - Accuracy: 0.574\n",
      "Epoch 16 - Loss: 0.6810415983200073 - Accuracy: 0.635\n",
      "Epoch 17 - Loss: 0.6835532188415527 - Accuracy: 0.557\n",
      "Epoch 18 - Loss: 0.679990828037262 - Accuracy: 0.626\n",
      "Epoch 19 - Loss: 0.6797524690628052 - Accuracy: 0.626\n",
      "Epoch 20 - Loss: 0.6757363080978394 - Accuracy: 0.661\n",
      "Epoch 21 - Loss: 0.6749370694160461 - Accuracy: 0.652\n",
      "Epoch 22 - Loss: 0.6739084124565125 - Accuracy: 0.635\n",
      "Epoch 23 - Loss: 0.6749100685119629 - Accuracy: 0.661\n",
      "Epoch 24 - Loss: 0.6701996326446533 - Accuracy: 0.696\n",
      "Epoch 25 - Loss: 0.6686808466911316 - Accuracy: 0.661\n",
      "Epoch 26 - Loss: 0.6700738668441772 - Accuracy: 0.635\n",
      "Epoch 27 - Loss: 0.6702955961227417 - Accuracy: 0.635\n",
      "Epoch 28 - Loss: 0.6649911999702454 - Accuracy: 0.687\n",
      "Epoch 29 - Loss: 0.6604738235473633 - Accuracy: 0.722\n",
      "Epoch 30 - Loss: 0.658417284488678 - Accuracy: 0.730\n",
      "Epoch 31 - Loss: 0.6574084758758545 - Accuracy: 0.678\n",
      "Epoch 32 - Loss: 0.655906081199646 - Accuracy: 0.704\n",
      "Epoch 33 - Loss: 0.6489091515541077 - Accuracy: 0.722\n",
      "Epoch 34 - Loss: 0.640833854675293 - Accuracy: 0.748\n",
      "Epoch 35 - Loss: 0.6437737345695496 - Accuracy: 0.739\n",
      "Epoch 36 - Loss: 0.6386712193489075 - Accuracy: 0.739\n",
      "Epoch 37 - Loss: 0.6425346732139587 - Accuracy: 0.678\n",
      "Epoch 38 - Loss: 0.634884238243103 - Accuracy: 0.757\n",
      "Epoch 39 - Loss: 0.6275404691696167 - Accuracy: 0.722\n",
      "Epoch 40 - Loss: 0.6213387250900269 - Accuracy: 0.757\n",
      "Epoch 41 - Loss: 0.6254891157150269 - Accuracy: 0.696\n",
      "Epoch 42 - Loss: 0.6210001111030579 - Accuracy: 0.748\n",
      "Epoch 43 - Loss: 0.6250993609428406 - Accuracy: 0.704\n",
      "Epoch 44 - Loss: 0.6012389063835144 - Accuracy: 0.791\n",
      "Epoch 45 - Loss: 0.6045439839363098 - Accuracy: 0.739\n",
      "Epoch 46 - Loss: 0.5939626097679138 - Accuracy: 0.748\n",
      "Epoch 47 - Loss: 0.5952861905097961 - Accuracy: 0.765\n",
      "Epoch 48 - Loss: 0.5957915186882019 - Accuracy: 0.730\n",
      "Epoch 49 - Loss: 0.5822237133979797 - Accuracy: 0.783\n",
      "Epoch 50 - Loss: 0.5783399343490601 - Accuracy: 0.748\n",
      "Epoch 51 - Loss: 0.5772976279258728 - Accuracy: 0.722\n",
      "Epoch 52 - Loss: 0.5618039965629578 - Accuracy: 0.765\n",
      "Epoch 53 - Loss: 0.5520153045654297 - Accuracy: 0.765\n",
      "Epoch 54 - Loss: 0.5659776329994202 - Accuracy: 0.757\n",
      "Epoch 55 - Loss: 0.5473352074623108 - Accuracy: 0.783\n",
      "Epoch 56 - Loss: 0.5512440800666809 - Accuracy: 0.757\n",
      "Epoch 57 - Loss: 0.5433392524719238 - Accuracy: 0.748\n",
      "Epoch 58 - Loss: 0.5294692516326904 - Accuracy: 0.783\n",
      "Epoch 59 - Loss: 0.5131271481513977 - Accuracy: 0.774\n",
      "Epoch 60 - Loss: 0.5220575332641602 - Accuracy: 0.757\n",
      "Epoch 61 - Loss: 0.5021370649337769 - Accuracy: 0.791\n",
      "Epoch 62 - Loss: 0.5220783948898315 - Accuracy: 0.730\n",
      "Epoch 63 - Loss: 0.5041173696517944 - Accuracy: 0.748\n",
      "Epoch 64 - Loss: 0.4921311140060425 - Accuracy: 0.826\n",
      "Epoch 65 - Loss: 0.4876456558704376 - Accuracy: 0.791\n",
      "Epoch 66 - Loss: 0.47962522506713867 - Accuracy: 0.774\n",
      "Epoch 67 - Loss: 0.4816172420978546 - Accuracy: 0.800\n",
      "Epoch 68 - Loss: 0.4857804477214813 - Accuracy: 0.791\n",
      "Epoch 69 - Loss: 0.47690680623054504 - Accuracy: 0.791\n",
      "Epoch 70 - Loss: 0.4555261433124542 - Accuracy: 0.800\n",
      "Epoch 71 - Loss: 0.469666987657547 - Accuracy: 0.783\n",
      "Epoch 72 - Loss: 0.44921812415122986 - Accuracy: 0.809\n",
      "Epoch 73 - Loss: 0.45876842737197876 - Accuracy: 0.800\n",
      "Epoch 74 - Loss: 0.45314574241638184 - Accuracy: 0.809\n",
      "Epoch 75 - Loss: 0.44876882433891296 - Accuracy: 0.800\n",
      "Epoch 76 - Loss: 0.438010573387146 - Accuracy: 0.826\n",
      "Epoch 77 - Loss: 0.4396815001964569 - Accuracy: 0.852\n",
      "Epoch 78 - Loss: 0.4312905967235565 - Accuracy: 0.791\n",
      "Epoch 79 - Loss: 0.4056289792060852 - Accuracy: 0.800\n",
      "Epoch 80 - Loss: 0.4284099042415619 - Accuracy: 0.817\n",
      "Epoch 81 - Loss: 0.4129396378993988 - Accuracy: 0.809\n",
      "Epoch 82 - Loss: 0.402861088514328 - Accuracy: 0.817\n",
      "Epoch 83 - Loss: 0.4135655462741852 - Accuracy: 0.800\n",
      "Epoch 84 - Loss: 0.4064832031726837 - Accuracy: 0.835\n",
      "Epoch 85 - Loss: 0.39052021503448486 - Accuracy: 0.835\n",
      "Epoch 86 - Loss: 0.37807348370552063 - Accuracy: 0.861\n",
      "Epoch 87 - Loss: 0.3884347379207611 - Accuracy: 0.852\n",
      "Epoch 88 - Loss: 0.39492926001548767 - Accuracy: 0.843\n",
      "Epoch 89 - Loss: 0.3631014823913574 - Accuracy: 0.878\n",
      "Epoch 90 - Loss: 0.3708184063434601 - Accuracy: 0.835\n",
      "Epoch 91 - Loss: 0.39758798480033875 - Accuracy: 0.852\n",
      "Epoch 92 - Loss: 0.3726730942726135 - Accuracy: 0.861\n",
      "Epoch 93 - Loss: 0.3565042018890381 - Accuracy: 0.843\n",
      "Epoch 94 - Loss: 0.3523201048374176 - Accuracy: 0.870\n",
      "Epoch 95 - Loss: 0.3568846881389618 - Accuracy: 0.861\n",
      "Epoch 96 - Loss: 0.36605098843574524 - Accuracy: 0.843\n",
      "Epoch 97 - Loss: 0.3555555045604706 - Accuracy: 0.878\n",
      "Epoch 98 - Loss: 0.3546082079410553 - Accuracy: 0.852\n",
      "Epoch 99 - Loss: 0.35193926095962524 - Accuracy: 0.861\n",
      "MLP model test accuracy: 0.861\n",
      "Running MLP experiments on ('IRefIndex', 0) data\n",
      "Epoch 0 - Loss: 0.6946204900741577 - Accuracy: 0.479\n",
      "Epoch 1 - Loss: 0.6915464401245117 - Accuracy: 0.530\n",
      "Epoch 2 - Loss: 0.6935596466064453 - Accuracy: 0.470\n",
      "Epoch 3 - Loss: 0.689609944820404 - Accuracy: 0.564\n",
      "Epoch 4 - Loss: 0.6925008893013 - Accuracy: 0.487\n",
      "Epoch 5 - Loss: 0.6899832487106323 - Accuracy: 0.581\n",
      "Epoch 6 - Loss: 0.6860405802726746 - Accuracy: 0.675\n",
      "Epoch 7 - Loss: 0.6863653063774109 - Accuracy: 0.675\n",
      "Epoch 8 - Loss: 0.6844316720962524 - Accuracy: 0.684\n",
      "Epoch 9 - Loss: 0.6837653517723083 - Accuracy: 0.658\n",
      "Epoch 10 - Loss: 0.683533251285553 - Accuracy: 0.624\n",
      "Epoch 11 - Loss: 0.682791531085968 - Accuracy: 0.641\n",
      "Epoch 12 - Loss: 0.6790739297866821 - Accuracy: 0.701\n",
      "Epoch 13 - Loss: 0.6778773069381714 - Accuracy: 0.675\n",
      "Epoch 14 - Loss: 0.6788586974143982 - Accuracy: 0.641\n",
      "Epoch 15 - Loss: 0.6754159331321716 - Accuracy: 0.632\n",
      "Epoch 16 - Loss: 0.6805998682975769 - Accuracy: 0.650\n",
      "Epoch 17 - Loss: 0.6793996691703796 - Accuracy: 0.641\n",
      "Epoch 18 - Loss: 0.6715162396430969 - Accuracy: 0.650\n",
      "Epoch 19 - Loss: 0.6718898415565491 - Accuracy: 0.718\n",
      "Epoch 20 - Loss: 0.6674753427505493 - Accuracy: 0.658\n",
      "Epoch 21 - Loss: 0.6681317090988159 - Accuracy: 0.684\n",
      "Epoch 22 - Loss: 0.6675522923469543 - Accuracy: 0.675\n",
      "Epoch 23 - Loss: 0.6655680537223816 - Accuracy: 0.709\n",
      "Epoch 24 - Loss: 0.6651461720466614 - Accuracy: 0.718\n",
      "Epoch 25 - Loss: 0.6561430096626282 - Accuracy: 0.761\n",
      "Epoch 26 - Loss: 0.6605368256568909 - Accuracy: 0.726\n",
      "Epoch 27 - Loss: 0.6506677865982056 - Accuracy: 0.752\n",
      "Epoch 28 - Loss: 0.6465122103691101 - Accuracy: 0.778\n",
      "Epoch 29 - Loss: 0.6409376263618469 - Accuracy: 0.726\n",
      "Epoch 30 - Loss: 0.6463992595672607 - Accuracy: 0.761\n",
      "Epoch 31 - Loss: 0.6391655802726746 - Accuracy: 0.744\n",
      "Epoch 32 - Loss: 0.6426236033439636 - Accuracy: 0.718\n",
      "Epoch 33 - Loss: 0.6323332786560059 - Accuracy: 0.778\n",
      "Epoch 34 - Loss: 0.6313804984092712 - Accuracy: 0.778\n",
      "Epoch 35 - Loss: 0.6242432594299316 - Accuracy: 0.778\n",
      "Epoch 36 - Loss: 0.619702160358429 - Accuracy: 0.761\n",
      "Epoch 37 - Loss: 0.6188585758209229 - Accuracy: 0.803\n",
      "Epoch 38 - Loss: 0.6182339191436768 - Accuracy: 0.795\n",
      "Epoch 39 - Loss: 0.6114758849143982 - Accuracy: 0.795\n",
      "Epoch 40 - Loss: 0.6030473113059998 - Accuracy: 0.803\n",
      "Epoch 41 - Loss: 0.5992037057876587 - Accuracy: 0.803\n",
      "Epoch 42 - Loss: 0.5931422710418701 - Accuracy: 0.761\n",
      "Epoch 43 - Loss: 0.5972519516944885 - Accuracy: 0.803\n",
      "Epoch 44 - Loss: 0.5806857943534851 - Accuracy: 0.786\n",
      "Epoch 45 - Loss: 0.5829823613166809 - Accuracy: 0.786\n",
      "Epoch 46 - Loss: 0.5726621747016907 - Accuracy: 0.778\n",
      "Epoch 47 - Loss: 0.5626308917999268 - Accuracy: 0.778\n",
      "Epoch 48 - Loss: 0.5651134848594666 - Accuracy: 0.803\n",
      "Epoch 49 - Loss: 0.5355048179626465 - Accuracy: 0.812\n",
      "Epoch 50 - Loss: 0.5397472381591797 - Accuracy: 0.821\n",
      "Epoch 51 - Loss: 0.559567928314209 - Accuracy: 0.812\n",
      "Epoch 52 - Loss: 0.5439873933792114 - Accuracy: 0.786\n",
      "Epoch 53 - Loss: 0.530896008014679 - Accuracy: 0.803\n",
      "Epoch 54 - Loss: 0.5366796851158142 - Accuracy: 0.803\n",
      "Epoch 55 - Loss: 0.5159430503845215 - Accuracy: 0.821\n",
      "Epoch 56 - Loss: 0.5024164915084839 - Accuracy: 0.803\n",
      "Epoch 57 - Loss: 0.510270357131958 - Accuracy: 0.778\n",
      "Epoch 58 - Loss: 0.49476996064186096 - Accuracy: 0.821\n",
      "Epoch 59 - Loss: 0.48710447549819946 - Accuracy: 0.812\n",
      "Epoch 60 - Loss: 0.48623624444007874 - Accuracy: 0.829\n",
      "Epoch 61 - Loss: 0.47628822922706604 - Accuracy: 0.829\n",
      "Epoch 62 - Loss: 0.46803295612335205 - Accuracy: 0.812\n",
      "Epoch 63 - Loss: 0.4531422257423401 - Accuracy: 0.829\n",
      "Epoch 64 - Loss: 0.45952218770980835 - Accuracy: 0.838\n",
      "Epoch 65 - Loss: 0.44212207198143005 - Accuracy: 0.838\n",
      "Epoch 66 - Loss: 0.4623745381832123 - Accuracy: 0.838\n",
      "Epoch 67 - Loss: 0.43641188740730286 - Accuracy: 0.829\n",
      "Epoch 68 - Loss: 0.43675246834754944 - Accuracy: 0.821\n",
      "Epoch 69 - Loss: 0.42565470933914185 - Accuracy: 0.863\n",
      "Epoch 70 - Loss: 0.4261467158794403 - Accuracy: 0.855\n",
      "Epoch 71 - Loss: 0.418363094329834 - Accuracy: 0.872\n",
      "Epoch 72 - Loss: 0.40428847074508667 - Accuracy: 0.838\n",
      "Epoch 73 - Loss: 0.4090553820133209 - Accuracy: 0.855\n",
      "Epoch 74 - Loss: 0.3922390639781952 - Accuracy: 0.855\n",
      "Epoch 75 - Loss: 0.3848634362220764 - Accuracy: 0.872\n",
      "Epoch 76 - Loss: 0.3770577311515808 - Accuracy: 0.863\n",
      "Epoch 77 - Loss: 0.372419536113739 - Accuracy: 0.846\n",
      "Epoch 78 - Loss: 0.3793821930885315 - Accuracy: 0.846\n",
      "Epoch 79 - Loss: 0.37391409277915955 - Accuracy: 0.855\n",
      "Epoch 80 - Loss: 0.4050624668598175 - Accuracy: 0.829\n",
      "Epoch 81 - Loss: 0.3542051613330841 - Accuracy: 0.889\n",
      "Epoch 82 - Loss: 0.3612237572669983 - Accuracy: 0.872\n",
      "Epoch 83 - Loss: 0.35674911737442017 - Accuracy: 0.838\n",
      "Epoch 84 - Loss: 0.34303393959999084 - Accuracy: 0.872\n",
      "Epoch 85 - Loss: 0.3274231255054474 - Accuracy: 0.897\n",
      "Epoch 86 - Loss: 0.3148095905780792 - Accuracy: 0.906\n",
      "Epoch 87 - Loss: 0.3375634551048279 - Accuracy: 0.889\n",
      "Epoch 88 - Loss: 0.34280768036842346 - Accuracy: 0.855\n",
      "Epoch 89 - Loss: 0.33047568798065186 - Accuracy: 0.846\n",
      "Epoch 90 - Loss: 0.31895819306373596 - Accuracy: 0.872\n",
      "Epoch 91 - Loss: 0.3126370906829834 - Accuracy: 0.863\n",
      "Epoch 92 - Loss: 0.33559325337409973 - Accuracy: 0.863\n",
      "Epoch 93 - Loss: 0.30401745438575745 - Accuracy: 0.889\n",
      "Epoch 94 - Loss: 0.29233723878860474 - Accuracy: 0.923\n",
      "Epoch 95 - Loss: 0.3289240002632141 - Accuracy: 0.897\n",
      "Epoch 96 - Loss: 0.3097131550312042 - Accuracy: 0.889\n",
      "Epoch 97 - Loss: 0.27895310521125793 - Accuracy: 0.915\n",
      "Epoch 98 - Loss: 0.2772715389728546 - Accuracy: 0.915\n",
      "Epoch 99 - Loss: 0.2998904883861542 - Accuracy: 0.880\n",
      "MLP model test accuracy: 0.880\n",
      "Running MLP experiments on ('IRefIndex', 1) data\n",
      "Epoch 0 - Loss: 0.7052280902862549 - Accuracy: 0.496\n",
      "Epoch 1 - Loss: 0.7022339701652527 - Accuracy: 0.496\n",
      "Epoch 2 - Loss: 0.7022673487663269 - Accuracy: 0.496\n",
      "Epoch 3 - Loss: 0.7008988261222839 - Accuracy: 0.496\n",
      "Epoch 4 - Loss: 0.6980830430984497 - Accuracy: 0.496\n",
      "Epoch 5 - Loss: 0.694940447807312 - Accuracy: 0.496\n",
      "Epoch 6 - Loss: 0.6984902024269104 - Accuracy: 0.496\n",
      "Epoch 7 - Loss: 0.6953118443489075 - Accuracy: 0.496\n",
      "Epoch 8 - Loss: 0.6946967244148254 - Accuracy: 0.496\n",
      "Epoch 9 - Loss: 0.6881381869316101 - Accuracy: 0.496\n",
      "Epoch 10 - Loss: 0.6877941489219666 - Accuracy: 0.496\n",
      "Epoch 11 - Loss: 0.6865761280059814 - Accuracy: 0.496\n",
      "Epoch 12 - Loss: 0.6855877041816711 - Accuracy: 0.496\n",
      "Epoch 13 - Loss: 0.6850493550300598 - Accuracy: 0.496\n",
      "Epoch 14 - Loss: 0.6855757236480713 - Accuracy: 0.496\n",
      "Epoch 15 - Loss: 0.6824860572814941 - Accuracy: 0.496\n",
      "Epoch 16 - Loss: 0.6813148856163025 - Accuracy: 0.496\n",
      "Epoch 17 - Loss: 0.6815035939216614 - Accuracy: 0.513\n",
      "Epoch 18 - Loss: 0.6818315386772156 - Accuracy: 0.530\n",
      "Epoch 19 - Loss: 0.6783302426338196 - Accuracy: 0.530\n",
      "Epoch 20 - Loss: 0.6779734492301941 - Accuracy: 0.538\n",
      "Epoch 21 - Loss: 0.6752879619598389 - Accuracy: 0.564\n",
      "Epoch 22 - Loss: 0.6700475215911865 - Accuracy: 0.573\n",
      "Epoch 23 - Loss: 0.6697940230369568 - Accuracy: 0.581\n",
      "Epoch 24 - Loss: 0.6676170825958252 - Accuracy: 0.581\n",
      "Epoch 25 - Loss: 0.6651754379272461 - Accuracy: 0.607\n",
      "Epoch 26 - Loss: 0.661022961139679 - Accuracy: 0.615\n",
      "Epoch 27 - Loss: 0.6600501537322998 - Accuracy: 0.641\n",
      "Epoch 28 - Loss: 0.652026891708374 - Accuracy: 0.675\n",
      "Epoch 29 - Loss: 0.6513807773590088 - Accuracy: 0.701\n",
      "Epoch 30 - Loss: 0.6474972367286682 - Accuracy: 0.684\n",
      "Epoch 31 - Loss: 0.6499843597412109 - Accuracy: 0.709\n",
      "Epoch 32 - Loss: 0.6391802430152893 - Accuracy: 0.778\n",
      "Epoch 33 - Loss: 0.6450653076171875 - Accuracy: 0.718\n",
      "Epoch 34 - Loss: 0.6352987289428711 - Accuracy: 0.744\n",
      "Epoch 35 - Loss: 0.6292608976364136 - Accuracy: 0.786\n",
      "Epoch 36 - Loss: 0.6212788224220276 - Accuracy: 0.795\n",
      "Epoch 37 - Loss: 0.6202885508537292 - Accuracy: 0.821\n",
      "Epoch 38 - Loss: 0.6135355830192566 - Accuracy: 0.846\n",
      "Epoch 39 - Loss: 0.6122133135795593 - Accuracy: 0.838\n",
      "Epoch 40 - Loss: 0.6033271551132202 - Accuracy: 0.872\n",
      "Epoch 41 - Loss: 0.5983608365058899 - Accuracy: 0.838\n",
      "Epoch 42 - Loss: 0.5954835414886475 - Accuracy: 0.846\n",
      "Epoch 43 - Loss: 0.5857462286949158 - Accuracy: 0.872\n",
      "Epoch 44 - Loss: 0.5737042427062988 - Accuracy: 0.897\n",
      "Epoch 45 - Loss: 0.5757780075073242 - Accuracy: 0.838\n",
      "Epoch 46 - Loss: 0.5744458436965942 - Accuracy: 0.855\n",
      "Epoch 47 - Loss: 0.5575694441795349 - Accuracy: 0.897\n",
      "Epoch 48 - Loss: 0.5491264462471008 - Accuracy: 0.897\n",
      "Epoch 49 - Loss: 0.5491235852241516 - Accuracy: 0.829\n",
      "Epoch 50 - Loss: 0.5400530099868774 - Accuracy: 0.889\n",
      "Epoch 51 - Loss: 0.5253864526748657 - Accuracy: 0.897\n",
      "Epoch 52 - Loss: 0.527187168598175 - Accuracy: 0.872\n",
      "Epoch 53 - Loss: 0.5157235264778137 - Accuracy: 0.897\n",
      "Epoch 54 - Loss: 0.5111501812934875 - Accuracy: 0.897\n",
      "Epoch 55 - Loss: 0.5024405121803284 - Accuracy: 0.880\n",
      "Epoch 56 - Loss: 0.49055030941963196 - Accuracy: 0.897\n",
      "Epoch 57 - Loss: 0.48453494906425476 - Accuracy: 0.880\n",
      "Epoch 58 - Loss: 0.4714215397834778 - Accuracy: 0.889\n",
      "Epoch 59 - Loss: 0.46489202976226807 - Accuracy: 0.906\n",
      "Epoch 60 - Loss: 0.44783690571784973 - Accuracy: 0.897\n",
      "Epoch 61 - Loss: 0.45188212394714355 - Accuracy: 0.880\n",
      "Epoch 62 - Loss: 0.44448378682136536 - Accuracy: 0.889\n",
      "Epoch 63 - Loss: 0.43482646346092224 - Accuracy: 0.880\n",
      "Epoch 64 - Loss: 0.42853203415870667 - Accuracy: 0.932\n",
      "Epoch 65 - Loss: 0.41772761940956116 - Accuracy: 0.915\n",
      "Epoch 66 - Loss: 0.40939706563949585 - Accuracy: 0.889\n",
      "Epoch 67 - Loss: 0.4003891050815582 - Accuracy: 0.897\n",
      "Epoch 68 - Loss: 0.3803226053714752 - Accuracy: 0.915\n",
      "Epoch 69 - Loss: 0.3631494641304016 - Accuracy: 0.906\n",
      "Epoch 70 - Loss: 0.37883269786834717 - Accuracy: 0.897\n",
      "Epoch 71 - Loss: 0.37252911925315857 - Accuracy: 0.880\n",
      "Epoch 72 - Loss: 0.352251797914505 - Accuracy: 0.915\n",
      "Epoch 73 - Loss: 0.3644229471683502 - Accuracy: 0.863\n",
      "Epoch 74 - Loss: 0.3373943269252777 - Accuracy: 0.915\n",
      "Epoch 75 - Loss: 0.3309488296508789 - Accuracy: 0.897\n",
      "Epoch 76 - Loss: 0.325440376996994 - Accuracy: 0.906\n",
      "Epoch 77 - Loss: 0.3186444044113159 - Accuracy: 0.915\n",
      "Epoch 78 - Loss: 0.3144499957561493 - Accuracy: 0.915\n",
      "Epoch 79 - Loss: 0.3066689074039459 - Accuracy: 0.906\n",
      "Epoch 80 - Loss: 0.28735581040382385 - Accuracy: 0.923\n",
      "Epoch 81 - Loss: 0.28925642371177673 - Accuracy: 0.915\n",
      "Epoch 82 - Loss: 0.2728751599788666 - Accuracy: 0.940\n",
      "Epoch 83 - Loss: 0.28179141879081726 - Accuracy: 0.915\n",
      "Epoch 84 - Loss: 0.29994750022888184 - Accuracy: 0.897\n",
      "Epoch 85 - Loss: 0.2783198356628418 - Accuracy: 0.915\n",
      "Epoch 86 - Loss: 0.26233798265457153 - Accuracy: 0.915\n",
      "Epoch 87 - Loss: 0.26312828063964844 - Accuracy: 0.915\n",
      "Epoch 88 - Loss: 0.26241928339004517 - Accuracy: 0.932\n",
      "Epoch 89 - Loss: 0.23569300770759583 - Accuracy: 0.923\n",
      "Epoch 90 - Loss: 0.245638906955719 - Accuracy: 0.949\n",
      "Epoch 91 - Loss: 0.23380865156650543 - Accuracy: 0.949\n",
      "Epoch 92 - Loss: 0.22387294471263885 - Accuracy: 0.949\n",
      "Epoch 93 - Loss: 0.22180518507957458 - Accuracy: 0.949\n",
      "Epoch 94 - Loss: 0.23978295922279358 - Accuracy: 0.923\n",
      "Epoch 95 - Loss: 0.22986824810504913 - Accuracy: 0.966\n",
      "Epoch 96 - Loss: 0.22463706135749817 - Accuracy: 0.915\n",
      "Epoch 97 - Loss: 0.2133665829896927 - Accuracy: 0.915\n",
      "Epoch 98 - Loss: 0.20118235051631927 - Accuracy: 0.949\n",
      "Epoch 99 - Loss: 0.1973164975643158 - Accuracy: 0.949\n",
      "MLP model test accuracy: 0.949\n",
      "Running MLP experiments on ('IRefIndex', 2) data\n",
      "Epoch 0 - Loss: 0.7044007182121277 - Accuracy: 0.504\n",
      "Epoch 1 - Loss: 0.7050628662109375 - Accuracy: 0.504\n",
      "Epoch 2 - Loss: 0.7021436095237732 - Accuracy: 0.504\n",
      "Epoch 3 - Loss: 0.7006269693374634 - Accuracy: 0.504\n",
      "Epoch 4 - Loss: 0.7007078528404236 - Accuracy: 0.504\n",
      "Epoch 5 - Loss: 0.6994927525520325 - Accuracy: 0.504\n",
      "Epoch 6 - Loss: 0.6974875926971436 - Accuracy: 0.504\n",
      "Epoch 7 - Loss: 0.6959913969039917 - Accuracy: 0.504\n",
      "Epoch 8 - Loss: 0.6950330138206482 - Accuracy: 0.504\n",
      "Epoch 9 - Loss: 0.6931076645851135 - Accuracy: 0.504\n",
      "Epoch 10 - Loss: 0.6947914958000183 - Accuracy: 0.504\n",
      "Epoch 11 - Loss: 0.6910333633422852 - Accuracy: 0.504\n",
      "Epoch 12 - Loss: 0.69254070520401 - Accuracy: 0.504\n",
      "Epoch 13 - Loss: 0.690570056438446 - Accuracy: 0.504\n",
      "Epoch 14 - Loss: 0.6873334646224976 - Accuracy: 0.504\n",
      "Epoch 15 - Loss: 0.6872512102127075 - Accuracy: 0.504\n",
      "Epoch 16 - Loss: 0.685775101184845 - Accuracy: 0.504\n",
      "Epoch 17 - Loss: 0.6828999519348145 - Accuracy: 0.504\n",
      "Epoch 18 - Loss: 0.6817238330841064 - Accuracy: 0.513\n",
      "Epoch 19 - Loss: 0.6830436587333679 - Accuracy: 0.538\n",
      "Epoch 20 - Loss: 0.6799963116645813 - Accuracy: 0.538\n",
      "Epoch 21 - Loss: 0.6785431504249573 - Accuracy: 0.538\n",
      "Epoch 22 - Loss: 0.6777783632278442 - Accuracy: 0.530\n",
      "Epoch 23 - Loss: 0.6768474578857422 - Accuracy: 0.538\n",
      "Epoch 24 - Loss: 0.6733479499816895 - Accuracy: 0.573\n",
      "Epoch 25 - Loss: 0.6669116616249084 - Accuracy: 0.615\n",
      "Epoch 26 - Loss: 0.6670435070991516 - Accuracy: 0.581\n",
      "Epoch 27 - Loss: 0.6662206649780273 - Accuracy: 0.581\n",
      "Epoch 28 - Loss: 0.6629624962806702 - Accuracy: 0.615\n",
      "Epoch 29 - Loss: 0.6607508063316345 - Accuracy: 0.615\n",
      "Epoch 30 - Loss: 0.6568247675895691 - Accuracy: 0.615\n",
      "Epoch 31 - Loss: 0.6516073346138 - Accuracy: 0.667\n",
      "Epoch 32 - Loss: 0.6477138996124268 - Accuracy: 0.632\n",
      "Epoch 33 - Loss: 0.6450899839401245 - Accuracy: 0.701\n",
      "Epoch 34 - Loss: 0.6365709900856018 - Accuracy: 0.701\n",
      "Epoch 35 - Loss: 0.6427448987960815 - Accuracy: 0.624\n",
      "Epoch 36 - Loss: 0.6401945352554321 - Accuracy: 0.684\n",
      "Epoch 37 - Loss: 0.635235071182251 - Accuracy: 0.675\n",
      "Epoch 38 - Loss: 0.6255362033843994 - Accuracy: 0.718\n",
      "Epoch 39 - Loss: 0.625454843044281 - Accuracy: 0.726\n",
      "Epoch 40 - Loss: 0.6237867474555969 - Accuracy: 0.701\n",
      "Epoch 41 - Loss: 0.6126556992530823 - Accuracy: 0.726\n",
      "Epoch 42 - Loss: 0.61107337474823 - Accuracy: 0.675\n",
      "Epoch 43 - Loss: 0.6111721992492676 - Accuracy: 0.752\n",
      "Epoch 44 - Loss: 0.6095051765441895 - Accuracy: 0.718\n",
      "Epoch 45 - Loss: 0.6006439328193665 - Accuracy: 0.718\n",
      "Epoch 46 - Loss: 0.5911614298820496 - Accuracy: 0.769\n",
      "Epoch 47 - Loss: 0.5840030312538147 - Accuracy: 0.744\n",
      "Epoch 48 - Loss: 0.5870432257652283 - Accuracy: 0.718\n",
      "Epoch 49 - Loss: 0.5838316679000854 - Accuracy: 0.735\n",
      "Epoch 50 - Loss: 0.5837645530700684 - Accuracy: 0.735\n",
      "Epoch 51 - Loss: 0.5737870931625366 - Accuracy: 0.726\n",
      "Epoch 52 - Loss: 0.5602970123291016 - Accuracy: 0.761\n",
      "Epoch 53 - Loss: 0.5595545768737793 - Accuracy: 0.744\n",
      "Epoch 54 - Loss: 0.5414844751358032 - Accuracy: 0.769\n",
      "Epoch 55 - Loss: 0.5504607558250427 - Accuracy: 0.718\n",
      "Epoch 56 - Loss: 0.5371108055114746 - Accuracy: 0.761\n",
      "Epoch 57 - Loss: 0.5342562794685364 - Accuracy: 0.769\n",
      "Epoch 58 - Loss: 0.5261346697807312 - Accuracy: 0.778\n",
      "Epoch 59 - Loss: 0.517981231212616 - Accuracy: 0.761\n",
      "Epoch 60 - Loss: 0.5217893719673157 - Accuracy: 0.752\n",
      "Epoch 61 - Loss: 0.5030869245529175 - Accuracy: 0.786\n",
      "Epoch 62 - Loss: 0.5136950016021729 - Accuracy: 0.761\n",
      "Epoch 63 - Loss: 0.50047367811203 - Accuracy: 0.803\n",
      "Epoch 64 - Loss: 0.4775984585285187 - Accuracy: 0.786\n",
      "Epoch 65 - Loss: 0.48928698897361755 - Accuracy: 0.778\n",
      "Epoch 66 - Loss: 0.4641238749027252 - Accuracy: 0.778\n",
      "Epoch 67 - Loss: 0.474080890417099 - Accuracy: 0.778\n",
      "Epoch 68 - Loss: 0.4659869968891144 - Accuracy: 0.821\n",
      "Epoch 69 - Loss: 0.45744916796684265 - Accuracy: 0.786\n",
      "Epoch 70 - Loss: 0.4619899094104767 - Accuracy: 0.769\n",
      "Epoch 71 - Loss: 0.45133253931999207 - Accuracy: 0.769\n",
      "Epoch 72 - Loss: 0.4498143792152405 - Accuracy: 0.769\n",
      "Epoch 73 - Loss: 0.446355938911438 - Accuracy: 0.769\n",
      "Epoch 74 - Loss: 0.428280234336853 - Accuracy: 0.803\n",
      "Epoch 75 - Loss: 0.4326329827308655 - Accuracy: 0.829\n",
      "Epoch 76 - Loss: 0.43410706520080566 - Accuracy: 0.803\n",
      "Epoch 77 - Loss: 0.4346010684967041 - Accuracy: 0.778\n",
      "Epoch 78 - Loss: 0.4164413809776306 - Accuracy: 0.803\n",
      "Epoch 79 - Loss: 0.40669548511505127 - Accuracy: 0.803\n",
      "Epoch 80 - Loss: 0.40814971923828125 - Accuracy: 0.795\n",
      "Epoch 81 - Loss: 0.39846959710121155 - Accuracy: 0.846\n",
      "Epoch 82 - Loss: 0.3868251442909241 - Accuracy: 0.829\n",
      "Epoch 83 - Loss: 0.3866555690765381 - Accuracy: 0.803\n",
      "Epoch 84 - Loss: 0.3914753198623657 - Accuracy: 0.821\n",
      "Epoch 85 - Loss: 0.39038604497909546 - Accuracy: 0.838\n",
      "Epoch 86 - Loss: 0.3857722580432892 - Accuracy: 0.812\n",
      "Epoch 87 - Loss: 0.3797222673892975 - Accuracy: 0.855\n",
      "Epoch 88 - Loss: 0.34678125381469727 - Accuracy: 0.863\n",
      "Epoch 89 - Loss: 0.3580222427845001 - Accuracy: 0.829\n",
      "Epoch 90 - Loss: 0.37291499972343445 - Accuracy: 0.829\n",
      "Epoch 91 - Loss: 0.375795841217041 - Accuracy: 0.829\n",
      "Epoch 92 - Loss: 0.3476454019546509 - Accuracy: 0.855\n",
      "Epoch 93 - Loss: 0.33442091941833496 - Accuracy: 0.863\n",
      "Epoch 94 - Loss: 0.34744301438331604 - Accuracy: 0.855\n",
      "Epoch 95 - Loss: 0.3289286196231842 - Accuracy: 0.855\n",
      "Epoch 96 - Loss: 0.3429096043109894 - Accuracy: 0.838\n",
      "Epoch 97 - Loss: 0.32652583718299866 - Accuracy: 0.855\n",
      "Epoch 98 - Loss: 0.3362955152988434 - Accuracy: 0.838\n",
      "Epoch 99 - Loss: 0.30391353368759155 - Accuracy: 0.872\n",
      "MLP model test accuracy: 0.872\n",
      "Running MLP experiments on ('IRefIndex_2015', 0) data\n",
      "Epoch 0 - Loss: 0.7019173502922058 - Accuracy: 0.505\n",
      "Epoch 1 - Loss: 0.6985294222831726 - Accuracy: 0.505\n",
      "Epoch 2 - Loss: 0.6990548968315125 - Accuracy: 0.505\n",
      "Epoch 3 - Loss: 0.6961314082145691 - Accuracy: 0.505\n",
      "Epoch 4 - Loss: 0.6985759735107422 - Accuracy: 0.505\n",
      "Epoch 5 - Loss: 0.695633590221405 - Accuracy: 0.505\n",
      "Epoch 6 - Loss: 0.6944211721420288 - Accuracy: 0.505\n",
      "Epoch 7 - Loss: 0.6940121054649353 - Accuracy: 0.505\n",
      "Epoch 8 - Loss: 0.6908398866653442 - Accuracy: 0.505\n",
      "Epoch 9 - Loss: 0.6909219026565552 - Accuracy: 0.505\n",
      "Epoch 10 - Loss: 0.6898863315582275 - Accuracy: 0.505\n",
      "Epoch 11 - Loss: 0.6857650876045227 - Accuracy: 0.505\n",
      "Epoch 12 - Loss: 0.6861825585365295 - Accuracy: 0.505\n",
      "Epoch 13 - Loss: 0.684030294418335 - Accuracy: 0.505\n",
      "Epoch 14 - Loss: 0.686259388923645 - Accuracy: 0.505\n",
      "Epoch 15 - Loss: 0.6851919889450073 - Accuracy: 0.542\n",
      "Epoch 16 - Loss: 0.685602605342865 - Accuracy: 0.514\n",
      "Epoch 17 - Loss: 0.6806699633598328 - Accuracy: 0.523\n",
      "Epoch 18 - Loss: 0.681161105632782 - Accuracy: 0.523\n",
      "Epoch 19 - Loss: 0.6727331280708313 - Accuracy: 0.542\n",
      "Epoch 20 - Loss: 0.6761707067489624 - Accuracy: 0.551\n",
      "Epoch 21 - Loss: 0.6700594425201416 - Accuracy: 0.570\n",
      "Epoch 22 - Loss: 0.6704531311988831 - Accuracy: 0.589\n",
      "Epoch 23 - Loss: 0.6697661280632019 - Accuracy: 0.579\n",
      "Epoch 24 - Loss: 0.6605298519134521 - Accuracy: 0.664\n",
      "Epoch 25 - Loss: 0.667903482913971 - Accuracy: 0.570\n",
      "Epoch 26 - Loss: 0.6608707308769226 - Accuracy: 0.617\n",
      "Epoch 27 - Loss: 0.662082850933075 - Accuracy: 0.617\n",
      "Epoch 28 - Loss: 0.6542255282402039 - Accuracy: 0.673\n",
      "Epoch 29 - Loss: 0.6527410745620728 - Accuracy: 0.729\n",
      "Epoch 30 - Loss: 0.646873414516449 - Accuracy: 0.785\n",
      "Epoch 31 - Loss: 0.642648458480835 - Accuracy: 0.701\n",
      "Epoch 32 - Loss: 0.6443426012992859 - Accuracy: 0.729\n",
      "Epoch 33 - Loss: 0.645099937915802 - Accuracy: 0.701\n",
      "Epoch 34 - Loss: 0.6449719667434692 - Accuracy: 0.645\n",
      "Epoch 35 - Loss: 0.6433799266815186 - Accuracy: 0.673\n",
      "Epoch 36 - Loss: 0.6359931826591492 - Accuracy: 0.766\n",
      "Epoch 37 - Loss: 0.6304706931114197 - Accuracy: 0.757\n",
      "Epoch 38 - Loss: 0.6278814673423767 - Accuracy: 0.757\n",
      "Epoch 39 - Loss: 0.6176912784576416 - Accuracy: 0.757\n",
      "Epoch 40 - Loss: 0.6179286241531372 - Accuracy: 0.776\n",
      "Epoch 41 - Loss: 0.6141337752342224 - Accuracy: 0.757\n",
      "Epoch 42 - Loss: 0.6022252440452576 - Accuracy: 0.785\n",
      "Epoch 43 - Loss: 0.61146080493927 - Accuracy: 0.776\n",
      "Epoch 44 - Loss: 0.6085456013679504 - Accuracy: 0.766\n",
      "Epoch 45 - Loss: 0.5982033014297485 - Accuracy: 0.729\n",
      "Epoch 46 - Loss: 0.5819646716117859 - Accuracy: 0.785\n",
      "Epoch 47 - Loss: 0.5969581604003906 - Accuracy: 0.729\n",
      "Epoch 48 - Loss: 0.5898633003234863 - Accuracy: 0.794\n",
      "Epoch 49 - Loss: 0.5672932863235474 - Accuracy: 0.785\n",
      "Epoch 50 - Loss: 0.5706524848937988 - Accuracy: 0.776\n",
      "Epoch 51 - Loss: 0.5585992336273193 - Accuracy: 0.794\n",
      "Epoch 52 - Loss: 0.5659390091896057 - Accuracy: 0.785\n",
      "Epoch 53 - Loss: 0.5528872013092041 - Accuracy: 0.813\n",
      "Epoch 54 - Loss: 0.5437259078025818 - Accuracy: 0.776\n",
      "Epoch 55 - Loss: 0.5256390571594238 - Accuracy: 0.822\n",
      "Epoch 56 - Loss: 0.5314131379127502 - Accuracy: 0.785\n",
      "Epoch 57 - Loss: 0.5298555493354797 - Accuracy: 0.794\n",
      "Epoch 58 - Loss: 0.5226151943206787 - Accuracy: 0.794\n",
      "Epoch 59 - Loss: 0.515258252620697 - Accuracy: 0.766\n",
      "Epoch 60 - Loss: 0.5021690726280212 - Accuracy: 0.841\n",
      "Epoch 61 - Loss: 0.5043632388114929 - Accuracy: 0.757\n",
      "Epoch 62 - Loss: 0.4993898570537567 - Accuracy: 0.794\n",
      "Epoch 63 - Loss: 0.5040950179100037 - Accuracy: 0.813\n",
      "Epoch 64 - Loss: 0.4897381365299225 - Accuracy: 0.785\n",
      "Epoch 65 - Loss: 0.47204455733299255 - Accuracy: 0.804\n",
      "Epoch 66 - Loss: 0.4672333896160126 - Accuracy: 0.822\n",
      "Epoch 67 - Loss: 0.46408194303512573 - Accuracy: 0.804\n",
      "Epoch 68 - Loss: 0.4675932228565216 - Accuracy: 0.813\n",
      "Epoch 69 - Loss: 0.45099809765815735 - Accuracy: 0.804\n",
      "Epoch 70 - Loss: 0.4403018057346344 - Accuracy: 0.794\n",
      "Epoch 71 - Loss: 0.44636666774749756 - Accuracy: 0.794\n",
      "Epoch 72 - Loss: 0.44483545422554016 - Accuracy: 0.832\n",
      "Epoch 73 - Loss: 0.44152989983558655 - Accuracy: 0.841\n",
      "Epoch 74 - Loss: 0.43417128920555115 - Accuracy: 0.869\n",
      "Epoch 75 - Loss: 0.41962847113609314 - Accuracy: 0.822\n",
      "Epoch 76 - Loss: 0.4204704761505127 - Accuracy: 0.841\n",
      "Epoch 77 - Loss: 0.4041506052017212 - Accuracy: 0.869\n",
      "Epoch 78 - Loss: 0.40894582867622375 - Accuracy: 0.860\n",
      "Epoch 79 - Loss: 0.4019106328487396 - Accuracy: 0.841\n",
      "Epoch 80 - Loss: 0.419122576713562 - Accuracy: 0.850\n",
      "Epoch 81 - Loss: 0.39931559562683105 - Accuracy: 0.832\n",
      "Epoch 82 - Loss: 0.39296284317970276 - Accuracy: 0.860\n",
      "Epoch 83 - Loss: 0.39071890711784363 - Accuracy: 0.869\n",
      "Epoch 84 - Loss: 0.3814789354801178 - Accuracy: 0.850\n",
      "Epoch 85 - Loss: 0.3788318932056427 - Accuracy: 0.850\n",
      "Epoch 86 - Loss: 0.35287603735923767 - Accuracy: 0.869\n",
      "Epoch 87 - Loss: 0.3931806981563568 - Accuracy: 0.860\n",
      "Epoch 88 - Loss: 0.377240926027298 - Accuracy: 0.850\n",
      "Epoch 89 - Loss: 0.37018272280693054 - Accuracy: 0.841\n",
      "Epoch 90 - Loss: 0.3997275233268738 - Accuracy: 0.832\n",
      "Epoch 91 - Loss: 0.3583615720272064 - Accuracy: 0.860\n",
      "Epoch 92 - Loss: 0.3612549304962158 - Accuracy: 0.860\n",
      "Epoch 93 - Loss: 0.3572530746459961 - Accuracy: 0.888\n",
      "Epoch 94 - Loss: 0.33246052265167236 - Accuracy: 0.869\n",
      "Epoch 95 - Loss: 0.3474920690059662 - Accuracy: 0.897\n",
      "Epoch 96 - Loss: 0.33285075426101685 - Accuracy: 0.888\n",
      "Epoch 97 - Loss: 0.33285266160964966 - Accuracy: 0.860\n",
      "Epoch 98 - Loss: 0.3420090079307556 - Accuracy: 0.879\n",
      "Epoch 99 - Loss: 0.34461989998817444 - Accuracy: 0.860\n",
      "MLP model test accuracy: 0.860\n",
      "Running MLP experiments on ('IRefIndex_2015', 1) data\n",
      "Epoch 0 - Loss: 0.6978006362915039 - Accuracy: 0.505\n",
      "Epoch 1 - Loss: 0.6925825476646423 - Accuracy: 0.505\n",
      "Epoch 2 - Loss: 0.6939775943756104 - Accuracy: 0.505\n",
      "Epoch 3 - Loss: 0.6936733722686768 - Accuracy: 0.505\n",
      "Epoch 4 - Loss: 0.6923679113388062 - Accuracy: 0.505\n",
      "Epoch 5 - Loss: 0.6909821629524231 - Accuracy: 0.505\n",
      "Epoch 6 - Loss: 0.6911417245864868 - Accuracy: 0.505\n",
      "Epoch 7 - Loss: 0.6906353831291199 - Accuracy: 0.533\n",
      "Epoch 8 - Loss: 0.6907122731208801 - Accuracy: 0.505\n",
      "Epoch 9 - Loss: 0.6877805590629578 - Accuracy: 0.533\n",
      "Epoch 10 - Loss: 0.689132571220398 - Accuracy: 0.551\n",
      "Epoch 11 - Loss: 0.6861245036125183 - Accuracy: 0.570\n",
      "Epoch 12 - Loss: 0.682424783706665 - Accuracy: 0.626\n",
      "Epoch 13 - Loss: 0.6860626339912415 - Accuracy: 0.607\n",
      "Epoch 14 - Loss: 0.6828158497810364 - Accuracy: 0.664\n",
      "Epoch 15 - Loss: 0.6861907243728638 - Accuracy: 0.617\n",
      "Epoch 16 - Loss: 0.6829849481582642 - Accuracy: 0.673\n",
      "Epoch 17 - Loss: 0.6790673732757568 - Accuracy: 0.710\n",
      "Epoch 18 - Loss: 0.6747682094573975 - Accuracy: 0.776\n",
      "Epoch 19 - Loss: 0.6736444234848022 - Accuracy: 0.710\n",
      "Epoch 20 - Loss: 0.67380690574646 - Accuracy: 0.776\n",
      "Epoch 21 - Loss: 0.6746858358383179 - Accuracy: 0.692\n",
      "Epoch 22 - Loss: 0.6722630858421326 - Accuracy: 0.729\n",
      "Epoch 23 - Loss: 0.6685812473297119 - Accuracy: 0.766\n",
      "Epoch 24 - Loss: 0.6694525480270386 - Accuracy: 0.729\n",
      "Epoch 25 - Loss: 0.6660558581352234 - Accuracy: 0.748\n",
      "Epoch 26 - Loss: 0.6624239087104797 - Accuracy: 0.748\n",
      "Epoch 27 - Loss: 0.6628544330596924 - Accuracy: 0.738\n",
      "Epoch 28 - Loss: 0.6592125296592712 - Accuracy: 0.785\n",
      "Epoch 29 - Loss: 0.6560121178627014 - Accuracy: 0.766\n",
      "Epoch 30 - Loss: 0.6549410223960876 - Accuracy: 0.757\n",
      "Epoch 31 - Loss: 0.6524401307106018 - Accuracy: 0.776\n",
      "Epoch 32 - Loss: 0.6480700969696045 - Accuracy: 0.766\n",
      "Epoch 33 - Loss: 0.6403114795684814 - Accuracy: 0.776\n",
      "Epoch 34 - Loss: 0.6439854502677917 - Accuracy: 0.738\n",
      "Epoch 35 - Loss: 0.6404651999473572 - Accuracy: 0.757\n",
      "Epoch 36 - Loss: 0.6374761462211609 - Accuracy: 0.738\n",
      "Epoch 37 - Loss: 0.629535436630249 - Accuracy: 0.776\n",
      "Epoch 38 - Loss: 0.6246857047080994 - Accuracy: 0.766\n",
      "Epoch 39 - Loss: 0.6194220781326294 - Accuracy: 0.785\n",
      "Epoch 40 - Loss: 0.62452632188797 - Accuracy: 0.738\n",
      "Epoch 41 - Loss: 0.6229570508003235 - Accuracy: 0.748\n",
      "Epoch 42 - Loss: 0.612589418888092 - Accuracy: 0.776\n",
      "Epoch 43 - Loss: 0.6030891537666321 - Accuracy: 0.757\n",
      "Epoch 44 - Loss: 0.6016567349433899 - Accuracy: 0.766\n",
      "Epoch 45 - Loss: 0.6008456945419312 - Accuracy: 0.766\n",
      "Epoch 46 - Loss: 0.5895897150039673 - Accuracy: 0.794\n",
      "Epoch 47 - Loss: 0.5718014240264893 - Accuracy: 0.822\n",
      "Epoch 48 - Loss: 0.5743235945701599 - Accuracy: 0.776\n",
      "Epoch 49 - Loss: 0.5739622116088867 - Accuracy: 0.813\n",
      "Epoch 50 - Loss: 0.565470278263092 - Accuracy: 0.813\n",
      "Epoch 51 - Loss: 0.5643624067306519 - Accuracy: 0.776\n",
      "Epoch 52 - Loss: 0.5623599886894226 - Accuracy: 0.785\n",
      "Epoch 53 - Loss: 0.5503091812133789 - Accuracy: 0.822\n",
      "Epoch 54 - Loss: 0.5382034182548523 - Accuracy: 0.804\n",
      "Epoch 55 - Loss: 0.5214560031890869 - Accuracy: 0.869\n",
      "Epoch 56 - Loss: 0.5155710577964783 - Accuracy: 0.850\n",
      "Epoch 57 - Loss: 0.527470588684082 - Accuracy: 0.841\n",
      "Epoch 58 - Loss: 0.5174142122268677 - Accuracy: 0.785\n",
      "Epoch 59 - Loss: 0.5141149759292603 - Accuracy: 0.822\n",
      "Epoch 60 - Loss: 0.49112316966056824 - Accuracy: 0.841\n",
      "Epoch 61 - Loss: 0.4850194752216339 - Accuracy: 0.841\n",
      "Epoch 62 - Loss: 0.4978157877922058 - Accuracy: 0.822\n",
      "Epoch 63 - Loss: 0.4827462434768677 - Accuracy: 0.832\n",
      "Epoch 64 - Loss: 0.4738865792751312 - Accuracy: 0.841\n",
      "Epoch 65 - Loss: 0.4616283178329468 - Accuracy: 0.850\n",
      "Epoch 66 - Loss: 0.47037041187286377 - Accuracy: 0.804\n",
      "Epoch 67 - Loss: 0.461460679769516 - Accuracy: 0.841\n",
      "Epoch 68 - Loss: 0.4607359766960144 - Accuracy: 0.822\n",
      "Epoch 69 - Loss: 0.44267600774765015 - Accuracy: 0.832\n",
      "Epoch 70 - Loss: 0.433493047952652 - Accuracy: 0.869\n",
      "Epoch 71 - Loss: 0.42115581035614014 - Accuracy: 0.860\n",
      "Epoch 72 - Loss: 0.40681299567222595 - Accuracy: 0.860\n",
      "Epoch 73 - Loss: 0.40678083896636963 - Accuracy: 0.841\n",
      "Epoch 74 - Loss: 0.3991588056087494 - Accuracy: 0.860\n",
      "Epoch 75 - Loss: 0.40016788244247437 - Accuracy: 0.860\n",
      "Epoch 76 - Loss: 0.41130805015563965 - Accuracy: 0.869\n",
      "Epoch 77 - Loss: 0.3932940363883972 - Accuracy: 0.897\n",
      "Epoch 78 - Loss: 0.39219388365745544 - Accuracy: 0.860\n",
      "Epoch 79 - Loss: 0.3643260896205902 - Accuracy: 0.916\n",
      "Epoch 80 - Loss: 0.3590838313102722 - Accuracy: 0.879\n",
      "Epoch 81 - Loss: 0.38272273540496826 - Accuracy: 0.869\n",
      "Epoch 82 - Loss: 0.34565702080726624 - Accuracy: 0.925\n",
      "Epoch 83 - Loss: 0.36170196533203125 - Accuracy: 0.879\n",
      "Epoch 84 - Loss: 0.35187727212905884 - Accuracy: 0.888\n",
      "Epoch 85 - Loss: 0.3433005213737488 - Accuracy: 0.916\n",
      "Epoch 86 - Loss: 0.3280368745326996 - Accuracy: 0.907\n",
      "Epoch 87 - Loss: 0.3250877559185028 - Accuracy: 0.916\n",
      "Epoch 88 - Loss: 0.3360756039619446 - Accuracy: 0.897\n",
      "Epoch 89 - Loss: 0.3334678113460541 - Accuracy: 0.897\n",
      "Epoch 90 - Loss: 0.34540000557899475 - Accuracy: 0.888\n",
      "Epoch 91 - Loss: 0.30463144183158875 - Accuracy: 0.935\n",
      "Epoch 92 - Loss: 0.31361159682273865 - Accuracy: 0.907\n",
      "Epoch 93 - Loss: 0.32571807503700256 - Accuracy: 0.897\n",
      "Epoch 94 - Loss: 0.3053379952907562 - Accuracy: 0.907\n",
      "Epoch 95 - Loss: 0.28541380167007446 - Accuracy: 0.916\n",
      "Epoch 96 - Loss: 0.3079504668712616 - Accuracy: 0.916\n",
      "Epoch 97 - Loss: 0.2779944837093353 - Accuracy: 0.944\n",
      "Epoch 98 - Loss: 0.3148612380027771 - Accuracy: 0.907\n",
      "Epoch 99 - Loss: 0.29228758811950684 - Accuracy: 0.907\n",
      "MLP model test accuracy: 0.907\n",
      "Running MLP experiments on ('IRefIndex_2015', 2) data\n",
      "Epoch 0 - Loss: 0.7002559900283813 - Accuracy: 0.505\n",
      "Epoch 1 - Loss: 0.6977069973945618 - Accuracy: 0.505\n",
      "Epoch 2 - Loss: 0.6975634694099426 - Accuracy: 0.505\n",
      "Epoch 3 - Loss: 0.6972827315330505 - Accuracy: 0.505\n",
      "Epoch 4 - Loss: 0.6938813328742981 - Accuracy: 0.505\n",
      "Epoch 5 - Loss: 0.6948161721229553 - Accuracy: 0.505\n",
      "Epoch 6 - Loss: 0.6930640339851379 - Accuracy: 0.505\n",
      "Epoch 7 - Loss: 0.6920506954193115 - Accuracy: 0.505\n",
      "Epoch 8 - Loss: 0.6902601718902588 - Accuracy: 0.505\n",
      "Epoch 9 - Loss: 0.6875174045562744 - Accuracy: 0.505\n",
      "Epoch 10 - Loss: 0.6887165904045105 - Accuracy: 0.514\n",
      "Epoch 11 - Loss: 0.6868020296096802 - Accuracy: 0.505\n",
      "Epoch 12 - Loss: 0.6837688684463501 - Accuracy: 0.514\n",
      "Epoch 13 - Loss: 0.6809614896774292 - Accuracy: 0.533\n",
      "Epoch 14 - Loss: 0.6834700107574463 - Accuracy: 0.533\n",
      "Epoch 15 - Loss: 0.6797582507133484 - Accuracy: 0.542\n",
      "Epoch 16 - Loss: 0.6760068535804749 - Accuracy: 0.551\n",
      "Epoch 17 - Loss: 0.6731098294258118 - Accuracy: 0.570\n",
      "Epoch 18 - Loss: 0.6752690076828003 - Accuracy: 0.561\n",
      "Epoch 19 - Loss: 0.6705464124679565 - Accuracy: 0.598\n",
      "Epoch 20 - Loss: 0.6700581908226013 - Accuracy: 0.579\n",
      "Epoch 21 - Loss: 0.6648553609848022 - Accuracy: 0.626\n",
      "Epoch 22 - Loss: 0.6611354947090149 - Accuracy: 0.664\n",
      "Epoch 23 - Loss: 0.6595346927642822 - Accuracy: 0.636\n",
      "Epoch 24 - Loss: 0.6585052609443665 - Accuracy: 0.626\n",
      "Epoch 25 - Loss: 0.652181088924408 - Accuracy: 0.664\n",
      "Epoch 26 - Loss: 0.6549147963523865 - Accuracy: 0.636\n",
      "Epoch 27 - Loss: 0.6465571522712708 - Accuracy: 0.692\n",
      "Epoch 28 - Loss: 0.6466068029403687 - Accuracy: 0.664\n",
      "Epoch 29 - Loss: 0.6381649971008301 - Accuracy: 0.738\n",
      "Epoch 30 - Loss: 0.6362061500549316 - Accuracy: 0.729\n",
      "Epoch 31 - Loss: 0.6305328011512756 - Accuracy: 0.720\n",
      "Epoch 32 - Loss: 0.6258344650268555 - Accuracy: 0.720\n",
      "Epoch 33 - Loss: 0.6219936609268188 - Accuracy: 0.710\n",
      "Epoch 34 - Loss: 0.6188297271728516 - Accuracy: 0.720\n",
      "Epoch 35 - Loss: 0.6155253648757935 - Accuracy: 0.729\n",
      "Epoch 36 - Loss: 0.6056929230690002 - Accuracy: 0.720\n",
      "Epoch 37 - Loss: 0.5982507467269897 - Accuracy: 0.785\n",
      "Epoch 38 - Loss: 0.6059563159942627 - Accuracy: 0.748\n",
      "Epoch 39 - Loss: 0.5971555113792419 - Accuracy: 0.757\n",
      "Epoch 40 - Loss: 0.583382248878479 - Accuracy: 0.794\n",
      "Epoch 41 - Loss: 0.5857298374176025 - Accuracy: 0.766\n",
      "Epoch 42 - Loss: 0.5704905390739441 - Accuracy: 0.804\n",
      "Epoch 43 - Loss: 0.5586297512054443 - Accuracy: 0.822\n",
      "Epoch 44 - Loss: 0.5695903301239014 - Accuracy: 0.738\n",
      "Epoch 45 - Loss: 0.5494378209114075 - Accuracy: 0.785\n",
      "Epoch 46 - Loss: 0.537563681602478 - Accuracy: 0.841\n",
      "Epoch 47 - Loss: 0.5427055954933167 - Accuracy: 0.757\n",
      "Epoch 48 - Loss: 0.5323357582092285 - Accuracy: 0.776\n",
      "Epoch 49 - Loss: 0.5281670093536377 - Accuracy: 0.813\n",
      "Epoch 50 - Loss: 0.5196327567100525 - Accuracy: 0.794\n",
      "Epoch 51 - Loss: 0.518425464630127 - Accuracy: 0.813\n",
      "Epoch 52 - Loss: 0.4994491934776306 - Accuracy: 0.794\n",
      "Epoch 53 - Loss: 0.5039706826210022 - Accuracy: 0.794\n",
      "Epoch 54 - Loss: 0.49507054686546326 - Accuracy: 0.766\n",
      "Epoch 55 - Loss: 0.48273736238479614 - Accuracy: 0.822\n",
      "Epoch 56 - Loss: 0.46743205189704895 - Accuracy: 0.822\n",
      "Epoch 57 - Loss: 0.4735688269138336 - Accuracy: 0.804\n",
      "Epoch 58 - Loss: 0.4618052542209625 - Accuracy: 0.813\n",
      "Epoch 59 - Loss: 0.4579537510871887 - Accuracy: 0.804\n",
      "Epoch 60 - Loss: 0.4609360694885254 - Accuracy: 0.813\n",
      "Epoch 61 - Loss: 0.4504522979259491 - Accuracy: 0.785\n",
      "Epoch 62 - Loss: 0.43338337540626526 - Accuracy: 0.832\n",
      "Epoch 63 - Loss: 0.43026992678642273 - Accuracy: 0.832\n",
      "Epoch 64 - Loss: 0.413251131772995 - Accuracy: 0.850\n",
      "Epoch 65 - Loss: 0.4116954505443573 - Accuracy: 0.794\n",
      "Epoch 66 - Loss: 0.4087764620780945 - Accuracy: 0.822\n",
      "Epoch 67 - Loss: 0.40919482707977295 - Accuracy: 0.832\n",
      "Epoch 68 - Loss: 0.3871740400791168 - Accuracy: 0.822\n",
      "Epoch 69 - Loss: 0.39188602566719055 - Accuracy: 0.822\n",
      "Epoch 70 - Loss: 0.3958628177642822 - Accuracy: 0.822\n",
      "Epoch 71 - Loss: 0.37283286452293396 - Accuracy: 0.841\n",
      "Epoch 72 - Loss: 0.39259737730026245 - Accuracy: 0.813\n",
      "Epoch 73 - Loss: 0.36993566155433655 - Accuracy: 0.869\n",
      "Epoch 74 - Loss: 0.36526423692703247 - Accuracy: 0.841\n",
      "Epoch 75 - Loss: 0.3664182722568512 - Accuracy: 0.804\n",
      "Epoch 76 - Loss: 0.35221534967422485 - Accuracy: 0.860\n",
      "Epoch 77 - Loss: 0.3620341718196869 - Accuracy: 0.850\n",
      "Epoch 78 - Loss: 0.34122854471206665 - Accuracy: 0.850\n",
      "Epoch 79 - Loss: 0.3320310413837433 - Accuracy: 0.860\n",
      "Epoch 80 - Loss: 0.3413480818271637 - Accuracy: 0.850\n",
      "Epoch 81 - Loss: 0.34618228673934937 - Accuracy: 0.841\n",
      "Epoch 82 - Loss: 0.32288703322410583 - Accuracy: 0.879\n",
      "Epoch 83 - Loss: 0.3138839602470398 - Accuracy: 0.869\n",
      "Epoch 84 - Loss: 0.2925756275653839 - Accuracy: 0.916\n",
      "Epoch 85 - Loss: 0.31194067001342773 - Accuracy: 0.860\n",
      "Epoch 86 - Loss: 0.32013988494873047 - Accuracy: 0.888\n",
      "Epoch 87 - Loss: 0.31153738498687744 - Accuracy: 0.888\n",
      "Epoch 88 - Loss: 0.3037997782230377 - Accuracy: 0.860\n",
      "Epoch 89 - Loss: 0.3231334388256073 - Accuracy: 0.869\n",
      "Epoch 90 - Loss: 0.29714396595954895 - Accuracy: 0.860\n",
      "Epoch 91 - Loss: 0.2995918393135071 - Accuracy: 0.860\n",
      "Epoch 92 - Loss: 0.2881443500518799 - Accuracy: 0.916\n",
      "Epoch 93 - Loss: 0.282908171415329 - Accuracy: 0.869\n",
      "Epoch 94 - Loss: 0.308497816324234 - Accuracy: 0.879\n",
      "Epoch 95 - Loss: 0.28290432691574097 - Accuracy: 0.897\n",
      "Epoch 96 - Loss: 0.2822052538394928 - Accuracy: 0.879\n",
      "Epoch 97 - Loss: 0.29471921920776367 - Accuracy: 0.888\n",
      "Epoch 98 - Loss: 0.2731107175350189 - Accuracy: 0.897\n",
      "Epoch 99 - Loss: 0.2616206109523773 - Accuracy: 0.897\n",
      "MLP model test accuracy: 0.897\n",
      "Running MLP experiments on ('PCNet', 0) data\n",
      "Epoch 0 - Loss: 0.6975862979888916 - Accuracy: 0.504\n",
      "Epoch 1 - Loss: 0.69645756483078 - Accuracy: 0.504\n",
      "Epoch 2 - Loss: 0.6933394074440002 - Accuracy: 0.504\n",
      "Epoch 3 - Loss: 0.6954019665718079 - Accuracy: 0.504\n",
      "Epoch 4 - Loss: 0.6942616105079651 - Accuracy: 0.504\n",
      "Epoch 5 - Loss: 0.6908926963806152 - Accuracy: 0.504\n",
      "Epoch 6 - Loss: 0.6902588605880737 - Accuracy: 0.504\n",
      "Epoch 7 - Loss: 0.687964677810669 - Accuracy: 0.512\n",
      "Epoch 8 - Loss: 0.6885356307029724 - Accuracy: 0.529\n",
      "Epoch 9 - Loss: 0.6844250559806824 - Accuracy: 0.529\n",
      "Epoch 10 - Loss: 0.6836868524551392 - Accuracy: 0.545\n",
      "Epoch 11 - Loss: 0.6830435991287231 - Accuracy: 0.562\n",
      "Epoch 12 - Loss: 0.6840260028839111 - Accuracy: 0.537\n",
      "Epoch 13 - Loss: 0.6807217001914978 - Accuracy: 0.570\n",
      "Epoch 14 - Loss: 0.6823891401290894 - Accuracy: 0.612\n",
      "Epoch 15 - Loss: 0.6779213547706604 - Accuracy: 0.603\n",
      "Epoch 16 - Loss: 0.6788797378540039 - Accuracy: 0.587\n",
      "Epoch 17 - Loss: 0.6755866408348083 - Accuracy: 0.620\n",
      "Epoch 18 - Loss: 0.6740623116493225 - Accuracy: 0.620\n",
      "Epoch 19 - Loss: 0.6779031753540039 - Accuracy: 0.603\n",
      "Epoch 20 - Loss: 0.6714074015617371 - Accuracy: 0.653\n",
      "Epoch 21 - Loss: 0.665763795375824 - Accuracy: 0.736\n",
      "Epoch 22 - Loss: 0.6652474999427795 - Accuracy: 0.711\n",
      "Epoch 23 - Loss: 0.6617350578308105 - Accuracy: 0.711\n",
      "Epoch 24 - Loss: 0.6575645804405212 - Accuracy: 0.785\n",
      "Epoch 25 - Loss: 0.6551641225814819 - Accuracy: 0.727\n",
      "Epoch 26 - Loss: 0.6504743099212646 - Accuracy: 0.793\n",
      "Epoch 27 - Loss: 0.6532579660415649 - Accuracy: 0.719\n",
      "Epoch 28 - Loss: 0.6481717228889465 - Accuracy: 0.736\n",
      "Epoch 29 - Loss: 0.6463087797164917 - Accuracy: 0.793\n",
      "Epoch 30 - Loss: 0.6432626843452454 - Accuracy: 0.744\n",
      "Epoch 31 - Loss: 0.6391212940216064 - Accuracy: 0.744\n",
      "Epoch 32 - Loss: 0.6351566910743713 - Accuracy: 0.719\n",
      "Epoch 33 - Loss: 0.6264623403549194 - Accuracy: 0.744\n",
      "Epoch 34 - Loss: 0.6248064637184143 - Accuracy: 0.744\n",
      "Epoch 35 - Loss: 0.6259608268737793 - Accuracy: 0.777\n",
      "Epoch 36 - Loss: 0.6130796670913696 - Accuracy: 0.826\n",
      "Epoch 37 - Loss: 0.6140405535697937 - Accuracy: 0.736\n",
      "Epoch 38 - Loss: 0.6057270765304565 - Accuracy: 0.785\n",
      "Epoch 39 - Loss: 0.601039469242096 - Accuracy: 0.793\n",
      "Epoch 40 - Loss: 0.5945958495140076 - Accuracy: 0.793\n",
      "Epoch 41 - Loss: 0.5877955555915833 - Accuracy: 0.802\n",
      "Epoch 42 - Loss: 0.5856971144676208 - Accuracy: 0.769\n",
      "Epoch 43 - Loss: 0.5744979977607727 - Accuracy: 0.802\n",
      "Epoch 44 - Loss: 0.5683354139328003 - Accuracy: 0.843\n",
      "Epoch 45 - Loss: 0.5688366293907166 - Accuracy: 0.777\n",
      "Epoch 46 - Loss: 0.5622827410697937 - Accuracy: 0.777\n",
      "Epoch 47 - Loss: 0.5564311146736145 - Accuracy: 0.810\n",
      "Epoch 48 - Loss: 0.5446083545684814 - Accuracy: 0.826\n",
      "Epoch 49 - Loss: 0.5404727458953857 - Accuracy: 0.810\n",
      "Epoch 50 - Loss: 0.5258386731147766 - Accuracy: 0.851\n",
      "Epoch 51 - Loss: 0.5310617089271545 - Accuracy: 0.826\n",
      "Epoch 52 - Loss: 0.5233684778213501 - Accuracy: 0.818\n",
      "Epoch 53 - Loss: 0.5146387219429016 - Accuracy: 0.802\n",
      "Epoch 54 - Loss: 0.49243587255477905 - Accuracy: 0.826\n",
      "Epoch 55 - Loss: 0.5070737600326538 - Accuracy: 0.802\n",
      "Epoch 56 - Loss: 0.507892370223999 - Accuracy: 0.818\n",
      "Epoch 57 - Loss: 0.4830944240093231 - Accuracy: 0.810\n",
      "Epoch 58 - Loss: 0.4838009178638458 - Accuracy: 0.843\n",
      "Epoch 59 - Loss: 0.48248329758644104 - Accuracy: 0.835\n",
      "Epoch 60 - Loss: 0.47291964292526245 - Accuracy: 0.860\n",
      "Epoch 61 - Loss: 0.46329304575920105 - Accuracy: 0.843\n",
      "Epoch 62 - Loss: 0.4648403525352478 - Accuracy: 0.826\n",
      "Epoch 63 - Loss: 0.4568012058734894 - Accuracy: 0.843\n",
      "Epoch 64 - Loss: 0.43458738923072815 - Accuracy: 0.851\n",
      "Epoch 65 - Loss: 0.43086904287338257 - Accuracy: 0.860\n",
      "Epoch 66 - Loss: 0.4292988181114197 - Accuracy: 0.843\n",
      "Epoch 67 - Loss: 0.40918242931365967 - Accuracy: 0.843\n",
      "Epoch 68 - Loss: 0.413469523191452 - Accuracy: 0.826\n",
      "Epoch 69 - Loss: 0.39494115114212036 - Accuracy: 0.868\n",
      "Epoch 70 - Loss: 0.39438238739967346 - Accuracy: 0.860\n",
      "Epoch 71 - Loss: 0.4020642638206482 - Accuracy: 0.868\n",
      "Epoch 72 - Loss: 0.38065576553344727 - Accuracy: 0.851\n",
      "Epoch 73 - Loss: 0.3778005540370941 - Accuracy: 0.876\n",
      "Epoch 74 - Loss: 0.37458765506744385 - Accuracy: 0.851\n",
      "Epoch 75 - Loss: 0.3517206311225891 - Accuracy: 0.876\n",
      "Epoch 76 - Loss: 0.3545132875442505 - Accuracy: 0.876\n",
      "Epoch 77 - Loss: 0.3512408435344696 - Accuracy: 0.843\n",
      "Epoch 78 - Loss: 0.34713366627693176 - Accuracy: 0.835\n",
      "Epoch 79 - Loss: 0.3385327458381653 - Accuracy: 0.868\n",
      "Epoch 80 - Loss: 0.34765633940696716 - Accuracy: 0.851\n",
      "Epoch 81 - Loss: 0.3331577777862549 - Accuracy: 0.884\n",
      "Epoch 82 - Loss: 0.3279569745063782 - Accuracy: 0.876\n",
      "Epoch 83 - Loss: 0.3131481409072876 - Accuracy: 0.901\n",
      "Epoch 84 - Loss: 0.31805548071861267 - Accuracy: 0.868\n",
      "Epoch 85 - Loss: 0.3189081847667694 - Accuracy: 0.860\n",
      "Epoch 86 - Loss: 0.3009771406650543 - Accuracy: 0.893\n",
      "Epoch 87 - Loss: 0.3051547110080719 - Accuracy: 0.884\n",
      "Epoch 88 - Loss: 0.3123806118965149 - Accuracy: 0.893\n",
      "Epoch 89 - Loss: 0.27229270339012146 - Accuracy: 0.893\n",
      "Epoch 90 - Loss: 0.30373382568359375 - Accuracy: 0.876\n",
      "Epoch 91 - Loss: 0.2816673219203949 - Accuracy: 0.884\n",
      "Epoch 92 - Loss: 0.2952672839164734 - Accuracy: 0.884\n",
      "Epoch 93 - Loss: 0.2962053418159485 - Accuracy: 0.868\n",
      "Epoch 94 - Loss: 0.26535993814468384 - Accuracy: 0.884\n",
      "Epoch 95 - Loss: 0.26757580041885376 - Accuracy: 0.909\n",
      "Epoch 96 - Loss: 0.26872119307518005 - Accuracy: 0.901\n",
      "Epoch 97 - Loss: 0.2731904983520508 - Accuracy: 0.917\n",
      "Epoch 98 - Loss: 0.2706359326839447 - Accuracy: 0.884\n",
      "Epoch 99 - Loss: 0.26441869139671326 - Accuracy: 0.893\n",
      "MLP model test accuracy: 0.893\n",
      "Running MLP experiments on ('PCNet', 1) data\n",
      "Epoch 0 - Loss: 0.6920309066772461 - Accuracy: 0.488\n",
      "Epoch 1 - Loss: 0.692972719669342 - Accuracy: 0.479\n",
      "Epoch 2 - Loss: 0.6912322640419006 - Accuracy: 0.537\n",
      "Epoch 3 - Loss: 0.6916674375534058 - Accuracy: 0.545\n",
      "Epoch 4 - Loss: 0.6883947253227234 - Accuracy: 0.612\n",
      "Epoch 5 - Loss: 0.6906540989875793 - Accuracy: 0.587\n",
      "Epoch 6 - Loss: 0.6875104308128357 - Accuracy: 0.636\n",
      "Epoch 7 - Loss: 0.6853145956993103 - Accuracy: 0.686\n",
      "Epoch 8 - Loss: 0.6871151924133301 - Accuracy: 0.562\n",
      "Epoch 9 - Loss: 0.6839047074317932 - Accuracy: 0.612\n",
      "Epoch 10 - Loss: 0.6840345859527588 - Accuracy: 0.661\n",
      "Epoch 11 - Loss: 0.6855283379554749 - Accuracy: 0.587\n",
      "Epoch 12 - Loss: 0.6815600395202637 - Accuracy: 0.694\n",
      "Epoch 13 - Loss: 0.6796517372131348 - Accuracy: 0.669\n",
      "Epoch 14 - Loss: 0.6774282455444336 - Accuracy: 0.669\n",
      "Epoch 15 - Loss: 0.6786139607429504 - Accuracy: 0.661\n",
      "Epoch 16 - Loss: 0.675431489944458 - Accuracy: 0.727\n",
      "Epoch 17 - Loss: 0.6743409633636475 - Accuracy: 0.645\n",
      "Epoch 18 - Loss: 0.6731030941009521 - Accuracy: 0.744\n",
      "Epoch 19 - Loss: 0.6697155833244324 - Accuracy: 0.744\n",
      "Epoch 20 - Loss: 0.666158139705658 - Accuracy: 0.719\n",
      "Epoch 21 - Loss: 0.6605503559112549 - Accuracy: 0.760\n",
      "Epoch 22 - Loss: 0.6656468510627747 - Accuracy: 0.686\n",
      "Epoch 23 - Loss: 0.6623749136924744 - Accuracy: 0.736\n",
      "Epoch 24 - Loss: 0.6596043705940247 - Accuracy: 0.694\n",
      "Epoch 25 - Loss: 0.6523572206497192 - Accuracy: 0.736\n",
      "Epoch 26 - Loss: 0.6491498351097107 - Accuracy: 0.727\n",
      "Epoch 27 - Loss: 0.649337887763977 - Accuracy: 0.686\n",
      "Epoch 28 - Loss: 0.6435219645500183 - Accuracy: 0.736\n",
      "Epoch 29 - Loss: 0.638940691947937 - Accuracy: 0.777\n",
      "Epoch 30 - Loss: 0.6423351168632507 - Accuracy: 0.686\n",
      "Epoch 31 - Loss: 0.6347529292106628 - Accuracy: 0.727\n",
      "Epoch 32 - Loss: 0.632213830947876 - Accuracy: 0.711\n",
      "Epoch 33 - Loss: 0.6244779825210571 - Accuracy: 0.744\n",
      "Epoch 34 - Loss: 0.6217217445373535 - Accuracy: 0.760\n",
      "Epoch 35 - Loss: 0.613909125328064 - Accuracy: 0.736\n",
      "Epoch 36 - Loss: 0.6103637218475342 - Accuracy: 0.752\n",
      "Epoch 37 - Loss: 0.6109172105789185 - Accuracy: 0.736\n",
      "Epoch 38 - Loss: 0.6087914109230042 - Accuracy: 0.752\n",
      "Epoch 39 - Loss: 0.5939361453056335 - Accuracy: 0.752\n",
      "Epoch 40 - Loss: 0.5936787724494934 - Accuracy: 0.769\n",
      "Epoch 41 - Loss: 0.5924972891807556 - Accuracy: 0.736\n",
      "Epoch 42 - Loss: 0.5867417454719543 - Accuracy: 0.736\n",
      "Epoch 43 - Loss: 0.5706468820571899 - Accuracy: 0.793\n",
      "Epoch 44 - Loss: 0.5694205164909363 - Accuracy: 0.769\n",
      "Epoch 45 - Loss: 0.5608405470848083 - Accuracy: 0.793\n",
      "Epoch 46 - Loss: 0.561314046382904 - Accuracy: 0.777\n",
      "Epoch 47 - Loss: 0.5436753630638123 - Accuracy: 0.818\n",
      "Epoch 48 - Loss: 0.5458855032920837 - Accuracy: 0.785\n",
      "Epoch 49 - Loss: 0.538673460483551 - Accuracy: 0.760\n",
      "Epoch 50 - Loss: 0.5241626501083374 - Accuracy: 0.793\n",
      "Epoch 51 - Loss: 0.5229758620262146 - Accuracy: 0.810\n",
      "Epoch 52 - Loss: 0.5191560387611389 - Accuracy: 0.769\n",
      "Epoch 53 - Loss: 0.5176219940185547 - Accuracy: 0.818\n",
      "Epoch 54 - Loss: 0.5025299787521362 - Accuracy: 0.826\n",
      "Epoch 55 - Loss: 0.5073363184928894 - Accuracy: 0.843\n",
      "Epoch 56 - Loss: 0.48440486192703247 - Accuracy: 0.851\n",
      "Epoch 57 - Loss: 0.4917677342891693 - Accuracy: 0.835\n",
      "Epoch 58 - Loss: 0.46637508273124695 - Accuracy: 0.843\n",
      "Epoch 59 - Loss: 0.4629775285720825 - Accuracy: 0.868\n",
      "Epoch 60 - Loss: 0.46635743975639343 - Accuracy: 0.860\n",
      "Epoch 61 - Loss: 0.4500892460346222 - Accuracy: 0.876\n",
      "Epoch 62 - Loss: 0.4542791247367859 - Accuracy: 0.851\n",
      "Epoch 63 - Loss: 0.44074079394340515 - Accuracy: 0.851\n",
      "Epoch 64 - Loss: 0.4254004955291748 - Accuracy: 0.860\n",
      "Epoch 65 - Loss: 0.428729772567749 - Accuracy: 0.884\n",
      "Epoch 66 - Loss: 0.4178621172904968 - Accuracy: 0.876\n",
      "Epoch 67 - Loss: 0.4160703420639038 - Accuracy: 0.893\n",
      "Epoch 68 - Loss: 0.40159985423088074 - Accuracy: 0.843\n",
      "Epoch 69 - Loss: 0.40539172291755676 - Accuracy: 0.893\n",
      "Epoch 70 - Loss: 0.37923943996429443 - Accuracy: 0.917\n",
      "Epoch 71 - Loss: 0.38257646560668945 - Accuracy: 0.884\n",
      "Epoch 72 - Loss: 0.3804406523704529 - Accuracy: 0.884\n",
      "Epoch 73 - Loss: 0.3896855115890503 - Accuracy: 0.893\n",
      "Epoch 74 - Loss: 0.3600442707538605 - Accuracy: 0.893\n",
      "Epoch 75 - Loss: 0.36271539330482483 - Accuracy: 0.876\n",
      "Epoch 76 - Loss: 0.3547782301902771 - Accuracy: 0.893\n",
      "Epoch 77 - Loss: 0.33803725242614746 - Accuracy: 0.901\n",
      "Epoch 78 - Loss: 0.3380874991416931 - Accuracy: 0.893\n",
      "Epoch 79 - Loss: 0.3245026767253876 - Accuracy: 0.893\n",
      "Epoch 80 - Loss: 0.32619228959083557 - Accuracy: 0.909\n",
      "Epoch 81 - Loss: 0.31485477089881897 - Accuracy: 0.917\n",
      "Epoch 82 - Loss: 0.3324819803237915 - Accuracy: 0.884\n",
      "Epoch 83 - Loss: 0.3250303566455841 - Accuracy: 0.901\n",
      "Epoch 84 - Loss: 0.3147197365760803 - Accuracy: 0.884\n",
      "Epoch 85 - Loss: 0.2940489947795868 - Accuracy: 0.909\n",
      "Epoch 86 - Loss: 0.28559234738349915 - Accuracy: 0.901\n",
      "Epoch 87 - Loss: 0.3063637316226959 - Accuracy: 0.901\n",
      "Epoch 88 - Loss: 0.2946065366268158 - Accuracy: 0.917\n",
      "Epoch 89 - Loss: 0.30096474289894104 - Accuracy: 0.901\n",
      "Epoch 90 - Loss: 0.2643912434577942 - Accuracy: 0.917\n",
      "Epoch 91 - Loss: 0.2538085877895355 - Accuracy: 0.909\n",
      "Epoch 92 - Loss: 0.27968573570251465 - Accuracy: 0.909\n",
      "Epoch 93 - Loss: 0.2722674012184143 - Accuracy: 0.917\n",
      "Epoch 94 - Loss: 0.255147784948349 - Accuracy: 0.926\n",
      "Epoch 95 - Loss: 0.26939865946769714 - Accuracy: 0.917\n",
      "Epoch 96 - Loss: 0.2566027045249939 - Accuracy: 0.917\n",
      "Epoch 97 - Loss: 0.26988688111305237 - Accuracy: 0.909\n",
      "Epoch 98 - Loss: 0.2583615779876709 - Accuracy: 0.909\n",
      "Epoch 99 - Loss: 0.24414408206939697 - Accuracy: 0.917\n",
      "MLP model test accuracy: 0.917\n",
      "Running MLP experiments on ('PCNet', 2) data\n",
      "Epoch 0 - Loss: 0.6913781762123108 - Accuracy: 0.554\n",
      "Epoch 1 - Loss: 0.6906133890151978 - Accuracy: 0.545\n",
      "Epoch 2 - Loss: 0.6894732117652893 - Accuracy: 0.628\n",
      "Epoch 3 - Loss: 0.689175546169281 - Accuracy: 0.620\n",
      "Epoch 4 - Loss: 0.6890332698822021 - Accuracy: 0.628\n",
      "Epoch 5 - Loss: 0.6861542463302612 - Accuracy: 0.694\n",
      "Epoch 6 - Loss: 0.686962902545929 - Accuracy: 0.661\n",
      "Epoch 7 - Loss: 0.6878315806388855 - Accuracy: 0.587\n",
      "Epoch 8 - Loss: 0.685778796672821 - Accuracy: 0.612\n",
      "Epoch 9 - Loss: 0.6842642426490784 - Accuracy: 0.636\n",
      "Epoch 10 - Loss: 0.6822009086608887 - Accuracy: 0.612\n",
      "Epoch 11 - Loss: 0.6822072267532349 - Accuracy: 0.678\n",
      "Epoch 12 - Loss: 0.6811385750770569 - Accuracy: 0.587\n",
      "Epoch 13 - Loss: 0.6800808310508728 - Accuracy: 0.595\n",
      "Epoch 14 - Loss: 0.6801670789718628 - Accuracy: 0.579\n",
      "Epoch 15 - Loss: 0.678560733795166 - Accuracy: 0.529\n",
      "Epoch 16 - Loss: 0.676692008972168 - Accuracy: 0.579\n",
      "Epoch 17 - Loss: 0.6736794710159302 - Accuracy: 0.587\n",
      "Epoch 18 - Loss: 0.6746624112129211 - Accuracy: 0.545\n",
      "Epoch 19 - Loss: 0.6757185459136963 - Accuracy: 0.521\n",
      "Epoch 20 - Loss: 0.6720637083053589 - Accuracy: 0.545\n",
      "Epoch 21 - Loss: 0.671427309513092 - Accuracy: 0.562\n",
      "Epoch 22 - Loss: 0.6683586239814758 - Accuracy: 0.570\n",
      "Epoch 23 - Loss: 0.6678082942962646 - Accuracy: 0.554\n",
      "Epoch 24 - Loss: 0.6662344932556152 - Accuracy: 0.579\n",
      "Epoch 25 - Loss: 0.6630675792694092 - Accuracy: 0.636\n",
      "Epoch 26 - Loss: 0.6554880142211914 - Accuracy: 0.612\n",
      "Epoch 27 - Loss: 0.6501866579055786 - Accuracy: 0.694\n",
      "Epoch 28 - Loss: 0.6535122394561768 - Accuracy: 0.612\n",
      "Epoch 29 - Loss: 0.6497706770896912 - Accuracy: 0.645\n",
      "Epoch 30 - Loss: 0.6479965448379517 - Accuracy: 0.669\n",
      "Epoch 31 - Loss: 0.6491265296936035 - Accuracy: 0.653\n",
      "Epoch 32 - Loss: 0.6384302377700806 - Accuracy: 0.612\n",
      "Epoch 33 - Loss: 0.6417880058288574 - Accuracy: 0.661\n",
      "Epoch 34 - Loss: 0.6397854685783386 - Accuracy: 0.678\n",
      "Epoch 35 - Loss: 0.6333812475204468 - Accuracy: 0.645\n",
      "Epoch 36 - Loss: 0.63152015209198 - Accuracy: 0.669\n",
      "Epoch 37 - Loss: 0.6311085820198059 - Accuracy: 0.678\n",
      "Epoch 38 - Loss: 0.625900387763977 - Accuracy: 0.678\n",
      "Epoch 39 - Loss: 0.6181313395500183 - Accuracy: 0.736\n",
      "Epoch 40 - Loss: 0.6189071536064148 - Accuracy: 0.694\n",
      "Epoch 41 - Loss: 0.6142691373825073 - Accuracy: 0.719\n",
      "Epoch 42 - Loss: 0.6037361025810242 - Accuracy: 0.727\n",
      "Epoch 43 - Loss: 0.6049521565437317 - Accuracy: 0.727\n",
      "Epoch 44 - Loss: 0.597239077091217 - Accuracy: 0.736\n",
      "Epoch 45 - Loss: 0.5948296785354614 - Accuracy: 0.760\n",
      "Epoch 46 - Loss: 0.5975156426429749 - Accuracy: 0.752\n",
      "Epoch 47 - Loss: 0.5875105261802673 - Accuracy: 0.744\n",
      "Epoch 48 - Loss: 0.575616180896759 - Accuracy: 0.777\n",
      "Epoch 49 - Loss: 0.5697885155677795 - Accuracy: 0.777\n",
      "Epoch 50 - Loss: 0.575965404510498 - Accuracy: 0.769\n",
      "Epoch 51 - Loss: 0.5684900879859924 - Accuracy: 0.785\n",
      "Epoch 52 - Loss: 0.5535221695899963 - Accuracy: 0.777\n",
      "Epoch 53 - Loss: 0.5585538744926453 - Accuracy: 0.777\n",
      "Epoch 54 - Loss: 0.5511565804481506 - Accuracy: 0.802\n",
      "Epoch 55 - Loss: 0.5437480807304382 - Accuracy: 0.777\n",
      "Epoch 56 - Loss: 0.5408350825309753 - Accuracy: 0.802\n",
      "Epoch 57 - Loss: 0.5310494303703308 - Accuracy: 0.802\n",
      "Epoch 58 - Loss: 0.5421422123908997 - Accuracy: 0.785\n",
      "Epoch 59 - Loss: 0.5281864404678345 - Accuracy: 0.818\n",
      "Epoch 60 - Loss: 0.5174855589866638 - Accuracy: 0.810\n",
      "Epoch 61 - Loss: 0.5087159276008606 - Accuracy: 0.810\n",
      "Epoch 62 - Loss: 0.5062768459320068 - Accuracy: 0.835\n",
      "Epoch 63 - Loss: 0.5091760754585266 - Accuracy: 0.835\n",
      "Epoch 64 - Loss: 0.5005211234092712 - Accuracy: 0.810\n",
      "Epoch 65 - Loss: 0.489031583070755 - Accuracy: 0.818\n",
      "Epoch 66 - Loss: 0.49645018577575684 - Accuracy: 0.810\n",
      "Epoch 67 - Loss: 0.48129063844680786 - Accuracy: 0.843\n",
      "Epoch 68 - Loss: 0.48414045572280884 - Accuracy: 0.835\n",
      "Epoch 69 - Loss: 0.46798452734947205 - Accuracy: 0.826\n",
      "Epoch 70 - Loss: 0.46679770946502686 - Accuracy: 0.835\n",
      "Epoch 71 - Loss: 0.47229811549186707 - Accuracy: 0.818\n",
      "Epoch 72 - Loss: 0.45459431409835815 - Accuracy: 0.826\n",
      "Epoch 73 - Loss: 0.45229244232177734 - Accuracy: 0.810\n",
      "Epoch 74 - Loss: 0.4389399588108063 - Accuracy: 0.851\n",
      "Epoch 75 - Loss: 0.4344702959060669 - Accuracy: 0.851\n",
      "Epoch 76 - Loss: 0.42665815353393555 - Accuracy: 0.843\n",
      "Epoch 77 - Loss: 0.43486788868904114 - Accuracy: 0.843\n",
      "Epoch 78 - Loss: 0.43329545855522156 - Accuracy: 0.826\n",
      "Epoch 79 - Loss: 0.4276273250579834 - Accuracy: 0.826\n",
      "Epoch 80 - Loss: 0.4219045341014862 - Accuracy: 0.835\n",
      "Epoch 81 - Loss: 0.403676301240921 - Accuracy: 0.851\n",
      "Epoch 82 - Loss: 0.41286811232566833 - Accuracy: 0.851\n",
      "Epoch 83 - Loss: 0.3886876404285431 - Accuracy: 0.868\n",
      "Epoch 84 - Loss: 0.3897307217121124 - Accuracy: 0.835\n",
      "Epoch 85 - Loss: 0.36706531047821045 - Accuracy: 0.860\n",
      "Epoch 86 - Loss: 0.38378098607063293 - Accuracy: 0.843\n",
      "Epoch 87 - Loss: 0.3792724311351776 - Accuracy: 0.835\n",
      "Epoch 88 - Loss: 0.37104862928390503 - Accuracy: 0.876\n",
      "Epoch 89 - Loss: 0.35461461544036865 - Accuracy: 0.893\n",
      "Epoch 90 - Loss: 0.35738393664360046 - Accuracy: 0.860\n",
      "Epoch 91 - Loss: 0.35884058475494385 - Accuracy: 0.860\n",
      "Epoch 92 - Loss: 0.3337935209274292 - Accuracy: 0.876\n",
      "Epoch 93 - Loss: 0.34347617626190186 - Accuracy: 0.860\n",
      "Epoch 94 - Loss: 0.34613415598869324 - Accuracy: 0.860\n",
      "Epoch 95 - Loss: 0.34765902161598206 - Accuracy: 0.860\n",
      "Epoch 96 - Loss: 0.3416629433631897 - Accuracy: 0.868\n",
      "Epoch 97 - Loss: 0.3291586935520172 - Accuracy: 0.884\n",
      "Epoch 98 - Loss: 0.3151242136955261 - Accuracy: 0.893\n",
      "Epoch 99 - Loss: 0.3189333379268646 - Accuracy: 0.884\n",
      "MLP model test accuracy: 0.884\n",
      "Running MLP experiments on ('STRINGdb', 0) data\n",
      "Epoch 0 - Loss: 0.6891341805458069 - Accuracy: 0.631\n",
      "Epoch 1 - Loss: 0.6924188733100891 - Accuracy: 0.523\n",
      "Epoch 2 - Loss: 0.6887982487678528 - Accuracy: 0.595\n",
      "Epoch 3 - Loss: 0.6870104670524597 - Accuracy: 0.649\n",
      "Epoch 4 - Loss: 0.6868953704833984 - Accuracy: 0.622\n",
      "Epoch 5 - Loss: 0.6872119307518005 - Accuracy: 0.613\n",
      "Epoch 6 - Loss: 0.6854283213615417 - Accuracy: 0.604\n",
      "Epoch 7 - Loss: 0.6845121383666992 - Accuracy: 0.613\n",
      "Epoch 8 - Loss: 0.6829209327697754 - Accuracy: 0.604\n",
      "Epoch 9 - Loss: 0.6821801662445068 - Accuracy: 0.676\n",
      "Epoch 10 - Loss: 0.6826907396316528 - Accuracy: 0.649\n",
      "Epoch 11 - Loss: 0.6785642504692078 - Accuracy: 0.685\n",
      "Epoch 12 - Loss: 0.6803118586540222 - Accuracy: 0.676\n",
      "Epoch 13 - Loss: 0.6753615736961365 - Accuracy: 0.667\n",
      "Epoch 14 - Loss: 0.6727043986320496 - Accuracy: 0.712\n",
      "Epoch 15 - Loss: 0.6727839708328247 - Accuracy: 0.667\n",
      "Epoch 16 - Loss: 0.6694861054420471 - Accuracy: 0.667\n",
      "Epoch 17 - Loss: 0.6671056151390076 - Accuracy: 0.748\n",
      "Epoch 18 - Loss: 0.6627728343009949 - Accuracy: 0.703\n",
      "Epoch 19 - Loss: 0.6633071303367615 - Accuracy: 0.739\n",
      "Epoch 20 - Loss: 0.6589615941047668 - Accuracy: 0.784\n",
      "Epoch 21 - Loss: 0.6533428430557251 - Accuracy: 0.721\n",
      "Epoch 22 - Loss: 0.6575672030448914 - Accuracy: 0.730\n",
      "Epoch 23 - Loss: 0.6575473546981812 - Accuracy: 0.730\n",
      "Epoch 24 - Loss: 0.6543830633163452 - Accuracy: 0.712\n",
      "Epoch 25 - Loss: 0.6497986912727356 - Accuracy: 0.703\n",
      "Epoch 26 - Loss: 0.6464431285858154 - Accuracy: 0.784\n",
      "Epoch 27 - Loss: 0.637447714805603 - Accuracy: 0.811\n",
      "Epoch 28 - Loss: 0.6431450247764587 - Accuracy: 0.748\n",
      "Epoch 29 - Loss: 0.632597804069519 - Accuracy: 0.775\n",
      "Epoch 30 - Loss: 0.6222829818725586 - Accuracy: 0.775\n",
      "Epoch 31 - Loss: 0.6196203827857971 - Accuracy: 0.784\n",
      "Epoch 32 - Loss: 0.6158955693244934 - Accuracy: 0.766\n",
      "Epoch 33 - Loss: 0.6247856616973877 - Accuracy: 0.730\n",
      "Epoch 34 - Loss: 0.6133779287338257 - Accuracy: 0.766\n",
      "Epoch 35 - Loss: 0.603839635848999 - Accuracy: 0.784\n",
      "Epoch 36 - Loss: 0.6019381880760193 - Accuracy: 0.775\n",
      "Epoch 37 - Loss: 0.593017578125 - Accuracy: 0.775\n",
      "Epoch 38 - Loss: 0.5913962125778198 - Accuracy: 0.766\n",
      "Epoch 39 - Loss: 0.5727065205574036 - Accuracy: 0.820\n",
      "Epoch 40 - Loss: 0.5716080665588379 - Accuracy: 0.766\n",
      "Epoch 41 - Loss: 0.571887195110321 - Accuracy: 0.847\n",
      "Epoch 42 - Loss: 0.5621823668479919 - Accuracy: 0.856\n",
      "Epoch 43 - Loss: 0.5645695924758911 - Accuracy: 0.811\n",
      "Epoch 44 - Loss: 0.5531132817268372 - Accuracy: 0.838\n",
      "Epoch 45 - Loss: 0.5541072487831116 - Accuracy: 0.856\n",
      "Epoch 46 - Loss: 0.5391926169395447 - Accuracy: 0.838\n",
      "Epoch 47 - Loss: 0.5242019891738892 - Accuracy: 0.802\n",
      "Epoch 48 - Loss: 0.5230411887168884 - Accuracy: 0.838\n",
      "Epoch 49 - Loss: 0.515457808971405 - Accuracy: 0.856\n",
      "Epoch 50 - Loss: 0.511705756187439 - Accuracy: 0.829\n",
      "Epoch 51 - Loss: 0.5000634789466858 - Accuracy: 0.874\n",
      "Epoch 52 - Loss: 0.5062012672424316 - Accuracy: 0.829\n",
      "Epoch 53 - Loss: 0.5011375546455383 - Accuracy: 0.838\n",
      "Epoch 54 - Loss: 0.49311572313308716 - Accuracy: 0.829\n",
      "Epoch 55 - Loss: 0.4855611324310303 - Accuracy: 0.847\n",
      "Epoch 56 - Loss: 0.47601187229156494 - Accuracy: 0.865\n",
      "Epoch 57 - Loss: 0.4760132431983948 - Accuracy: 0.847\n",
      "Epoch 58 - Loss: 0.4377461373806 - Accuracy: 0.874\n",
      "Epoch 59 - Loss: 0.45229166746139526 - Accuracy: 0.847\n",
      "Epoch 60 - Loss: 0.42646995186805725 - Accuracy: 0.874\n",
      "Epoch 61 - Loss: 0.42348921298980713 - Accuracy: 0.901\n",
      "Epoch 62 - Loss: 0.4252943694591522 - Accuracy: 0.856\n",
      "Epoch 63 - Loss: 0.4101687967777252 - Accuracy: 0.892\n",
      "Epoch 64 - Loss: 0.4036432206630707 - Accuracy: 0.892\n",
      "Epoch 65 - Loss: 0.4048539698123932 - Accuracy: 0.874\n",
      "Epoch 66 - Loss: 0.39825934171676636 - Accuracy: 0.883\n",
      "Epoch 67 - Loss: 0.4017575681209564 - Accuracy: 0.874\n",
      "Epoch 68 - Loss: 0.39232003688812256 - Accuracy: 0.883\n",
      "Epoch 69 - Loss: 0.3655310273170471 - Accuracy: 0.928\n",
      "Epoch 70 - Loss: 0.3518334925174713 - Accuracy: 0.892\n",
      "Epoch 71 - Loss: 0.36527395248413086 - Accuracy: 0.874\n",
      "Epoch 72 - Loss: 0.35277700424194336 - Accuracy: 0.892\n",
      "Epoch 73 - Loss: 0.3449442982673645 - Accuracy: 0.901\n",
      "Epoch 74 - Loss: 0.35944223403930664 - Accuracy: 0.883\n",
      "Epoch 75 - Loss: 0.3463890850543976 - Accuracy: 0.883\n",
      "Epoch 76 - Loss: 0.32816770672798157 - Accuracy: 0.910\n",
      "Epoch 77 - Loss: 0.34378620982170105 - Accuracy: 0.883\n",
      "Epoch 78 - Loss: 0.32345712184906006 - Accuracy: 0.901\n",
      "Epoch 79 - Loss: 0.32490795850753784 - Accuracy: 0.883\n",
      "Epoch 80 - Loss: 0.312740683555603 - Accuracy: 0.919\n",
      "Epoch 81 - Loss: 0.29474395513534546 - Accuracy: 0.910\n",
      "Epoch 82 - Loss: 0.27742916345596313 - Accuracy: 0.928\n",
      "Epoch 83 - Loss: 0.2971038222312927 - Accuracy: 0.910\n",
      "Epoch 84 - Loss: 0.30542975664138794 - Accuracy: 0.847\n",
      "Epoch 85 - Loss: 0.28309166431427 - Accuracy: 0.901\n",
      "Epoch 86 - Loss: 0.2780260443687439 - Accuracy: 0.892\n",
      "Epoch 87 - Loss: 0.2805826961994171 - Accuracy: 0.937\n",
      "Epoch 88 - Loss: 0.26938918232917786 - Accuracy: 0.910\n",
      "Epoch 89 - Loss: 0.2927698791027069 - Accuracy: 0.883\n",
      "Epoch 90 - Loss: 0.2700282037258148 - Accuracy: 0.892\n",
      "Epoch 91 - Loss: 0.26597654819488525 - Accuracy: 0.937\n",
      "Epoch 92 - Loss: 0.26483118534088135 - Accuracy: 0.928\n",
      "Epoch 93 - Loss: 0.23973828554153442 - Accuracy: 0.928\n",
      "Epoch 94 - Loss: 0.22735127806663513 - Accuracy: 0.946\n",
      "Epoch 95 - Loss: 0.24706169962882996 - Accuracy: 0.946\n",
      "Epoch 96 - Loss: 0.23085148632526398 - Accuracy: 0.928\n",
      "Epoch 97 - Loss: 0.24340015649795532 - Accuracy: 0.937\n",
      "Epoch 98 - Loss: 0.23675361275672913 - Accuracy: 0.946\n",
      "Epoch 99 - Loss: 0.2416967749595642 - Accuracy: 0.910\n",
      "MLP model test accuracy: 0.910\n",
      "Running MLP experiments on ('STRINGdb', 1) data\n",
      "Epoch 0 - Loss: 0.6945180892944336 - Accuracy: 0.505\n",
      "Epoch 1 - Loss: 0.6914106607437134 - Accuracy: 0.532\n",
      "Epoch 2 - Loss: 0.6924402713775635 - Accuracy: 0.495\n",
      "Epoch 3 - Loss: 0.6893314719200134 - Accuracy: 0.550\n",
      "Epoch 4 - Loss: 0.6878981590270996 - Accuracy: 0.532\n",
      "Epoch 5 - Loss: 0.6869496703147888 - Accuracy: 0.595\n",
      "Epoch 6 - Loss: 0.6819241642951965 - Accuracy: 0.721\n",
      "Epoch 7 - Loss: 0.6854428052902222 - Accuracy: 0.622\n",
      "Epoch 8 - Loss: 0.6832094192504883 - Accuracy: 0.685\n",
      "Epoch 9 - Loss: 0.6834428906440735 - Accuracy: 0.703\n",
      "Epoch 10 - Loss: 0.6808880567550659 - Accuracy: 0.739\n",
      "Epoch 11 - Loss: 0.6793223023414612 - Accuracy: 0.721\n",
      "Epoch 12 - Loss: 0.6799432635307312 - Accuracy: 0.721\n",
      "Epoch 13 - Loss: 0.675933301448822 - Accuracy: 0.793\n",
      "Epoch 14 - Loss: 0.6786257028579712 - Accuracy: 0.640\n",
      "Epoch 15 - Loss: 0.6741332411766052 - Accuracy: 0.703\n",
      "Epoch 16 - Loss: 0.6744738221168518 - Accuracy: 0.703\n",
      "Epoch 17 - Loss: 0.6712939739227295 - Accuracy: 0.739\n",
      "Epoch 18 - Loss: 0.6720191240310669 - Accuracy: 0.694\n",
      "Epoch 19 - Loss: 0.668973982334137 - Accuracy: 0.748\n",
      "Epoch 20 - Loss: 0.665450930595398 - Accuracy: 0.766\n",
      "Epoch 21 - Loss: 0.6659506559371948 - Accuracy: 0.766\n",
      "Epoch 22 - Loss: 0.6642226576805115 - Accuracy: 0.721\n",
      "Epoch 23 - Loss: 0.6574991345405579 - Accuracy: 0.793\n",
      "Epoch 24 - Loss: 0.6564035415649414 - Accuracy: 0.757\n",
      "Epoch 25 - Loss: 0.6522454619407654 - Accuracy: 0.766\n",
      "Epoch 26 - Loss: 0.6543552279472351 - Accuracy: 0.766\n",
      "Epoch 27 - Loss: 0.6503265500068665 - Accuracy: 0.766\n",
      "Epoch 28 - Loss: 0.6492034196853638 - Accuracy: 0.793\n",
      "Epoch 29 - Loss: 0.6365023851394653 - Accuracy: 0.829\n",
      "Epoch 30 - Loss: 0.6341184377670288 - Accuracy: 0.802\n",
      "Epoch 31 - Loss: 0.6304562091827393 - Accuracy: 0.793\n",
      "Epoch 32 - Loss: 0.627177894115448 - Accuracy: 0.793\n",
      "Epoch 33 - Loss: 0.6246984601020813 - Accuracy: 0.865\n",
      "Epoch 34 - Loss: 0.623055100440979 - Accuracy: 0.784\n",
      "Epoch 35 - Loss: 0.6209474205970764 - Accuracy: 0.802\n",
      "Epoch 36 - Loss: 0.6175568103790283 - Accuracy: 0.775\n",
      "Epoch 37 - Loss: 0.6078061461448669 - Accuracy: 0.838\n",
      "Epoch 38 - Loss: 0.6096934676170349 - Accuracy: 0.784\n",
      "Epoch 39 - Loss: 0.5987130999565125 - Accuracy: 0.802\n",
      "Epoch 40 - Loss: 0.6033144593238831 - Accuracy: 0.775\n",
      "Epoch 41 - Loss: 0.5883975625038147 - Accuracy: 0.811\n",
      "Epoch 42 - Loss: 0.5924853682518005 - Accuracy: 0.793\n",
      "Epoch 43 - Loss: 0.589475691318512 - Accuracy: 0.757\n",
      "Epoch 44 - Loss: 0.5677779316902161 - Accuracy: 0.811\n",
      "Epoch 45 - Loss: 0.5801724195480347 - Accuracy: 0.820\n",
      "Epoch 46 - Loss: 0.5633124113082886 - Accuracy: 0.793\n",
      "Epoch 47 - Loss: 0.5456975102424622 - Accuracy: 0.865\n",
      "Epoch 48 - Loss: 0.5479439496994019 - Accuracy: 0.829\n",
      "Epoch 49 - Loss: 0.5496464967727661 - Accuracy: 0.793\n",
      "Epoch 50 - Loss: 0.542811393737793 - Accuracy: 0.811\n",
      "Epoch 51 - Loss: 0.5349118113517761 - Accuracy: 0.847\n",
      "Epoch 52 - Loss: 0.5182403922080994 - Accuracy: 0.856\n",
      "Epoch 53 - Loss: 0.5247263312339783 - Accuracy: 0.838\n",
      "Epoch 54 - Loss: 0.5181638598442078 - Accuracy: 0.820\n",
      "Epoch 55 - Loss: 0.5065180063247681 - Accuracy: 0.829\n",
      "Epoch 56 - Loss: 0.5118213891983032 - Accuracy: 0.802\n",
      "Epoch 57 - Loss: 0.49647098779678345 - Accuracy: 0.820\n",
      "Epoch 58 - Loss: 0.48275986313819885 - Accuracy: 0.847\n",
      "Epoch 59 - Loss: 0.4750197231769562 - Accuracy: 0.856\n",
      "Epoch 60 - Loss: 0.46881717443466187 - Accuracy: 0.847\n",
      "Epoch 61 - Loss: 0.46402809023857117 - Accuracy: 0.847\n",
      "Epoch 62 - Loss: 0.4501599967479706 - Accuracy: 0.865\n",
      "Epoch 63 - Loss: 0.4373258352279663 - Accuracy: 0.865\n",
      "Epoch 64 - Loss: 0.4400765001773834 - Accuracy: 0.892\n",
      "Epoch 65 - Loss: 0.43827715516090393 - Accuracy: 0.865\n",
      "Epoch 66 - Loss: 0.4341434836387634 - Accuracy: 0.802\n",
      "Epoch 67 - Loss: 0.41401416063308716 - Accuracy: 0.892\n",
      "Epoch 68 - Loss: 0.42359134554862976 - Accuracy: 0.874\n",
      "Epoch 69 - Loss: 0.4095635414123535 - Accuracy: 0.865\n",
      "Epoch 70 - Loss: 0.3989969789981842 - Accuracy: 0.856\n",
      "Epoch 71 - Loss: 0.38701826333999634 - Accuracy: 0.892\n",
      "Epoch 72 - Loss: 0.3868962824344635 - Accuracy: 0.865\n",
      "Epoch 73 - Loss: 0.37516576051712036 - Accuracy: 0.910\n",
      "Epoch 74 - Loss: 0.3810148537158966 - Accuracy: 0.883\n",
      "Epoch 75 - Loss: 0.3661484122276306 - Accuracy: 0.892\n",
      "Epoch 76 - Loss: 0.36043256521224976 - Accuracy: 0.910\n",
      "Epoch 77 - Loss: 0.3528193235397339 - Accuracy: 0.892\n",
      "Epoch 78 - Loss: 0.3366987407207489 - Accuracy: 0.928\n",
      "Epoch 79 - Loss: 0.34000998735427856 - Accuracy: 0.928\n",
      "Epoch 80 - Loss: 0.35104385018348694 - Accuracy: 0.874\n",
      "Epoch 81 - Loss: 0.3298015296459198 - Accuracy: 0.901\n",
      "Epoch 82 - Loss: 0.3226885497570038 - Accuracy: 0.901\n",
      "Epoch 83 - Loss: 0.3159252107143402 - Accuracy: 0.919\n",
      "Epoch 84 - Loss: 0.3176085948944092 - Accuracy: 0.892\n",
      "Epoch 85 - Loss: 0.291557252407074 - Accuracy: 0.928\n",
      "Epoch 86 - Loss: 0.304237425327301 - Accuracy: 0.910\n",
      "Epoch 87 - Loss: 0.3096252381801605 - Accuracy: 0.919\n",
      "Epoch 88 - Loss: 0.2948274314403534 - Accuracy: 0.901\n",
      "Epoch 89 - Loss: 0.2772175967693329 - Accuracy: 0.928\n",
      "Epoch 90 - Loss: 0.29060131311416626 - Accuracy: 0.910\n",
      "Epoch 91 - Loss: 0.27273163199424744 - Accuracy: 0.919\n",
      "Epoch 92 - Loss: 0.28454187512397766 - Accuracy: 0.910\n",
      "Epoch 93 - Loss: 0.2531690299510956 - Accuracy: 0.937\n",
      "Epoch 94 - Loss: 0.2674295902252197 - Accuracy: 0.910\n",
      "Epoch 95 - Loss: 0.23371173441410065 - Accuracy: 0.946\n",
      "Epoch 96 - Loss: 0.25042492151260376 - Accuracy: 0.928\n",
      "Epoch 97 - Loss: 0.2404901683330536 - Accuracy: 0.946\n",
      "Epoch 98 - Loss: 0.22927913069725037 - Accuracy: 0.928\n",
      "Epoch 99 - Loss: 0.24141976237297058 - Accuracy: 0.919\n",
      "MLP model test accuracy: 0.919\n",
      "Running MLP experiments on ('STRINGdb', 2) data\n",
      "Epoch 0 - Loss: 0.6937879920005798 - Accuracy: 0.505\n",
      "Epoch 1 - Loss: 0.6919754147529602 - Accuracy: 0.505\n",
      "Epoch 2 - Loss: 0.6927511692047119 - Accuracy: 0.505\n",
      "Epoch 3 - Loss: 0.6930583715438843 - Accuracy: 0.505\n",
      "Epoch 4 - Loss: 0.691139817237854 - Accuracy: 0.505\n",
      "Epoch 5 - Loss: 0.6914553046226501 - Accuracy: 0.505\n",
      "Epoch 6 - Loss: 0.6893954873085022 - Accuracy: 0.505\n",
      "Epoch 7 - Loss: 0.6883361339569092 - Accuracy: 0.514\n",
      "Epoch 8 - Loss: 0.6885477304458618 - Accuracy: 0.505\n",
      "Epoch 9 - Loss: 0.6895326375961304 - Accuracy: 0.505\n",
      "Epoch 10 - Loss: 0.686460554599762 - Accuracy: 0.514\n",
      "Epoch 11 - Loss: 0.6846676468849182 - Accuracy: 0.523\n",
      "Epoch 12 - Loss: 0.6867222189903259 - Accuracy: 0.505\n",
      "Epoch 13 - Loss: 0.6854973435401917 - Accuracy: 0.550\n",
      "Epoch 14 - Loss: 0.6805304884910583 - Accuracy: 0.541\n",
      "Epoch 15 - Loss: 0.6815711855888367 - Accuracy: 0.577\n",
      "Epoch 16 - Loss: 0.6798877120018005 - Accuracy: 0.577\n",
      "Epoch 17 - Loss: 0.6776442527770996 - Accuracy: 0.577\n",
      "Epoch 18 - Loss: 0.6781086921691895 - Accuracy: 0.604\n",
      "Epoch 19 - Loss: 0.6761017441749573 - Accuracy: 0.622\n",
      "Epoch 20 - Loss: 0.6749724745750427 - Accuracy: 0.577\n",
      "Epoch 21 - Loss: 0.6722527742385864 - Accuracy: 0.622\n",
      "Epoch 22 - Loss: 0.6722570061683655 - Accuracy: 0.649\n",
      "Epoch 23 - Loss: 0.668438196182251 - Accuracy: 0.640\n",
      "Epoch 24 - Loss: 0.665132462978363 - Accuracy: 0.649\n",
      "Epoch 25 - Loss: 0.6699162125587463 - Accuracy: 0.604\n",
      "Epoch 26 - Loss: 0.6644214391708374 - Accuracy: 0.622\n",
      "Epoch 27 - Loss: 0.6665003299713135 - Accuracy: 0.676\n",
      "Epoch 28 - Loss: 0.6618773341178894 - Accuracy: 0.703\n",
      "Epoch 29 - Loss: 0.6587523818016052 - Accuracy: 0.667\n",
      "Epoch 30 - Loss: 0.6534296870231628 - Accuracy: 0.721\n",
      "Epoch 31 - Loss: 0.6533460021018982 - Accuracy: 0.667\n",
      "Epoch 32 - Loss: 0.6539489030838013 - Accuracy: 0.685\n",
      "Epoch 33 - Loss: 0.6499588489532471 - Accuracy: 0.739\n",
      "Epoch 34 - Loss: 0.6461202502250671 - Accuracy: 0.703\n",
      "Epoch 35 - Loss: 0.6386165618896484 - Accuracy: 0.739\n",
      "Epoch 36 - Loss: 0.6299680471420288 - Accuracy: 0.748\n",
      "Epoch 37 - Loss: 0.6268705725669861 - Accuracy: 0.757\n",
      "Epoch 38 - Loss: 0.6212822794914246 - Accuracy: 0.757\n",
      "Epoch 39 - Loss: 0.62940514087677 - Accuracy: 0.703\n",
      "Epoch 40 - Loss: 0.6265046000480652 - Accuracy: 0.721\n",
      "Epoch 41 - Loss: 0.6123311519622803 - Accuracy: 0.775\n",
      "Epoch 42 - Loss: 0.6112107038497925 - Accuracy: 0.739\n",
      "Epoch 43 - Loss: 0.6114516854286194 - Accuracy: 0.712\n",
      "Epoch 44 - Loss: 0.606781005859375 - Accuracy: 0.748\n",
      "Epoch 45 - Loss: 0.5922855138778687 - Accuracy: 0.712\n",
      "Epoch 46 - Loss: 0.5933694839477539 - Accuracy: 0.766\n",
      "Epoch 47 - Loss: 0.5801610350608826 - Accuracy: 0.793\n",
      "Epoch 48 - Loss: 0.5886294841766357 - Accuracy: 0.784\n",
      "Epoch 49 - Loss: 0.573838472366333 - Accuracy: 0.775\n",
      "Epoch 50 - Loss: 0.558285117149353 - Accuracy: 0.757\n",
      "Epoch 51 - Loss: 0.5671654343605042 - Accuracy: 0.775\n",
      "Epoch 52 - Loss: 0.5646873712539673 - Accuracy: 0.766\n",
      "Epoch 53 - Loss: 0.5644044876098633 - Accuracy: 0.757\n",
      "Epoch 54 - Loss: 0.537822425365448 - Accuracy: 0.802\n",
      "Epoch 55 - Loss: 0.54342120885849 - Accuracy: 0.775\n",
      "Epoch 56 - Loss: 0.5252848863601685 - Accuracy: 0.775\n",
      "Epoch 57 - Loss: 0.5225993394851685 - Accuracy: 0.829\n",
      "Epoch 58 - Loss: 0.5254481434822083 - Accuracy: 0.775\n",
      "Epoch 59 - Loss: 0.5147967338562012 - Accuracy: 0.766\n",
      "Epoch 60 - Loss: 0.5252377986907959 - Accuracy: 0.829\n",
      "Epoch 61 - Loss: 0.4997651278972626 - Accuracy: 0.829\n",
      "Epoch 62 - Loss: 0.49465861916542053 - Accuracy: 0.802\n",
      "Epoch 63 - Loss: 0.49285998940467834 - Accuracy: 0.820\n",
      "Epoch 64 - Loss: 0.4803875982761383 - Accuracy: 0.820\n",
      "Epoch 65 - Loss: 0.488735556602478 - Accuracy: 0.802\n",
      "Epoch 66 - Loss: 0.4686111807823181 - Accuracy: 0.838\n",
      "Epoch 67 - Loss: 0.46554020047187805 - Accuracy: 0.811\n",
      "Epoch 68 - Loss: 0.45280158519744873 - Accuracy: 0.793\n",
      "Epoch 69 - Loss: 0.44106239080429077 - Accuracy: 0.838\n",
      "Epoch 70 - Loss: 0.44428694248199463 - Accuracy: 0.829\n",
      "Epoch 71 - Loss: 0.43737149238586426 - Accuracy: 0.838\n",
      "Epoch 72 - Loss: 0.43589553236961365 - Accuracy: 0.829\n",
      "Epoch 73 - Loss: 0.4405388832092285 - Accuracy: 0.829\n",
      "Epoch 74 - Loss: 0.4257441759109497 - Accuracy: 0.829\n",
      "Epoch 75 - Loss: 0.42663195729255676 - Accuracy: 0.829\n",
      "Epoch 76 - Loss: 0.41504526138305664 - Accuracy: 0.829\n",
      "Epoch 77 - Loss: 0.39401859045028687 - Accuracy: 0.856\n",
      "Epoch 78 - Loss: 0.40150895714759827 - Accuracy: 0.829\n",
      "Epoch 79 - Loss: 0.3940901756286621 - Accuracy: 0.829\n",
      "Epoch 80 - Loss: 0.4073036015033722 - Accuracy: 0.838\n",
      "Epoch 81 - Loss: 0.37419450283050537 - Accuracy: 0.856\n",
      "Epoch 82 - Loss: 0.38142791390419006 - Accuracy: 0.838\n",
      "Epoch 83 - Loss: 0.3709852397441864 - Accuracy: 0.856\n",
      "Epoch 84 - Loss: 0.3555240333080292 - Accuracy: 0.874\n",
      "Epoch 85 - Loss: 0.35730797052383423 - Accuracy: 0.874\n",
      "Epoch 86 - Loss: 0.3511603772640228 - Accuracy: 0.874\n",
      "Epoch 87 - Loss: 0.3493894338607788 - Accuracy: 0.892\n",
      "Epoch 88 - Loss: 0.35103660821914673 - Accuracy: 0.883\n",
      "Epoch 89 - Loss: 0.36095502972602844 - Accuracy: 0.856\n",
      "Epoch 90 - Loss: 0.34958416223526 - Accuracy: 0.838\n",
      "Epoch 91 - Loss: 0.3457008898258209 - Accuracy: 0.883\n",
      "Epoch 92 - Loss: 0.32460805773735046 - Accuracy: 0.883\n",
      "Epoch 93 - Loss: 0.3246430456638336 - Accuracy: 0.892\n",
      "Epoch 94 - Loss: 0.3148278594017029 - Accuracy: 0.883\n",
      "Epoch 95 - Loss: 0.31559717655181885 - Accuracy: 0.883\n",
      "Epoch 96 - Loss: 0.3249073922634125 - Accuracy: 0.901\n",
      "Epoch 97 - Loss: 0.32120466232299805 - Accuracy: 0.901\n",
      "Epoch 98 - Loss: 0.30132588744163513 - Accuracy: 0.892\n",
      "Epoch 99 - Loss: 0.29270732402801514 - Accuracy: 0.919\n",
      "MLP model test accuracy: 0.919\n"
     ]
    }
   ],
   "source": [
    "mlp_results_multi_seed = {}\n",
    "seeds = [0,1,2]\n",
    "for ppi in ppis:\n",
    "    for seed in seeds:\n",
    "        mask_train = data[ppi, seed].train_mask.squeeze()  \n",
    "        mask_test = data[ppi, seed].test_mask.squeeze()\n",
    "\n",
    "        X_train = torch.tensor(data[ppi, seed].x[mask_train].numpy(), dtype=torch.float32)\n",
    "        y_train = torch.tensor([y.item() for yz in data[ppi, seed].y[mask_train] for y in yz], dtype=torch.long)\n",
    "        X_test = torch.tensor(data[ppi, seed].x[mask_test].numpy(), dtype=torch.float32)  \n",
    "        y_test = torch.tensor([y.item() for yz in data[ppi, seed].y[mask_test] for y in yz], dtype=torch.long)\n",
    "\n",
    "        print(f\"Running MLP experiments on {ppi, seed} data\")\n",
    "        models, test_acc, test_auroc, test_aupr,test_f1, _ = train_mlp(X_train, X_test, y_train, y_test)\n",
    "        mlp_results_multi_seed[ppi, seed] = (test_acc, test_auroc, test_aupr,test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('CPDB', 0): (0.7777777777777778,\n",
       "  np.float64(0.7777777777777777),\n",
       "  np.float64(0.7380952380952381),\n",
       "  np.float64(0.75)),\n",
       " ('CPDB', 1): (0.7222222222222222,\n",
       "  np.float64(0.7222222222222223),\n",
       "  np.float64(0.6746031746031746),\n",
       "  np.float64(0.6875)),\n",
       " ('CPDB', 2): (0.6666666666666666,\n",
       "  np.float64(0.6666666666666667),\n",
       "  np.float64(0.6111111111111112),\n",
       "  np.float64(0.6666666666666666)),\n",
       " ('IRefIndex', 0): (0.7837837837837838,\n",
       "  np.float64(0.7792397660818714),\n",
       "  np.float64(0.7493743743743744),\n",
       "  np.float64(0.7333333333333333)),\n",
       " ('IRefIndex', 1): (0.7297297297297297,\n",
       "  np.float64(0.7339181286549707),\n",
       "  np.float64(0.7060947587263376),\n",
       "  np.float64(0.6875)),\n",
       " ('IRefIndex', 2): (0.7837837837837838,\n",
       "  np.float64(0.7821637426900584),\n",
       "  np.float64(0.7219406906906907),\n",
       "  np.float64(0.7647058823529411)),\n",
       " ('IRefIndex_2015', 0): (0.8235294117647058,\n",
       "  np.float64(0.8235294117647058),\n",
       "  np.float64(0.7554179566563467),\n",
       "  np.float64(0.8333333333333334)),\n",
       " ('IRefIndex_2015', 1): (0.7647058823529411,\n",
       "  np.float64(0.7647058823529411),\n",
       "  np.float64(0.7117647058823531),\n",
       "  np.float64(0.75)),\n",
       " ('IRefIndex_2015', 2): (0.6176470588235294,\n",
       "  np.float64(0.6176470588235294),\n",
       "  np.float64(0.588235294117647),\n",
       "  np.float64(0.48)),\n",
       " ('PCNet', 0): (0.6842105263157895,\n",
       "  np.float64(0.6842105263157895),\n",
       "  np.float64(0.6350877192982456),\n",
       "  np.float64(0.6470588235294118)),\n",
       " ('PCNet', 1): (0.6052631578947368,\n",
       "  np.float64(0.6052631578947368),\n",
       "  np.float64(0.5657894736842105),\n",
       "  np.float64(0.5714285714285714)),\n",
       " ('PCNet', 2): (0.8157894736842105,\n",
       "  np.float64(0.8157894736842104),\n",
       "  np.float64(0.7526315789473684),\n",
       "  np.float64(0.8205128205128205)),\n",
       " ('STRINGdb', 0): (0.8,\n",
       "  np.float64(0.8022875816993464),\n",
       "  np.float64(0.7189075630252101),\n",
       "  np.float64(0.8108108108108109)),\n",
       " ('STRINGdb', 1): (0.6571428571428571,\n",
       "  np.float64(0.6584967320261438),\n",
       "  np.float64(0.6201388888888889),\n",
       "  np.float64(0.6470588235294118)),\n",
       " ('STRINGdb', 2): (0.7428571428571429,\n",
       "  np.float64(0.7401960784313726),\n",
       "  np.float64(0.6798319327731092),\n",
       "  np.float64(0.7096774193548387))}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results_multi_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for CPDB: 0.722 ±0.045\n",
      "Mean AUC for CPDB: 0.722 ±0.045\n",
      "Mean AUPR for CPDB: 0.675 ±0.052\n",
      "Mean F1 for CPDB: 0.701 ±0.035\n",
      "Mean accuracy for IRefIndex: 0.766 ±0.025\n",
      "Mean AUC for IRefIndex: 0.765 ±0.022\n",
      "Mean AUPR for IRefIndex: 0.726 ±0.018\n",
      "Mean F1 for IRefIndex: 0.729 ±0.032\n",
      "Mean accuracy for IRefIndex_2015: 0.735 ±0.087\n",
      "Mean AUC for IRefIndex_2015: 0.735 ±0.087\n",
      "Mean AUPR for IRefIndex_2015: 0.685 ±0.071\n",
      "Mean F1 for IRefIndex_2015: 0.688 ±0.151\n",
      "Mean accuracy for PCNet: 0.702 ±0.087\n",
      "Mean AUC for PCNet: 0.702 ±0.087\n",
      "Mean AUPR for PCNet: 0.651 ±0.077\n",
      "Mean F1 for PCNet: 0.680 ±0.104\n",
      "Mean accuracy for STRINGdb: 0.733 ±0.059\n",
      "Mean AUC for STRINGdb: 0.734 ±0.059\n",
      "Mean AUPR for STRINGdb: 0.673 ±0.041\n",
      "Mean F1 for STRINGdb: 0.723 ±0.067\n"
     ]
    }
   ],
   "source": [
    "mlp_results_multi_seed_df = pd.DataFrame(columns=[\n",
    "    'PPI', 'Mean Accuracy', 'Std Accuracy', \n",
    "    'Mean AUC', 'Std AUC', 'Mean AUPR', 'Std AUPR', 'Mean F1', 'Std F1'\n",
    "    ])\n",
    "\n",
    "for i, ppi in enumerate(ppis):\n",
    "    acc_ppi = []\n",
    "    auc_ppi = []\n",
    "    aupr_ppi =[]\n",
    "    f1_ppi = []\n",
    "    for seed in seeds:\n",
    "        #print(f'Accuracy for {ppi,seed}: {mlp_results_multi_seed[ppi, seed][0]}')\n",
    "        acc_ppi.append(mlp_results_multi_seed[ppi, seed][0])\n",
    "        auc_ppi.append(mlp_results_multi_seed[ppi, seed][1])\n",
    "        aupr_ppi.append(mlp_results_multi_seed[ppi, seed][2])\n",
    "        f1_ppi.append(mlp_results_multi_seed[ppi, seed][3])\n",
    "    mean_acc = np.mean(acc_ppi)\n",
    "    std_acc = np.std(acc_ppi)\n",
    "    mean_auc = np.mean(auc_ppi)\n",
    "    std_auc = np.std(auc_ppi)\n",
    "    mean_aupr = np.mean(aupr_ppi)\n",
    "    std_aupr = np.std(aupr_ppi)\n",
    "    mean_f1 = np.mean(f1_ppi)\n",
    "    std_f1 = np.std(f1_ppi)\n",
    "\n",
    "    print(f\"Mean accuracy for {ppi}: {mean_acc:.3f} ±{std_acc:.3f}\")\n",
    "    print(f\"Mean AUC for {ppi}: {mean_auc:.3f} ±{std_auc:.3f}\")\n",
    "    print(f\"Mean AUPR for {ppi}: {mean_aupr:.3f} ±{std_aupr:.3f}\")\n",
    "    print(f\"Mean F1 for {ppi}: {mean_f1:.3f} ±{std_f1:.3f}\")\n",
    "\n",
    "    mlp_results_multi_seed_df.loc[i] = [\n",
    "        ppi, mean_acc, std_acc, mean_auc, std_auc, mean_aupr, std_aupr, mean_f1, std_f1\n",
    "    ]\n",
    "\n",
    "mlp_results_multi_seed_df.to_csv('../results/mlp_results_upd.tsv', sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPI</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Std Accuracy</th>\n",
       "      <th>Mean AUC</th>\n",
       "      <th>Std AUC</th>\n",
       "      <th>Mean AUPR</th>\n",
       "      <th>Std AUPR</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Std F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPDB</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.045361</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.045361</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.051841</td>\n",
       "      <td>0.701389</td>\n",
       "      <td>0.035410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRefIndex</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>0.765107</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>0.725803</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.728513</td>\n",
       "      <td>0.031703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRefIndex_2015</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.086586</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.086586</td>\n",
       "      <td>0.685139</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>0.687778</td>\n",
       "      <td>0.150809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCNet</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.086838</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.086838</td>\n",
       "      <td>0.651170</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.104270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STRINGdb</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.058709</td>\n",
       "      <td>0.733660</td>\n",
       "      <td>0.058884</td>\n",
       "      <td>0.672959</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>0.722516</td>\n",
       "      <td>0.067465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PPI  Mean Accuracy  Std Accuracy  Mean AUC   Std AUC  Mean AUPR  \\\n",
       "0            CPDB       0.722222      0.045361  0.722222  0.045361   0.674603   \n",
       "1       IRefIndex       0.765766      0.025481  0.765107  0.022086   0.725803   \n",
       "2  IRefIndex_2015       0.735294      0.086586  0.735294  0.086586   0.685139   \n",
       "3           PCNet       0.701754      0.086838  0.701754  0.086838   0.651170   \n",
       "4        STRINGdb       0.733333      0.058709  0.733660  0.058884   0.672959   \n",
       "\n",
       "   Std AUPR   Mean F1    Std F1  \n",
       "0  0.051841  0.701389  0.035410  \n",
       "1  0.017879  0.728513  0.031703  \n",
       "2  0.070801  0.687778  0.150809  \n",
       "3  0.077121  0.679667  0.104270  \n",
       "4  0.040614  0.722516  0.067465  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results_multi_seed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_experiment(X_train, X_test, y_train, y_test, seeds=[42, 7, 21]):\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    for seed in seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        model, acc, _ = train_mlp(X_train, X_test, y_train, y_test)\n",
    "        accuracies.append(acc)\n",
    "        models.append(model)\n",
    "        print(f\"Seed {seed} - Test Accuracy: {acc:.2f}%\")\n",
    "    avg_acc = np.mean(accuracies)\n",
    "    print(f\"Average Test Accuracy over seeds: {avg_acc:.2f}%\")\n",
    "    return models, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MLP experiments on CPDB data\n",
      "Epoch 0 - Loss: 0.6943416595458984 - Accuracy: 49.57%\n",
      "Epoch 1 - Loss: 0.6936794519424438 - Accuracy: 49.57%\n",
      "Epoch 2 - Loss: 0.6930168271064758 - Accuracy: 49.57%\n",
      "Epoch 3 - Loss: 0.6923506259918213 - Accuracy: 49.57%\n",
      "Epoch 4 - Loss: 0.6916755437850952 - Accuracy: 50.43%\n",
      "Epoch 5 - Loss: 0.6909906268119812 - Accuracy: 50.43%\n",
      "Epoch 6 - Loss: 0.6902964115142822 - Accuracy: 51.30%\n",
      "Epoch 7 - Loss: 0.6895898580551147 - Accuracy: 53.04%\n",
      "Epoch 8 - Loss: 0.6888704895973206 - Accuracy: 63.48%\n",
      "Epoch 9 - Loss: 0.6881344318389893 - Accuracy: 68.70%\n",
      "Epoch 10 - Loss: 0.6873695254325867 - Accuracy: 74.78%\n",
      "Epoch 11 - Loss: 0.6865664720535278 - Accuracy: 78.26%\n",
      "Epoch 12 - Loss: 0.6857249140739441 - Accuracy: 75.65%\n",
      "Epoch 13 - Loss: 0.6848435401916504 - Accuracy: 76.52%\n",
      "Epoch 14 - Loss: 0.683896541595459 - Accuracy: 75.65%\n",
      "Epoch 15 - Loss: 0.6828877329826355 - Accuracy: 78.26%\n",
      "Epoch 16 - Loss: 0.6818037629127502 - Accuracy: 79.13%\n",
      "Epoch 17 - Loss: 0.6806365847587585 - Accuracy: 78.26%\n",
      "Epoch 18 - Loss: 0.6793779730796814 - Accuracy: 77.39%\n",
      "Epoch 19 - Loss: 0.6780444383621216 - Accuracy: 76.52%\n",
      "Epoch 20 - Loss: 0.6766065955162048 - Accuracy: 76.52%\n",
      "Epoch 21 - Loss: 0.6750507950782776 - Accuracy: 77.39%\n",
      "Epoch 22 - Loss: 0.6733874678611755 - Accuracy: 77.39%\n",
      "Epoch 23 - Loss: 0.6715996265411377 - Accuracy: 76.52%\n",
      "Epoch 24 - Loss: 0.669669508934021 - Accuracy: 76.52%\n",
      "Epoch 25 - Loss: 0.6675733327865601 - Accuracy: 75.65%\n",
      "Epoch 26 - Loss: 0.6653305888175964 - Accuracy: 75.65%\n",
      "Epoch 27 - Loss: 0.6629425287246704 - Accuracy: 75.65%\n",
      "Epoch 28 - Loss: 0.660417377948761 - Accuracy: 76.52%\n",
      "Epoch 29 - Loss: 0.6577185988426208 - Accuracy: 76.52%\n",
      "Epoch 30 - Loss: 0.6548168063163757 - Accuracy: 75.65%\n",
      "Epoch 31 - Loss: 0.6517210602760315 - Accuracy: 75.65%\n",
      "Epoch 32 - Loss: 0.6484212875366211 - Accuracy: 76.52%\n",
      "Epoch 33 - Loss: 0.6449331641197205 - Accuracy: 76.52%\n",
      "Epoch 34 - Loss: 0.6412493586540222 - Accuracy: 78.26%\n",
      "Epoch 35 - Loss: 0.6373561024665833 - Accuracy: 79.13%\n",
      "Epoch 36 - Loss: 0.6332482099533081 - Accuracy: 78.26%\n",
      "Epoch 37 - Loss: 0.628924548625946 - Accuracy: 78.26%\n",
      "Epoch 38 - Loss: 0.6243715882301331 - Accuracy: 79.13%\n",
      "Epoch 39 - Loss: 0.6195858120918274 - Accuracy: 79.13%\n",
      "Epoch 40 - Loss: 0.6145819425582886 - Accuracy: 79.13%\n",
      "Epoch 41 - Loss: 0.6093408465385437 - Accuracy: 80.00%\n",
      "Epoch 42 - Loss: 0.6038371920585632 - Accuracy: 80.00%\n",
      "Epoch 43 - Loss: 0.5980786681175232 - Accuracy: 80.00%\n",
      "Epoch 44 - Loss: 0.5921054482460022 - Accuracy: 80.00%\n",
      "Epoch 45 - Loss: 0.585910439491272 - Accuracy: 80.87%\n",
      "Epoch 46 - Loss: 0.5795416831970215 - Accuracy: 81.74%\n",
      "Epoch 47 - Loss: 0.5729787945747375 - Accuracy: 81.74%\n",
      "Epoch 48 - Loss: 0.5662177801132202 - Accuracy: 80.87%\n",
      "Epoch 49 - Loss: 0.5592664480209351 - Accuracy: 80.87%\n",
      "Epoch 50 - Loss: 0.5521483421325684 - Accuracy: 82.61%\n",
      "Epoch 51 - Loss: 0.5448915362358093 - Accuracy: 82.61%\n",
      "Epoch 52 - Loss: 0.5374988317489624 - Accuracy: 82.61%\n",
      "Epoch 53 - Loss: 0.529999315738678 - Accuracy: 82.61%\n",
      "Epoch 54 - Loss: 0.5223957300186157 - Accuracy: 82.61%\n",
      "Epoch 55 - Loss: 0.5147127509117126 - Accuracy: 82.61%\n",
      "Epoch 56 - Loss: 0.5069718956947327 - Accuracy: 82.61%\n",
      "Epoch 57 - Loss: 0.4991952180862427 - Accuracy: 83.48%\n",
      "Epoch 58 - Loss: 0.49139177799224854 - Accuracy: 85.22%\n",
      "Epoch 59 - Loss: 0.48358896374702454 - Accuracy: 85.22%\n",
      "Epoch 60 - Loss: 0.47579753398895264 - Accuracy: 85.22%\n",
      "Epoch 61 - Loss: 0.4679987132549286 - Accuracy: 84.35%\n",
      "Epoch 62 - Loss: 0.46022504568099976 - Accuracy: 84.35%\n",
      "Epoch 63 - Loss: 0.45247259736061096 - Accuracy: 84.35%\n",
      "Epoch 64 - Loss: 0.4447610676288605 - Accuracy: 84.35%\n",
      "Epoch 65 - Loss: 0.437037855386734 - Accuracy: 84.35%\n",
      "Epoch 66 - Loss: 0.429397314786911 - Accuracy: 85.22%\n",
      "Epoch 67 - Loss: 0.4218408465385437 - Accuracy: 85.22%\n",
      "Epoch 68 - Loss: 0.41439366340637207 - Accuracy: 85.22%\n",
      "Epoch 69 - Loss: 0.40705814957618713 - Accuracy: 86.96%\n",
      "Epoch 70 - Loss: 0.3998146653175354 - Accuracy: 86.96%\n",
      "Epoch 71 - Loss: 0.3926631212234497 - Accuracy: 86.96%\n",
      "Epoch 72 - Loss: 0.38562655448913574 - Accuracy: 86.96%\n",
      "Epoch 73 - Loss: 0.3786912262439728 - Accuracy: 86.96%\n",
      "Epoch 74 - Loss: 0.3718720078468323 - Accuracy: 86.09%\n",
      "Epoch 75 - Loss: 0.3651483356952667 - Accuracy: 86.09%\n",
      "Epoch 76 - Loss: 0.35856306552886963 - Accuracy: 86.09%\n",
      "Epoch 77 - Loss: 0.3520582914352417 - Accuracy: 86.09%\n",
      "Epoch 78 - Loss: 0.34563568234443665 - Accuracy: 86.96%\n",
      "Epoch 79 - Loss: 0.3393248915672302 - Accuracy: 86.96%\n",
      "Epoch 80 - Loss: 0.33314037322998047 - Accuracy: 86.96%\n",
      "Epoch 81 - Loss: 0.32706740498542786 - Accuracy: 88.70%\n",
      "Epoch 82 - Loss: 0.3211168348789215 - Accuracy: 88.70%\n",
      "Epoch 83 - Loss: 0.3152939975261688 - Accuracy: 88.70%\n",
      "Epoch 84 - Loss: 0.3096023499965668 - Accuracy: 88.70%\n",
      "Epoch 85 - Loss: 0.30403050780296326 - Accuracy: 88.70%\n",
      "Epoch 86 - Loss: 0.2985859811306 - Accuracy: 89.57%\n",
      "Epoch 87 - Loss: 0.2932536005973816 - Accuracy: 89.57%\n",
      "Epoch 88 - Loss: 0.2880280315876007 - Accuracy: 89.57%\n",
      "Epoch 89 - Loss: 0.28290697932243347 - Accuracy: 89.57%\n",
      "Epoch 90 - Loss: 0.2779029905796051 - Accuracy: 89.57%\n",
      "Epoch 91 - Loss: 0.2730139493942261 - Accuracy: 89.57%\n",
      "Epoch 92 - Loss: 0.26824644207954407 - Accuracy: 89.57%\n",
      "Epoch 93 - Loss: 0.263586163520813 - Accuracy: 89.57%\n",
      "Epoch 94 - Loss: 0.2590330243110657 - Accuracy: 90.43%\n",
      "Epoch 95 - Loss: 0.2545830011367798 - Accuracy: 90.43%\n",
      "Epoch 96 - Loss: 0.2502250373363495 - Accuracy: 90.43%\n",
      "Epoch 97 - Loss: 0.2459549903869629 - Accuracy: 90.43%\n",
      "Epoch 98 - Loss: 0.2417517453432083 - Accuracy: 90.43%\n",
      "Epoch 99 - Loss: 0.2376249134540558 - Accuracy: 90.43%\n",
      "MLP model test accuracy: 66.67%\n",
      "Seed 42 - Test Accuracy: 66.67%\n",
      "Epoch 0 - Loss: 0.6936178207397461 - Accuracy: 50.43%\n",
      "Epoch 1 - Loss: 0.6924362182617188 - Accuracy: 50.43%\n",
      "Epoch 2 - Loss: 0.6912994980812073 - Accuracy: 50.43%\n",
      "Epoch 3 - Loss: 0.690155565738678 - Accuracy: 50.43%\n",
      "Epoch 4 - Loss: 0.6889937520027161 - Accuracy: 50.43%\n",
      "Epoch 5 - Loss: 0.6878378391265869 - Accuracy: 50.43%\n",
      "Epoch 6 - Loss: 0.6866351366043091 - Accuracy: 50.43%\n",
      "Epoch 7 - Loss: 0.6853845119476318 - Accuracy: 50.43%\n",
      "Epoch 8 - Loss: 0.6840519905090332 - Accuracy: 50.43%\n",
      "Epoch 9 - Loss: 0.6826600432395935 - Accuracy: 50.43%\n",
      "Epoch 10 - Loss: 0.6811914443969727 - Accuracy: 51.30%\n",
      "Epoch 11 - Loss: 0.679633617401123 - Accuracy: 51.30%\n",
      "Epoch 12 - Loss: 0.6780297756195068 - Accuracy: 54.78%\n",
      "Epoch 13 - Loss: 0.676372766494751 - Accuracy: 60.87%\n",
      "Epoch 14 - Loss: 0.6746478080749512 - Accuracy: 61.74%\n",
      "Epoch 15 - Loss: 0.6728352308273315 - Accuracy: 63.48%\n",
      "Epoch 16 - Loss: 0.6709008812904358 - Accuracy: 66.96%\n",
      "Epoch 17 - Loss: 0.6688456535339355 - Accuracy: 68.70%\n",
      "Epoch 18 - Loss: 0.6666424870491028 - Accuracy: 73.04%\n",
      "Epoch 19 - Loss: 0.6642881035804749 - Accuracy: 75.65%\n",
      "Epoch 20 - Loss: 0.6617660522460938 - Accuracy: 77.39%\n",
      "Epoch 21 - Loss: 0.6590616106987 - Accuracy: 79.13%\n",
      "Epoch 22 - Loss: 0.6561952829360962 - Accuracy: 78.26%\n",
      "Epoch 23 - Loss: 0.6531918048858643 - Accuracy: 79.13%\n",
      "Epoch 24 - Loss: 0.6500207185745239 - Accuracy: 79.13%\n",
      "Epoch 25 - Loss: 0.6466943621635437 - Accuracy: 79.13%\n",
      "Epoch 26 - Loss: 0.6432068943977356 - Accuracy: 80.00%\n",
      "Epoch 27 - Loss: 0.6395537257194519 - Accuracy: 80.87%\n",
      "Epoch 28 - Loss: 0.6357333660125732 - Accuracy: 82.61%\n",
      "Epoch 29 - Loss: 0.6317228078842163 - Accuracy: 82.61%\n",
      "Epoch 30 - Loss: 0.62750244140625 - Accuracy: 82.61%\n",
      "Epoch 31 - Loss: 0.6230741143226624 - Accuracy: 82.61%\n",
      "Epoch 32 - Loss: 0.6184201836585999 - Accuracy: 82.61%\n",
      "Epoch 33 - Loss: 0.6135226488113403 - Accuracy: 83.48%\n",
      "Epoch 34 - Loss: 0.6083813309669495 - Accuracy: 83.48%\n",
      "Epoch 35 - Loss: 0.603020429611206 - Accuracy: 84.35%\n",
      "Epoch 36 - Loss: 0.5974297523498535 - Accuracy: 86.09%\n",
      "Epoch 37 - Loss: 0.5916458368301392 - Accuracy: 86.09%\n",
      "Epoch 38 - Loss: 0.5856480002403259 - Accuracy: 84.35%\n",
      "Epoch 39 - Loss: 0.5794005393981934 - Accuracy: 85.22%\n",
      "Epoch 40 - Loss: 0.5729329586029053 - Accuracy: 86.09%\n",
      "Epoch 41 - Loss: 0.5662288069725037 - Accuracy: 86.09%\n",
      "Epoch 42 - Loss: 0.5593134164810181 - Accuracy: 86.09%\n",
      "Epoch 43 - Loss: 0.5521991848945618 - Accuracy: 86.09%\n",
      "Epoch 44 - Loss: 0.5448609590530396 - Accuracy: 86.09%\n",
      "Epoch 45 - Loss: 0.5373870134353638 - Accuracy: 86.09%\n",
      "Epoch 46 - Loss: 0.5297493934631348 - Accuracy: 86.09%\n",
      "Epoch 47 - Loss: 0.5219346284866333 - Accuracy: 86.09%\n",
      "Epoch 48 - Loss: 0.5140010118484497 - Accuracy: 86.96%\n",
      "Epoch 49 - Loss: 0.50594162940979 - Accuracy: 87.83%\n",
      "Epoch 50 - Loss: 0.49779170751571655 - Accuracy: 86.96%\n",
      "Epoch 51 - Loss: 0.48953309655189514 - Accuracy: 86.96%\n",
      "Epoch 52 - Loss: 0.48123764991760254 - Accuracy: 86.96%\n",
      "Epoch 53 - Loss: 0.47292062640190125 - Accuracy: 86.96%\n",
      "Epoch 54 - Loss: 0.4645999073982239 - Accuracy: 86.96%\n",
      "Epoch 55 - Loss: 0.4563012719154358 - Accuracy: 86.96%\n",
      "Epoch 56 - Loss: 0.44801631569862366 - Accuracy: 87.83%\n",
      "Epoch 57 - Loss: 0.4397779405117035 - Accuracy: 87.83%\n",
      "Epoch 58 - Loss: 0.431610643863678 - Accuracy: 87.83%\n",
      "Epoch 59 - Loss: 0.4235439896583557 - Accuracy: 87.83%\n",
      "Epoch 60 - Loss: 0.4155595004558563 - Accuracy: 87.83%\n",
      "Epoch 61 - Loss: 0.40766608715057373 - Accuracy: 87.83%\n",
      "Epoch 62 - Loss: 0.3998893201351166 - Accuracy: 87.83%\n",
      "Epoch 63 - Loss: 0.3922368586063385 - Accuracy: 87.83%\n",
      "Epoch 64 - Loss: 0.3847236633300781 - Accuracy: 87.83%\n",
      "Epoch 65 - Loss: 0.37731224298477173 - Accuracy: 88.70%\n",
      "Epoch 66 - Loss: 0.3700340688228607 - Accuracy: 89.57%\n",
      "Epoch 67 - Loss: 0.3628929555416107 - Accuracy: 89.57%\n",
      "Epoch 68 - Loss: 0.3558892607688904 - Accuracy: 89.57%\n",
      "Epoch 69 - Loss: 0.34900280833244324 - Accuracy: 89.57%\n",
      "Epoch 70 - Loss: 0.3422504663467407 - Accuracy: 88.70%\n",
      "Epoch 71 - Loss: 0.3356631398200989 - Accuracy: 87.83%\n",
      "Epoch 72 - Loss: 0.3292069435119629 - Accuracy: 88.70%\n",
      "Epoch 73 - Loss: 0.32290443778038025 - Accuracy: 88.70%\n",
      "Epoch 74 - Loss: 0.3167518079280853 - Accuracy: 88.70%\n",
      "Epoch 75 - Loss: 0.3107365667819977 - Accuracy: 88.70%\n",
      "Epoch 76 - Loss: 0.30484798550605774 - Accuracy: 87.83%\n",
      "Epoch 77 - Loss: 0.2990969717502594 - Accuracy: 87.83%\n",
      "Epoch 78 - Loss: 0.29347628355026245 - Accuracy: 87.83%\n",
      "Epoch 79 - Loss: 0.2880110442638397 - Accuracy: 87.83%\n",
      "Epoch 80 - Loss: 0.2826494574546814 - Accuracy: 88.70%\n",
      "Epoch 81 - Loss: 0.2774004340171814 - Accuracy: 88.70%\n",
      "Epoch 82 - Loss: 0.2722625732421875 - Accuracy: 88.70%\n",
      "Epoch 83 - Loss: 0.26726439595222473 - Accuracy: 88.70%\n",
      "Epoch 84 - Loss: 0.2623615562915802 - Accuracy: 89.57%\n",
      "Epoch 85 - Loss: 0.25757503509521484 - Accuracy: 89.57%\n",
      "Epoch 86 - Loss: 0.25288641452789307 - Accuracy: 89.57%\n",
      "Epoch 87 - Loss: 0.24830830097198486 - Accuracy: 89.57%\n",
      "Epoch 88 - Loss: 0.2437959760427475 - Accuracy: 89.57%\n",
      "Epoch 89 - Loss: 0.23934628069400787 - Accuracy: 90.43%\n",
      "Epoch 90 - Loss: 0.2349676489830017 - Accuracy: 90.43%\n",
      "Epoch 91 - Loss: 0.2306755781173706 - Accuracy: 90.43%\n",
      "Epoch 92 - Loss: 0.22647257149219513 - Accuracy: 90.43%\n",
      "Epoch 93 - Loss: 0.22234223783016205 - Accuracy: 91.30%\n",
      "Epoch 94 - Loss: 0.21827048063278198 - Accuracy: 91.30%\n",
      "Epoch 95 - Loss: 0.2142561376094818 - Accuracy: 91.30%\n",
      "Epoch 96 - Loss: 0.21032345294952393 - Accuracy: 92.17%\n",
      "Epoch 97 - Loss: 0.20645594596862793 - Accuracy: 92.17%\n",
      "Epoch 98 - Loss: 0.20262448489665985 - Accuracy: 92.17%\n",
      "Epoch 99 - Loss: 0.19884052872657776 - Accuracy: 92.17%\n",
      "MLP model test accuracy: 66.67%\n",
      "Seed 7 - Test Accuracy: 66.67%\n",
      "Epoch 0 - Loss: 0.698360800743103 - Accuracy: 50.43%\n",
      "Epoch 1 - Loss: 0.697099506855011 - Accuracy: 50.43%\n",
      "Epoch 2 - Loss: 0.6959550976753235 - Accuracy: 50.43%\n",
      "Epoch 3 - Loss: 0.6948943138122559 - Accuracy: 50.43%\n",
      "Epoch 4 - Loss: 0.6938760876655579 - Accuracy: 50.43%\n",
      "Epoch 5 - Loss: 0.692907452583313 - Accuracy: 50.43%\n",
      "Epoch 6 - Loss: 0.6919847130775452 - Accuracy: 50.43%\n",
      "Epoch 7 - Loss: 0.6910887360572815 - Accuracy: 50.43%\n",
      "Epoch 8 - Loss: 0.6901953220367432 - Accuracy: 50.43%\n",
      "Epoch 9 - Loss: 0.6892762780189514 - Accuracy: 50.43%\n",
      "Epoch 10 - Loss: 0.6883216500282288 - Accuracy: 51.30%\n",
      "Epoch 11 - Loss: 0.687296450138092 - Accuracy: 52.17%\n",
      "Epoch 12 - Loss: 0.6862104535102844 - Accuracy: 52.17%\n",
      "Epoch 13 - Loss: 0.6850584149360657 - Accuracy: 53.04%\n",
      "Epoch 14 - Loss: 0.683829665184021 - Accuracy: 54.78%\n",
      "Epoch 15 - Loss: 0.6825416684150696 - Accuracy: 55.65%\n",
      "Epoch 16 - Loss: 0.6811941862106323 - Accuracy: 54.78%\n",
      "Epoch 17 - Loss: 0.6797621250152588 - Accuracy: 56.52%\n",
      "Epoch 18 - Loss: 0.6782302856445312 - Accuracy: 57.39%\n",
      "Epoch 19 - Loss: 0.676584005355835 - Accuracy: 59.13%\n",
      "Epoch 20 - Loss: 0.6748212575912476 - Accuracy: 60.00%\n",
      "Epoch 21 - Loss: 0.6729233264923096 - Accuracy: 64.35%\n",
      "Epoch 22 - Loss: 0.6708759665489197 - Accuracy: 68.70%\n",
      "Epoch 23 - Loss: 0.6686916351318359 - Accuracy: 70.43%\n",
      "Epoch 24 - Loss: 0.6663660407066345 - Accuracy: 73.91%\n",
      "Epoch 25 - Loss: 0.6638662815093994 - Accuracy: 77.39%\n",
      "Epoch 26 - Loss: 0.661171019077301 - Accuracy: 76.52%\n",
      "Epoch 27 - Loss: 0.6582865715026855 - Accuracy: 77.39%\n",
      "Epoch 28 - Loss: 0.6551913022994995 - Accuracy: 78.26%\n",
      "Epoch 29 - Loss: 0.6518910527229309 - Accuracy: 78.26%\n",
      "Epoch 30 - Loss: 0.6483839750289917 - Accuracy: 78.26%\n",
      "Epoch 31 - Loss: 0.644647479057312 - Accuracy: 80.87%\n",
      "Epoch 32 - Loss: 0.6406919956207275 - Accuracy: 80.87%\n",
      "Epoch 33 - Loss: 0.6365418434143066 - Accuracy: 81.74%\n",
      "Epoch 34 - Loss: 0.6321938037872314 - Accuracy: 81.74%\n",
      "Epoch 35 - Loss: 0.6276503801345825 - Accuracy: 80.87%\n",
      "Epoch 36 - Loss: 0.6228894591331482 - Accuracy: 80.87%\n",
      "Epoch 37 - Loss: 0.6178834438323975 - Accuracy: 80.87%\n",
      "Epoch 38 - Loss: 0.6126255393028259 - Accuracy: 80.87%\n",
      "Epoch 39 - Loss: 0.6071122288703918 - Accuracy: 80.87%\n",
      "Epoch 40 - Loss: 0.6013545393943787 - Accuracy: 80.87%\n",
      "Epoch 41 - Loss: 0.5954270958900452 - Accuracy: 80.87%\n",
      "Epoch 42 - Loss: 0.5892197489738464 - Accuracy: 80.87%\n",
      "Epoch 43 - Loss: 0.5827296376228333 - Accuracy: 81.74%\n",
      "Epoch 44 - Loss: 0.5760097503662109 - Accuracy: 81.74%\n",
      "Epoch 45 - Loss: 0.5691143274307251 - Accuracy: 82.61%\n",
      "Epoch 46 - Loss: 0.5620366930961609 - Accuracy: 81.74%\n",
      "Epoch 47 - Loss: 0.5548339486122131 - Accuracy: 80.00%\n",
      "Epoch 48 - Loss: 0.547507107257843 - Accuracy: 80.00%\n",
      "Epoch 49 - Loss: 0.5400601625442505 - Accuracy: 80.00%\n",
      "Epoch 50 - Loss: 0.5324849486351013 - Accuracy: 80.00%\n",
      "Epoch 51 - Loss: 0.5248013138771057 - Accuracy: 80.00%\n",
      "Epoch 52 - Loss: 0.5170453786849976 - Accuracy: 80.87%\n",
      "Epoch 53 - Loss: 0.5092182159423828 - Accuracy: 80.87%\n",
      "Epoch 54 - Loss: 0.5013502836227417 - Accuracy: 81.74%\n",
      "Epoch 55 - Loss: 0.49343472719192505 - Accuracy: 82.61%\n",
      "Epoch 56 - Loss: 0.48549774289131165 - Accuracy: 82.61%\n",
      "Epoch 57 - Loss: 0.4775448739528656 - Accuracy: 82.61%\n",
      "Epoch 58 - Loss: 0.46958136558532715 - Accuracy: 82.61%\n",
      "Epoch 59 - Loss: 0.4616391360759735 - Accuracy: 82.61%\n",
      "Epoch 60 - Loss: 0.45374640822410583 - Accuracy: 82.61%\n",
      "Epoch 61 - Loss: 0.44586455821990967 - Accuracy: 83.48%\n",
      "Epoch 62 - Loss: 0.4379788041114807 - Accuracy: 83.48%\n",
      "Epoch 63 - Loss: 0.4301677346229553 - Accuracy: 83.48%\n",
      "Epoch 64 - Loss: 0.4224494993686676 - Accuracy: 84.35%\n",
      "Epoch 65 - Loss: 0.41478267312049866 - Accuracy: 84.35%\n",
      "Epoch 66 - Loss: 0.4072580337524414 - Accuracy: 85.22%\n",
      "Epoch 67 - Loss: 0.3998495638370514 - Accuracy: 84.35%\n",
      "Epoch 68 - Loss: 0.392581969499588 - Accuracy: 84.35%\n",
      "Epoch 69 - Loss: 0.3854648768901825 - Accuracy: 85.22%\n",
      "Epoch 70 - Loss: 0.378478467464447 - Accuracy: 85.22%\n",
      "Epoch 71 - Loss: 0.3716123700141907 - Accuracy: 85.22%\n",
      "Epoch 72 - Loss: 0.36487510800361633 - Accuracy: 85.22%\n",
      "Epoch 73 - Loss: 0.35828879475593567 - Accuracy: 85.22%\n",
      "Epoch 74 - Loss: 0.3518386781215668 - Accuracy: 85.22%\n",
      "Epoch 75 - Loss: 0.34552615880966187 - Accuracy: 85.22%\n",
      "Epoch 76 - Loss: 0.33936700224876404 - Accuracy: 85.22%\n",
      "Epoch 77 - Loss: 0.33333587646484375 - Accuracy: 85.22%\n",
      "Epoch 78 - Loss: 0.32744792103767395 - Accuracy: 85.22%\n",
      "Epoch 79 - Loss: 0.32170596718788147 - Accuracy: 85.22%\n",
      "Epoch 80 - Loss: 0.31610074639320374 - Accuracy: 86.09%\n",
      "Epoch 81 - Loss: 0.31061917543411255 - Accuracy: 86.09%\n",
      "Epoch 82 - Loss: 0.3052530586719513 - Accuracy: 86.09%\n",
      "Epoch 83 - Loss: 0.3000182509422302 - Accuracy: 86.96%\n",
      "Epoch 84 - Loss: 0.29488998651504517 - Accuracy: 86.96%\n",
      "Epoch 85 - Loss: 0.28987154364585876 - Accuracy: 87.83%\n",
      "Epoch 86 - Loss: 0.2849891781806946 - Accuracy: 88.70%\n",
      "Epoch 87 - Loss: 0.2802591621875763 - Accuracy: 88.70%\n",
      "Epoch 88 - Loss: 0.2756440043449402 - Accuracy: 90.43%\n",
      "Epoch 89 - Loss: 0.27115100622177124 - Accuracy: 90.43%\n",
      "Epoch 90 - Loss: 0.2667735517024994 - Accuracy: 90.43%\n",
      "Epoch 91 - Loss: 0.2625020146369934 - Accuracy: 90.43%\n",
      "Epoch 92 - Loss: 0.25834617018699646 - Accuracy: 90.43%\n",
      "Epoch 93 - Loss: 0.2542876899242401 - Accuracy: 90.43%\n",
      "Epoch 94 - Loss: 0.2503092586994171 - Accuracy: 90.43%\n",
      "Epoch 95 - Loss: 0.24641653895378113 - Accuracy: 90.43%\n",
      "Epoch 96 - Loss: 0.24260182678699493 - Accuracy: 90.43%\n",
      "Epoch 97 - Loss: 0.2388596534729004 - Accuracy: 91.30%\n",
      "Epoch 98 - Loss: 0.23518326878547668 - Accuracy: 91.30%\n",
      "Epoch 99 - Loss: 0.23158474266529083 - Accuracy: 91.30%\n",
      "MLP model test accuracy: 66.67%\n",
      "Seed 21 - Test Accuracy: 66.67%\n",
      "Average Test Accuracy over seeds: 66.67%\n",
      "Running MLP experiments on IRefIndex data\n",
      "Epoch 0 - Loss: 0.6933667063713074 - Accuracy: 49.57%\n",
      "Epoch 1 - Loss: 0.6926152110099792 - Accuracy: 49.57%\n",
      "Epoch 2 - Loss: 0.6918818354606628 - Accuracy: 49.57%\n",
      "Epoch 3 - Loss: 0.6911503672599792 - Accuracy: 49.57%\n",
      "Epoch 4 - Loss: 0.6904039978981018 - Accuracy: 51.28%\n",
      "Epoch 5 - Loss: 0.6896350383758545 - Accuracy: 55.56%\n",
      "Epoch 6 - Loss: 0.6888489723205566 - Accuracy: 58.97%\n",
      "Epoch 7 - Loss: 0.6880210638046265 - Accuracy: 64.96%\n",
      "Epoch 8 - Loss: 0.6871461272239685 - Accuracy: 68.38%\n",
      "Epoch 9 - Loss: 0.6862283945083618 - Accuracy: 69.23%\n",
      "Epoch 10 - Loss: 0.6852474212646484 - Accuracy: 68.38%\n",
      "Epoch 11 - Loss: 0.6842029094696045 - Accuracy: 74.36%\n",
      "Epoch 12 - Loss: 0.6831045746803284 - Accuracy: 78.63%\n",
      "Epoch 13 - Loss: 0.6819584369659424 - Accuracy: 76.07%\n",
      "Epoch 14 - Loss: 0.6807381510734558 - Accuracy: 75.21%\n",
      "Epoch 15 - Loss: 0.6793992519378662 - Accuracy: 70.94%\n",
      "Epoch 16 - Loss: 0.677975058555603 - Accuracy: 70.09%\n",
      "Epoch 17 - Loss: 0.6764533519744873 - Accuracy: 69.23%\n",
      "Epoch 18 - Loss: 0.6748217344284058 - Accuracy: 70.09%\n",
      "Epoch 19 - Loss: 0.6730623841285706 - Accuracy: 69.23%\n",
      "Epoch 20 - Loss: 0.6711815595626831 - Accuracy: 69.23%\n",
      "Epoch 21 - Loss: 0.6691770553588867 - Accuracy: 68.38%\n",
      "Epoch 22 - Loss: 0.6670393347740173 - Accuracy: 69.23%\n",
      "Epoch 23 - Loss: 0.6647425889968872 - Accuracy: 70.09%\n",
      "Epoch 24 - Loss: 0.6622820496559143 - Accuracy: 70.09%\n",
      "Epoch 25 - Loss: 0.6596501469612122 - Accuracy: 70.94%\n",
      "Epoch 26 - Loss: 0.6568630933761597 - Accuracy: 70.94%\n",
      "Epoch 27 - Loss: 0.6538885831832886 - Accuracy: 70.09%\n",
      "Epoch 28 - Loss: 0.6507402062416077 - Accuracy: 70.09%\n",
      "Epoch 29 - Loss: 0.6474202871322632 - Accuracy: 70.09%\n",
      "Epoch 30 - Loss: 0.643911600112915 - Accuracy: 70.09%\n",
      "Epoch 31 - Loss: 0.6401840448379517 - Accuracy: 70.09%\n",
      "Epoch 32 - Loss: 0.6362505555152893 - Accuracy: 70.09%\n",
      "Epoch 33 - Loss: 0.6321105360984802 - Accuracy: 70.09%\n",
      "Epoch 34 - Loss: 0.6277873516082764 - Accuracy: 70.94%\n",
      "Epoch 35 - Loss: 0.6232661604881287 - Accuracy: 70.94%\n",
      "Epoch 36 - Loss: 0.618571400642395 - Accuracy: 70.94%\n",
      "Epoch 37 - Loss: 0.6137253046035767 - Accuracy: 70.09%\n",
      "Epoch 38 - Loss: 0.6087232828140259 - Accuracy: 69.23%\n",
      "Epoch 39 - Loss: 0.6035515069961548 - Accuracy: 70.09%\n",
      "Epoch 40 - Loss: 0.5981557965278625 - Accuracy: 70.94%\n",
      "Epoch 41 - Loss: 0.5925788283348083 - Accuracy: 70.94%\n",
      "Epoch 42 - Loss: 0.5868279933929443 - Accuracy: 70.94%\n",
      "Epoch 43 - Loss: 0.580901563167572 - Accuracy: 71.79%\n",
      "Epoch 44 - Loss: 0.5748055577278137 - Accuracy: 72.65%\n",
      "Epoch 45 - Loss: 0.5685268044471741 - Accuracy: 74.36%\n",
      "Epoch 46 - Loss: 0.562039852142334 - Accuracy: 75.21%\n",
      "Epoch 47 - Loss: 0.5553643703460693 - Accuracy: 77.78%\n",
      "Epoch 48 - Loss: 0.5485042929649353 - Accuracy: 77.78%\n",
      "Epoch 49 - Loss: 0.5414835810661316 - Accuracy: 79.49%\n",
      "Epoch 50 - Loss: 0.5343278050422668 - Accuracy: 78.63%\n",
      "Epoch 51 - Loss: 0.5270277261734009 - Accuracy: 78.63%\n",
      "Epoch 52 - Loss: 0.5195987820625305 - Accuracy: 79.49%\n",
      "Epoch 53 - Loss: 0.5120372772216797 - Accuracy: 78.63%\n",
      "Epoch 54 - Loss: 0.504362940788269 - Accuracy: 78.63%\n",
      "Epoch 55 - Loss: 0.4965709447860718 - Accuracy: 77.78%\n",
      "Epoch 56 - Loss: 0.48866355419158936 - Accuracy: 77.78%\n",
      "Epoch 57 - Loss: 0.48063045740127563 - Accuracy: 77.78%\n",
      "Epoch 58 - Loss: 0.4724906086921692 - Accuracy: 79.49%\n",
      "Epoch 59 - Loss: 0.4642634391784668 - Accuracy: 78.63%\n",
      "Epoch 60 - Loss: 0.4559665620326996 - Accuracy: 79.49%\n",
      "Epoch 61 - Loss: 0.4476258158683777 - Accuracy: 82.05%\n",
      "Epoch 62 - Loss: 0.43922194838523865 - Accuracy: 82.05%\n",
      "Epoch 63 - Loss: 0.4307558536529541 - Accuracy: 83.76%\n",
      "Epoch 64 - Loss: 0.422235906124115 - Accuracy: 84.62%\n",
      "Epoch 65 - Loss: 0.4137076735496521 - Accuracy: 86.32%\n",
      "Epoch 66 - Loss: 0.4052141606807709 - Accuracy: 86.32%\n",
      "Epoch 67 - Loss: 0.39675214886665344 - Accuracy: 86.32%\n",
      "Epoch 68 - Loss: 0.38832932710647583 - Accuracy: 88.03%\n",
      "Epoch 69 - Loss: 0.37995967268943787 - Accuracy: 89.74%\n",
      "Epoch 70 - Loss: 0.37166470289230347 - Accuracy: 89.74%\n",
      "Epoch 71 - Loss: 0.3634623885154724 - Accuracy: 89.74%\n",
      "Epoch 72 - Loss: 0.35535335540771484 - Accuracy: 89.74%\n",
      "Epoch 73 - Loss: 0.3473692536354065 - Accuracy: 90.60%\n",
      "Epoch 74 - Loss: 0.33951935172080994 - Accuracy: 90.60%\n",
      "Epoch 75 - Loss: 0.33180662989616394 - Accuracy: 90.60%\n",
      "Epoch 76 - Loss: 0.3242145776748657 - Accuracy: 90.60%\n",
      "Epoch 77 - Loss: 0.31674888730049133 - Accuracy: 90.60%\n",
      "Epoch 78 - Loss: 0.309418261051178 - Accuracy: 91.45%\n",
      "Epoch 79 - Loss: 0.30223196744918823 - Accuracy: 92.31%\n",
      "Epoch 80 - Loss: 0.29520079493522644 - Accuracy: 92.31%\n",
      "Epoch 81 - Loss: 0.28830486536026 - Accuracy: 92.31%\n",
      "Epoch 82 - Loss: 0.28154855966567993 - Accuracy: 92.31%\n",
      "Epoch 83 - Loss: 0.27493828535079956 - Accuracy: 93.16%\n",
      "Epoch 84 - Loss: 0.26847437024116516 - Accuracy: 93.16%\n",
      "Epoch 85 - Loss: 0.26216137409210205 - Accuracy: 93.16%\n",
      "Epoch 86 - Loss: 0.2559968829154968 - Accuracy: 93.16%\n",
      "Epoch 87 - Loss: 0.24997656047344208 - Accuracy: 94.02%\n",
      "Epoch 88 - Loss: 0.24411746859550476 - Accuracy: 94.87%\n",
      "Epoch 89 - Loss: 0.23840975761413574 - Accuracy: 95.73%\n",
      "Epoch 90 - Loss: 0.2328508049249649 - Accuracy: 95.73%\n",
      "Epoch 91 - Loss: 0.2274433821439743 - Accuracy: 95.73%\n",
      "Epoch 92 - Loss: 0.22219394147396088 - Accuracy: 95.73%\n",
      "Epoch 93 - Loss: 0.2170969843864441 - Accuracy: 95.73%\n",
      "Epoch 94 - Loss: 0.21212616562843323 - Accuracy: 95.73%\n",
      "Epoch 95 - Loss: 0.2072817087173462 - Accuracy: 95.73%\n",
      "Epoch 96 - Loss: 0.20257428288459778 - Accuracy: 95.73%\n",
      "Epoch 97 - Loss: 0.19798433780670166 - Accuracy: 95.73%\n",
      "Epoch 98 - Loss: 0.1935037076473236 - Accuracy: 95.73%\n",
      "Epoch 99 - Loss: 0.18913286924362183 - Accuracy: 95.73%\n",
      "MLP model test accuracy: 86.49%\n",
      "Seed 42 - Test Accuracy: 86.49%\n",
      "Epoch 0 - Loss: 0.6942915916442871 - Accuracy: 50.43%\n",
      "Epoch 1 - Loss: 0.6930259466171265 - Accuracy: 50.43%\n",
      "Epoch 2 - Loss: 0.6918168663978577 - Accuracy: 50.43%\n",
      "Epoch 3 - Loss: 0.6906400322914124 - Accuracy: 50.43%\n",
      "Epoch 4 - Loss: 0.6894990801811218 - Accuracy: 50.43%\n",
      "Epoch 5 - Loss: 0.6883507966995239 - Accuracy: 50.43%\n",
      "Epoch 6 - Loss: 0.6871660947799683 - Accuracy: 50.43%\n",
      "Epoch 7 - Loss: 0.6859360337257385 - Accuracy: 50.43%\n",
      "Epoch 8 - Loss: 0.6846482157707214 - Accuracy: 51.28%\n",
      "Epoch 9 - Loss: 0.68330317735672 - Accuracy: 51.28%\n",
      "Epoch 10 - Loss: 0.6818701028823853 - Accuracy: 51.28%\n",
      "Epoch 11 - Loss: 0.6803358793258667 - Accuracy: 52.14%\n",
      "Epoch 12 - Loss: 0.6786986589431763 - Accuracy: 52.99%\n",
      "Epoch 13 - Loss: 0.6769710183143616 - Accuracy: 57.26%\n",
      "Epoch 14 - Loss: 0.6751583218574524 - Accuracy: 57.26%\n",
      "Epoch 15 - Loss: 0.6732427477836609 - Accuracy: 60.68%\n",
      "Epoch 16 - Loss: 0.6712091565132141 - Accuracy: 62.39%\n",
      "Epoch 17 - Loss: 0.6690369844436646 - Accuracy: 63.25%\n",
      "Epoch 18 - Loss: 0.6667371988296509 - Accuracy: 64.10%\n",
      "Epoch 19 - Loss: 0.6643286347389221 - Accuracy: 65.81%\n",
      "Epoch 20 - Loss: 0.661800742149353 - Accuracy: 66.67%\n",
      "Epoch 21 - Loss: 0.6591309309005737 - Accuracy: 71.79%\n",
      "Epoch 22 - Loss: 0.6563313007354736 - Accuracy: 70.94%\n",
      "Epoch 23 - Loss: 0.653383731842041 - Accuracy: 70.94%\n",
      "Epoch 24 - Loss: 0.6502894163131714 - Accuracy: 70.94%\n",
      "Epoch 25 - Loss: 0.6470518708229065 - Accuracy: 72.65%\n",
      "Epoch 26 - Loss: 0.6436495780944824 - Accuracy: 72.65%\n",
      "Epoch 27 - Loss: 0.6400735974311829 - Accuracy: 73.50%\n",
      "Epoch 28 - Loss: 0.6363032460212708 - Accuracy: 74.36%\n",
      "Epoch 29 - Loss: 0.6323503851890564 - Accuracy: 75.21%\n",
      "Epoch 30 - Loss: 0.6282222270965576 - Accuracy: 76.07%\n",
      "Epoch 31 - Loss: 0.6239181160926819 - Accuracy: 76.07%\n",
      "Epoch 32 - Loss: 0.6194309592247009 - Accuracy: 76.92%\n",
      "Epoch 33 - Loss: 0.6147406101226807 - Accuracy: 76.92%\n",
      "Epoch 34 - Loss: 0.6098260283470154 - Accuracy: 76.92%\n",
      "Epoch 35 - Loss: 0.6047232151031494 - Accuracy: 76.92%\n",
      "Epoch 36 - Loss: 0.5994479060173035 - Accuracy: 77.78%\n",
      "Epoch 37 - Loss: 0.593966007232666 - Accuracy: 77.78%\n",
      "Epoch 38 - Loss: 0.5882928967475891 - Accuracy: 78.63%\n",
      "Epoch 39 - Loss: 0.5824218988418579 - Accuracy: 79.49%\n",
      "Epoch 40 - Loss: 0.57635897397995 - Accuracy: 78.63%\n",
      "Epoch 41 - Loss: 0.570091724395752 - Accuracy: 78.63%\n",
      "Epoch 42 - Loss: 0.5636237859725952 - Accuracy: 77.78%\n",
      "Epoch 43 - Loss: 0.5569543838500977 - Accuracy: 77.78%\n",
      "Epoch 44 - Loss: 0.5501251816749573 - Accuracy: 77.78%\n",
      "Epoch 45 - Loss: 0.5431593060493469 - Accuracy: 78.63%\n",
      "Epoch 46 - Loss: 0.5360496640205383 - Accuracy: 77.78%\n",
      "Epoch 47 - Loss: 0.528816282749176 - Accuracy: 77.78%\n",
      "Epoch 48 - Loss: 0.5214651226997375 - Accuracy: 78.63%\n",
      "Epoch 49 - Loss: 0.5139665007591248 - Accuracy: 78.63%\n",
      "Epoch 50 - Loss: 0.5063216090202332 - Accuracy: 80.34%\n",
      "Epoch 51 - Loss: 0.4985756576061249 - Accuracy: 80.34%\n",
      "Epoch 52 - Loss: 0.49070504307746887 - Accuracy: 80.34%\n",
      "Epoch 53 - Loss: 0.48277801275253296 - Accuracy: 80.34%\n",
      "Epoch 54 - Loss: 0.4747110605239868 - Accuracy: 80.34%\n",
      "Epoch 55 - Loss: 0.46658554673194885 - Accuracy: 81.20%\n",
      "Epoch 56 - Loss: 0.4584079384803772 - Accuracy: 81.20%\n",
      "Epoch 57 - Loss: 0.45013847947120667 - Accuracy: 82.05%\n",
      "Epoch 58 - Loss: 0.44180601835250854 - Accuracy: 84.62%\n",
      "Epoch 59 - Loss: 0.43345341086387634 - Accuracy: 84.62%\n",
      "Epoch 60 - Loss: 0.42508238554000854 - Accuracy: 84.62%\n",
      "Epoch 61 - Loss: 0.416690468788147 - Accuracy: 85.47%\n",
      "Epoch 62 - Loss: 0.40828147530555725 - Accuracy: 85.47%\n",
      "Epoch 63 - Loss: 0.3998660743236542 - Accuracy: 86.32%\n",
      "Epoch 64 - Loss: 0.39146438241004944 - Accuracy: 86.32%\n",
      "Epoch 65 - Loss: 0.3831052780151367 - Accuracy: 88.89%\n",
      "Epoch 66 - Loss: 0.3747895061969757 - Accuracy: 88.89%\n",
      "Epoch 67 - Loss: 0.36663368344306946 - Accuracy: 88.89%\n",
      "Epoch 68 - Loss: 0.35858291387557983 - Accuracy: 88.89%\n",
      "Epoch 69 - Loss: 0.3506298363208771 - Accuracy: 88.89%\n",
      "Epoch 70 - Loss: 0.34280142188072205 - Accuracy: 89.74%\n",
      "Epoch 71 - Loss: 0.3350841701030731 - Accuracy: 90.60%\n",
      "Epoch 72 - Loss: 0.3275091052055359 - Accuracy: 90.60%\n",
      "Epoch 73 - Loss: 0.3200644552707672 - Accuracy: 90.60%\n",
      "Epoch 74 - Loss: 0.31276071071624756 - Accuracy: 90.60%\n",
      "Epoch 75 - Loss: 0.3056052029132843 - Accuracy: 90.60%\n",
      "Epoch 76 - Loss: 0.2985913157463074 - Accuracy: 91.45%\n",
      "Epoch 77 - Loss: 0.29171231389045715 - Accuracy: 92.31%\n",
      "Epoch 78 - Loss: 0.28498131036758423 - Accuracy: 92.31%\n",
      "Epoch 79 - Loss: 0.2783900797367096 - Accuracy: 93.16%\n",
      "Epoch 80 - Loss: 0.2719506621360779 - Accuracy: 94.02%\n",
      "Epoch 81 - Loss: 0.26566535234451294 - Accuracy: 94.02%\n",
      "Epoch 82 - Loss: 0.25952306389808655 - Accuracy: 94.02%\n",
      "Epoch 83 - Loss: 0.25351911783218384 - Accuracy: 94.02%\n",
      "Epoch 84 - Loss: 0.24765385687351227 - Accuracy: 94.87%\n",
      "Epoch 85 - Loss: 0.24193158745765686 - Accuracy: 94.87%\n",
      "Epoch 86 - Loss: 0.23635846376419067 - Accuracy: 94.87%\n",
      "Epoch 87 - Loss: 0.23091500997543335 - Accuracy: 95.73%\n",
      "Epoch 88 - Loss: 0.22560946643352509 - Accuracy: 95.73%\n",
      "Epoch 89 - Loss: 0.22045589983463287 - Accuracy: 95.73%\n",
      "Epoch 90 - Loss: 0.21544528007507324 - Accuracy: 95.73%\n",
      "Epoch 91 - Loss: 0.21055546402931213 - Accuracy: 95.73%\n",
      "Epoch 92 - Loss: 0.205801859498024 - Accuracy: 95.73%\n",
      "Epoch 93 - Loss: 0.20118562877178192 - Accuracy: 95.73%\n",
      "Epoch 94 - Loss: 0.19668909907341003 - Accuracy: 95.73%\n",
      "Epoch 95 - Loss: 0.19229574501514435 - Accuracy: 95.73%\n",
      "Epoch 96 - Loss: 0.18800219893455505 - Accuracy: 95.73%\n",
      "Epoch 97 - Loss: 0.18382205069065094 - Accuracy: 94.87%\n",
      "Epoch 98 - Loss: 0.17975085973739624 - Accuracy: 94.87%\n",
      "Epoch 99 - Loss: 0.17577268183231354 - Accuracy: 94.87%\n",
      "MLP model test accuracy: 86.49%\n",
      "Seed 7 - Test Accuracy: 86.49%\n",
      "Epoch 0 - Loss: 0.696855902671814 - Accuracy: 50.43%\n",
      "Epoch 1 - Loss: 0.6953672170639038 - Accuracy: 50.43%\n",
      "Epoch 2 - Loss: 0.6939072012901306 - Accuracy: 50.43%\n",
      "Epoch 3 - Loss: 0.6924839615821838 - Accuracy: 50.43%\n",
      "Epoch 4 - Loss: 0.6910707354545593 - Accuracy: 50.43%\n",
      "Epoch 5 - Loss: 0.6896415948867798 - Accuracy: 50.43%\n",
      "Epoch 6 - Loss: 0.6881980299949646 - Accuracy: 50.43%\n",
      "Epoch 7 - Loss: 0.686705470085144 - Accuracy: 50.43%\n",
      "Epoch 8 - Loss: 0.6851443648338318 - Accuracy: 50.43%\n",
      "Epoch 9 - Loss: 0.683508574962616 - Accuracy: 52.14%\n",
      "Epoch 10 - Loss: 0.6817740201950073 - Accuracy: 52.14%\n",
      "Epoch 11 - Loss: 0.6799615025520325 - Accuracy: 52.99%\n",
      "Epoch 12 - Loss: 0.678055465221405 - Accuracy: 55.56%\n",
      "Epoch 13 - Loss: 0.6760199069976807 - Accuracy: 56.41%\n",
      "Epoch 14 - Loss: 0.6738411784172058 - Accuracy: 57.26%\n",
      "Epoch 15 - Loss: 0.6714969873428345 - Accuracy: 58.97%\n",
      "Epoch 16 - Loss: 0.6690311431884766 - Accuracy: 60.68%\n",
      "Epoch 17 - Loss: 0.6664630174636841 - Accuracy: 60.68%\n",
      "Epoch 18 - Loss: 0.6637120842933655 - Accuracy: 60.68%\n",
      "Epoch 19 - Loss: 0.6607487797737122 - Accuracy: 61.54%\n",
      "Epoch 20 - Loss: 0.6575812697410583 - Accuracy: 63.25%\n",
      "Epoch 21 - Loss: 0.6542205810546875 - Accuracy: 64.10%\n",
      "Epoch 22 - Loss: 0.650698184967041 - Accuracy: 66.67%\n",
      "Epoch 23 - Loss: 0.6469818949699402 - Accuracy: 66.67%\n",
      "Epoch 24 - Loss: 0.6430773735046387 - Accuracy: 64.96%\n",
      "Epoch 25 - Loss: 0.6389598846435547 - Accuracy: 69.23%\n",
      "Epoch 26 - Loss: 0.6346261501312256 - Accuracy: 69.23%\n",
      "Epoch 27 - Loss: 0.6300667524337769 - Accuracy: 71.79%\n",
      "Epoch 28 - Loss: 0.6253131031990051 - Accuracy: 72.65%\n",
      "Epoch 29 - Loss: 0.6203632354736328 - Accuracy: 72.65%\n",
      "Epoch 30 - Loss: 0.6151832938194275 - Accuracy: 73.50%\n",
      "Epoch 31 - Loss: 0.6098276972770691 - Accuracy: 76.07%\n",
      "Epoch 32 - Loss: 0.6043015122413635 - Accuracy: 76.07%\n",
      "Epoch 33 - Loss: 0.5985949039459229 - Accuracy: 76.07%\n",
      "Epoch 34 - Loss: 0.592701256275177 - Accuracy: 76.92%\n",
      "Epoch 35 - Loss: 0.5866091847419739 - Accuracy: 76.92%\n",
      "Epoch 36 - Loss: 0.5803641080856323 - Accuracy: 76.07%\n",
      "Epoch 37 - Loss: 0.5739501118659973 - Accuracy: 76.92%\n",
      "Epoch 38 - Loss: 0.5673403143882751 - Accuracy: 78.63%\n",
      "Epoch 39 - Loss: 0.5606081485748291 - Accuracy: 78.63%\n",
      "Epoch 40 - Loss: 0.5537762641906738 - Accuracy: 78.63%\n",
      "Epoch 41 - Loss: 0.5468246936798096 - Accuracy: 79.49%\n",
      "Epoch 42 - Loss: 0.5397466421127319 - Accuracy: 79.49%\n",
      "Epoch 43 - Loss: 0.5325232744216919 - Accuracy: 79.49%\n",
      "Epoch 44 - Loss: 0.525164008140564 - Accuracy: 79.49%\n",
      "Epoch 45 - Loss: 0.5176966190338135 - Accuracy: 79.49%\n",
      "Epoch 46 - Loss: 0.5101175308227539 - Accuracy: 80.34%\n",
      "Epoch 47 - Loss: 0.5024313926696777 - Accuracy: 81.20%\n",
      "Epoch 48 - Loss: 0.4946476221084595 - Accuracy: 81.20%\n",
      "Epoch 49 - Loss: 0.48677846789360046 - Accuracy: 80.34%\n",
      "Epoch 50 - Loss: 0.4788386821746826 - Accuracy: 80.34%\n",
      "Epoch 51 - Loss: 0.47083282470703125 - Accuracy: 80.34%\n",
      "Epoch 52 - Loss: 0.46278098225593567 - Accuracy: 80.34%\n",
      "Epoch 53 - Loss: 0.4546906054019928 - Accuracy: 81.20%\n",
      "Epoch 54 - Loss: 0.44655171036720276 - Accuracy: 82.05%\n",
      "Epoch 55 - Loss: 0.43834659457206726 - Accuracy: 83.76%\n",
      "Epoch 56 - Loss: 0.4300921559333801 - Accuracy: 84.62%\n",
      "Epoch 57 - Loss: 0.42179468274116516 - Accuracy: 85.47%\n",
      "Epoch 58 - Loss: 0.4134874939918518 - Accuracy: 85.47%\n",
      "Epoch 59 - Loss: 0.4052082896232605 - Accuracy: 86.32%\n",
      "Epoch 60 - Loss: 0.3969733417034149 - Accuracy: 88.03%\n",
      "Epoch 61 - Loss: 0.38877734541893005 - Accuracy: 88.89%\n",
      "Epoch 62 - Loss: 0.38064366579055786 - Accuracy: 88.89%\n",
      "Epoch 63 - Loss: 0.3725842535495758 - Accuracy: 88.89%\n",
      "Epoch 64 - Loss: 0.36462345719337463 - Accuracy: 89.74%\n",
      "Epoch 65 - Loss: 0.3567357063293457 - Accuracy: 89.74%\n",
      "Epoch 66 - Loss: 0.3489605188369751 - Accuracy: 89.74%\n",
      "Epoch 67 - Loss: 0.3412974774837494 - Accuracy: 90.60%\n",
      "Epoch 68 - Loss: 0.3337182402610779 - Accuracy: 90.60%\n",
      "Epoch 69 - Loss: 0.32624226808547974 - Accuracy: 92.31%\n",
      "Epoch 70 - Loss: 0.3189030587673187 - Accuracy: 92.31%\n",
      "Epoch 71 - Loss: 0.31167927384376526 - Accuracy: 92.31%\n",
      "Epoch 72 - Loss: 0.30457839369773865 - Accuracy: 92.31%\n",
      "Epoch 73 - Loss: 0.29760852456092834 - Accuracy: 92.31%\n",
      "Epoch 74 - Loss: 0.29079481959342957 - Accuracy: 92.31%\n",
      "Epoch 75 - Loss: 0.28411173820495605 - Accuracy: 92.31%\n",
      "Epoch 76 - Loss: 0.2775818705558777 - Accuracy: 93.16%\n",
      "Epoch 77 - Loss: 0.27120184898376465 - Accuracy: 94.02%\n",
      "Epoch 78 - Loss: 0.26494306325912476 - Accuracy: 94.02%\n",
      "Epoch 79 - Loss: 0.25880804657936096 - Accuracy: 94.02%\n",
      "Epoch 80 - Loss: 0.25280576944351196 - Accuracy: 94.02%\n",
      "Epoch 81 - Loss: 0.24693870544433594 - Accuracy: 94.02%\n",
      "Epoch 82 - Loss: 0.24123820662498474 - Accuracy: 94.02%\n",
      "Epoch 83 - Loss: 0.23569020628929138 - Accuracy: 94.87%\n",
      "Epoch 84 - Loss: 0.23029503226280212 - Accuracy: 94.87%\n",
      "Epoch 85 - Loss: 0.225022554397583 - Accuracy: 94.87%\n",
      "Epoch 86 - Loss: 0.21988286077976227 - Accuracy: 94.87%\n",
      "Epoch 87 - Loss: 0.21486784517765045 - Accuracy: 94.87%\n",
      "Epoch 88 - Loss: 0.20998603105545044 - Accuracy: 94.87%\n",
      "Epoch 89 - Loss: 0.20520536601543427 - Accuracy: 95.73%\n",
      "Epoch 90 - Loss: 0.20053823292255402 - Accuracy: 95.73%\n",
      "Epoch 91 - Loss: 0.19599850475788116 - Accuracy: 95.73%\n",
      "Epoch 92 - Loss: 0.19157277047634125 - Accuracy: 96.58%\n",
      "Epoch 93 - Loss: 0.18725833296775818 - Accuracy: 96.58%\n",
      "Epoch 94 - Loss: 0.18305611610412598 - Accuracy: 96.58%\n",
      "Epoch 95 - Loss: 0.17897240817546844 - Accuracy: 96.58%\n",
      "Epoch 96 - Loss: 0.1749948412179947 - Accuracy: 95.73%\n",
      "Epoch 97 - Loss: 0.17111288011074066 - Accuracy: 95.73%\n",
      "Epoch 98 - Loss: 0.16731899976730347 - Accuracy: 95.73%\n",
      "Epoch 99 - Loss: 0.1636289805173874 - Accuracy: 96.58%\n",
      "MLP model test accuracy: 86.49%\n",
      "Seed 21 - Test Accuracy: 86.49%\n",
      "Average Test Accuracy over seeds: 86.49%\n",
      "Running MLP experiments on IRefIndex_2015 data\n",
      "Epoch 0 - Loss: 0.6937282681465149 - Accuracy: 49.53%\n",
      "Epoch 1 - Loss: 0.6931406855583191 - Accuracy: 49.53%\n",
      "Epoch 2 - Loss: 0.6925767064094543 - Accuracy: 49.53%\n",
      "Epoch 3 - Loss: 0.6920202970504761 - Accuracy: 50.47%\n",
      "Epoch 4 - Loss: 0.6914628744125366 - Accuracy: 52.34%\n",
      "Epoch 5 - Loss: 0.6909098625183105 - Accuracy: 53.27%\n",
      "Epoch 6 - Loss: 0.6903467178344727 - Accuracy: 54.21%\n",
      "Epoch 7 - Loss: 0.6897772550582886 - Accuracy: 54.21%\n",
      "Epoch 8 - Loss: 0.6891781687736511 - Accuracy: 60.75%\n",
      "Epoch 9 - Loss: 0.6885494589805603 - Accuracy: 62.62%\n",
      "Epoch 10 - Loss: 0.6878888010978699 - Accuracy: 66.36%\n",
      "Epoch 11 - Loss: 0.6871915459632874 - Accuracy: 66.36%\n",
      "Epoch 12 - Loss: 0.6864548921585083 - Accuracy: 70.09%\n",
      "Epoch 13 - Loss: 0.6856681704521179 - Accuracy: 70.09%\n",
      "Epoch 14 - Loss: 0.6848412752151489 - Accuracy: 72.90%\n",
      "Epoch 15 - Loss: 0.6839625239372253 - Accuracy: 73.83%\n",
      "Epoch 16 - Loss: 0.6830320954322815 - Accuracy: 71.96%\n",
      "Epoch 17 - Loss: 0.6820319294929504 - Accuracy: 71.96%\n",
      "Epoch 18 - Loss: 0.6809647679328918 - Accuracy: 68.22%\n",
      "Epoch 19 - Loss: 0.679816722869873 - Accuracy: 66.36%\n",
      "Epoch 20 - Loss: 0.6785801649093628 - Accuracy: 64.49%\n",
      "Epoch 21 - Loss: 0.67724609375 - Accuracy: 63.55%\n",
      "Epoch 22 - Loss: 0.6758033037185669 - Accuracy: 63.55%\n",
      "Epoch 23 - Loss: 0.6742500066757202 - Accuracy: 63.55%\n",
      "Epoch 24 - Loss: 0.6726095080375671 - Accuracy: 63.55%\n",
      "Epoch 25 - Loss: 0.6708545684814453 - Accuracy: 63.55%\n",
      "Epoch 26 - Loss: 0.6689637303352356 - Accuracy: 63.55%\n",
      "Epoch 27 - Loss: 0.6669344902038574 - Accuracy: 63.55%\n",
      "Epoch 28 - Loss: 0.6647452712059021 - Accuracy: 64.49%\n",
      "Epoch 29 - Loss: 0.6623957753181458 - Accuracy: 64.49%\n",
      "Epoch 30 - Loss: 0.6599225401878357 - Accuracy: 66.36%\n",
      "Epoch 31 - Loss: 0.6573126912117004 - Accuracy: 68.22%\n",
      "Epoch 32 - Loss: 0.6545454859733582 - Accuracy: 69.16%\n",
      "Epoch 33 - Loss: 0.6516327857971191 - Accuracy: 69.16%\n",
      "Epoch 34 - Loss: 0.6485887765884399 - Accuracy: 69.16%\n",
      "Epoch 35 - Loss: 0.6453943848609924 - Accuracy: 69.16%\n",
      "Epoch 36 - Loss: 0.6420394778251648 - Accuracy: 71.03%\n",
      "Epoch 37 - Loss: 0.6384938955307007 - Accuracy: 71.03%\n",
      "Epoch 38 - Loss: 0.6347702145576477 - Accuracy: 70.09%\n",
      "Epoch 39 - Loss: 0.6308532357215881 - Accuracy: 69.16%\n",
      "Epoch 40 - Loss: 0.6267244815826416 - Accuracy: 71.96%\n",
      "Epoch 41 - Loss: 0.6224074363708496 - Accuracy: 73.83%\n",
      "Epoch 42 - Loss: 0.6179053783416748 - Accuracy: 73.83%\n",
      "Epoch 43 - Loss: 0.6131995916366577 - Accuracy: 74.77%\n",
      "Epoch 44 - Loss: 0.6083232760429382 - Accuracy: 75.70%\n",
      "Epoch 45 - Loss: 0.603211522102356 - Accuracy: 75.70%\n",
      "Epoch 46 - Loss: 0.5978861451148987 - Accuracy: 76.64%\n",
      "Epoch 47 - Loss: 0.5923644304275513 - Accuracy: 76.64%\n",
      "Epoch 48 - Loss: 0.5866475105285645 - Accuracy: 77.57%\n",
      "Epoch 49 - Loss: 0.5807745456695557 - Accuracy: 78.50%\n",
      "Epoch 50 - Loss: 0.5747295022010803 - Accuracy: 81.31%\n",
      "Epoch 51 - Loss: 0.5684956908226013 - Accuracy: 80.37%\n",
      "Epoch 52 - Loss: 0.5621297359466553 - Accuracy: 82.24%\n",
      "Epoch 53 - Loss: 0.5556538105010986 - Accuracy: 82.24%\n",
      "Epoch 54 - Loss: 0.5490310788154602 - Accuracy: 82.24%\n",
      "Epoch 55 - Loss: 0.5422541499137878 - Accuracy: 83.18%\n",
      "Epoch 56 - Loss: 0.5353329181671143 - Accuracy: 83.18%\n",
      "Epoch 57 - Loss: 0.5283205509185791 - Accuracy: 82.24%\n",
      "Epoch 58 - Loss: 0.5212190747261047 - Accuracy: 83.18%\n",
      "Epoch 59 - Loss: 0.5140436887741089 - Accuracy: 83.18%\n",
      "Epoch 60 - Loss: 0.5068007111549377 - Accuracy: 83.18%\n",
      "Epoch 61 - Loss: 0.4994715750217438 - Accuracy: 83.18%\n",
      "Epoch 62 - Loss: 0.4920860230922699 - Accuracy: 83.18%\n",
      "Epoch 63 - Loss: 0.48462554812431335 - Accuracy: 85.98%\n",
      "Epoch 64 - Loss: 0.47710686922073364 - Accuracy: 85.98%\n",
      "Epoch 65 - Loss: 0.4695335328578949 - Accuracy: 85.98%\n",
      "Epoch 66 - Loss: 0.4618925154209137 - Accuracy: 85.98%\n",
      "Epoch 67 - Loss: 0.4542355537414551 - Accuracy: 86.92%\n",
      "Epoch 68 - Loss: 0.44657230377197266 - Accuracy: 87.85%\n",
      "Epoch 69 - Loss: 0.43886300921440125 - Accuracy: 87.85%\n",
      "Epoch 70 - Loss: 0.4310924708843231 - Accuracy: 87.85%\n",
      "Epoch 71 - Loss: 0.42334073781967163 - Accuracy: 87.85%\n",
      "Epoch 72 - Loss: 0.4155891537666321 - Accuracy: 87.85%\n",
      "Epoch 73 - Loss: 0.40784603357315063 - Accuracy: 87.85%\n",
      "Epoch 74 - Loss: 0.4001288115978241 - Accuracy: 87.85%\n",
      "Epoch 75 - Loss: 0.3924776613712311 - Accuracy: 87.85%\n",
      "Epoch 76 - Loss: 0.384874552488327 - Accuracy: 87.85%\n",
      "Epoch 77 - Loss: 0.3773406445980072 - Accuracy: 87.85%\n",
      "Epoch 78 - Loss: 0.36994612216949463 - Accuracy: 88.79%\n",
      "Epoch 79 - Loss: 0.3626391589641571 - Accuracy: 88.79%\n",
      "Epoch 80 - Loss: 0.3554193079471588 - Accuracy: 89.72%\n",
      "Epoch 81 - Loss: 0.3483034372329712 - Accuracy: 89.72%\n",
      "Epoch 82 - Loss: 0.3412924110889435 - Accuracy: 89.72%\n",
      "Epoch 83 - Loss: 0.33438584208488464 - Accuracy: 89.72%\n",
      "Epoch 84 - Loss: 0.3276108503341675 - Accuracy: 90.65%\n",
      "Epoch 85 - Loss: 0.32098808884620667 - Accuracy: 90.65%\n",
      "Epoch 86 - Loss: 0.31450918316841125 - Accuracy: 90.65%\n",
      "Epoch 87 - Loss: 0.30818647146224976 - Accuracy: 91.59%\n",
      "Epoch 88 - Loss: 0.3020261526107788 - Accuracy: 92.52%\n",
      "Epoch 89 - Loss: 0.29601818323135376 - Accuracy: 92.52%\n",
      "Epoch 90 - Loss: 0.29014626145362854 - Accuracy: 92.52%\n",
      "Epoch 91 - Loss: 0.28441062569618225 - Accuracy: 93.46%\n",
      "Epoch 92 - Loss: 0.27881208062171936 - Accuracy: 93.46%\n",
      "Epoch 93 - Loss: 0.2733609676361084 - Accuracy: 93.46%\n",
      "Epoch 94 - Loss: 0.268058717250824 - Accuracy: 93.46%\n",
      "Epoch 95 - Loss: 0.2628821134567261 - Accuracy: 93.46%\n",
      "Epoch 96 - Loss: 0.2578159272670746 - Accuracy: 92.52%\n",
      "Epoch 97 - Loss: 0.2528666853904724 - Accuracy: 92.52%\n",
      "Epoch 98 - Loss: 0.2480406016111374 - Accuracy: 92.52%\n",
      "Epoch 99 - Loss: 0.24333983659744263 - Accuracy: 92.52%\n",
      "MLP model test accuracy: 73.53%\n",
      "Seed 42 - Test Accuracy: 73.53%\n",
      "Epoch 0 - Loss: 0.6939698457717896 - Accuracy: 50.47%\n",
      "Epoch 1 - Loss: 0.6928595304489136 - Accuracy: 50.47%\n",
      "Epoch 2 - Loss: 0.6918041706085205 - Accuracy: 50.47%\n",
      "Epoch 3 - Loss: 0.690796971321106 - Accuracy: 50.47%\n",
      "Epoch 4 - Loss: 0.6898003816604614 - Accuracy: 50.47%\n",
      "Epoch 5 - Loss: 0.6887925267219543 - Accuracy: 50.47%\n",
      "Epoch 6 - Loss: 0.68779057264328 - Accuracy: 50.47%\n",
      "Epoch 7 - Loss: 0.6867609620094299 - Accuracy: 50.47%\n",
      "Epoch 8 - Loss: 0.6857073307037354 - Accuracy: 51.40%\n",
      "Epoch 9 - Loss: 0.6846149563789368 - Accuracy: 51.40%\n",
      "Epoch 10 - Loss: 0.6834680438041687 - Accuracy: 51.40%\n",
      "Epoch 11 - Loss: 0.6822746992111206 - Accuracy: 53.27%\n",
      "Epoch 12 - Loss: 0.681023359298706 - Accuracy: 54.21%\n",
      "Epoch 13 - Loss: 0.6797060370445251 - Accuracy: 56.07%\n",
      "Epoch 14 - Loss: 0.6783044338226318 - Accuracy: 59.81%\n",
      "Epoch 15 - Loss: 0.6767992377281189 - Accuracy: 59.81%\n",
      "Epoch 16 - Loss: 0.6751882433891296 - Accuracy: 61.68%\n",
      "Epoch 17 - Loss: 0.6734629273414612 - Accuracy: 63.55%\n",
      "Epoch 18 - Loss: 0.6716295480728149 - Accuracy: 64.49%\n",
      "Epoch 19 - Loss: 0.669685423374176 - Accuracy: 64.49%\n",
      "Epoch 20 - Loss: 0.6676258444786072 - Accuracy: 64.49%\n",
      "Epoch 21 - Loss: 0.6654259562492371 - Accuracy: 68.22%\n",
      "Epoch 22 - Loss: 0.6630642414093018 - Accuracy: 68.22%\n",
      "Epoch 23 - Loss: 0.660550057888031 - Accuracy: 73.83%\n",
      "Epoch 24 - Loss: 0.6579132676124573 - Accuracy: 75.70%\n",
      "Epoch 25 - Loss: 0.6551125645637512 - Accuracy: 76.64%\n",
      "Epoch 26 - Loss: 0.6521246433258057 - Accuracy: 76.64%\n",
      "Epoch 27 - Loss: 0.6489669680595398 - Accuracy: 75.70%\n",
      "Epoch 28 - Loss: 0.6456709504127502 - Accuracy: 75.70%\n",
      "Epoch 29 - Loss: 0.6422067284584045 - Accuracy: 75.70%\n",
      "Epoch 30 - Loss: 0.6386008858680725 - Accuracy: 73.83%\n",
      "Epoch 31 - Loss: 0.6348229050636292 - Accuracy: 73.83%\n",
      "Epoch 32 - Loss: 0.6308668851852417 - Accuracy: 73.83%\n",
      "Epoch 33 - Loss: 0.626726508140564 - Accuracy: 74.77%\n",
      "Epoch 34 - Loss: 0.6224107146263123 - Accuracy: 74.77%\n",
      "Epoch 35 - Loss: 0.6179010272026062 - Accuracy: 75.70%\n",
      "Epoch 36 - Loss: 0.6132119297981262 - Accuracy: 75.70%\n",
      "Epoch 37 - Loss: 0.6083451509475708 - Accuracy: 78.50%\n",
      "Epoch 38 - Loss: 0.6032946109771729 - Accuracy: 79.44%\n",
      "Epoch 39 - Loss: 0.5980595350265503 - Accuracy: 79.44%\n",
      "Epoch 40 - Loss: 0.592660129070282 - Accuracy: 80.37%\n",
      "Epoch 41 - Loss: 0.58706134557724 - Accuracy: 81.31%\n",
      "Epoch 42 - Loss: 0.5812620520591736 - Accuracy: 82.24%\n",
      "Epoch 43 - Loss: 0.5752754211425781 - Accuracy: 82.24%\n",
      "Epoch 44 - Loss: 0.5691182613372803 - Accuracy: 82.24%\n",
      "Epoch 45 - Loss: 0.5627649426460266 - Accuracy: 82.24%\n",
      "Epoch 46 - Loss: 0.556231677532196 - Accuracy: 83.18%\n",
      "Epoch 47 - Loss: 0.5495414137840271 - Accuracy: 82.24%\n",
      "Epoch 48 - Loss: 0.5427594780921936 - Accuracy: 83.18%\n",
      "Epoch 49 - Loss: 0.5358564853668213 - Accuracy: 83.18%\n",
      "Epoch 50 - Loss: 0.5287905335426331 - Accuracy: 83.18%\n",
      "Epoch 51 - Loss: 0.5216116309165955 - Accuracy: 83.18%\n",
      "Epoch 52 - Loss: 0.5143184065818787 - Accuracy: 83.18%\n",
      "Epoch 53 - Loss: 0.5068937540054321 - Accuracy: 83.18%\n",
      "Epoch 54 - Loss: 0.4993535280227661 - Accuracy: 82.24%\n",
      "Epoch 55 - Loss: 0.49171745777130127 - Accuracy: 82.24%\n",
      "Epoch 56 - Loss: 0.48393410444259644 - Accuracy: 83.18%\n",
      "Epoch 57 - Loss: 0.4760453402996063 - Accuracy: 83.18%\n",
      "Epoch 58 - Loss: 0.46813061833381653 - Accuracy: 83.18%\n",
      "Epoch 59 - Loss: 0.4601590037345886 - Accuracy: 83.18%\n",
      "Epoch 60 - Loss: 0.4521503150463104 - Accuracy: 84.11%\n",
      "Epoch 61 - Loss: 0.44411781430244446 - Accuracy: 84.11%\n",
      "Epoch 62 - Loss: 0.436103492975235 - Accuracy: 85.05%\n",
      "Epoch 63 - Loss: 0.428078830242157 - Accuracy: 85.05%\n",
      "Epoch 64 - Loss: 0.4200372099876404 - Accuracy: 87.85%\n",
      "Epoch 65 - Loss: 0.411958783864975 - Accuracy: 87.85%\n",
      "Epoch 66 - Loss: 0.403889536857605 - Accuracy: 87.85%\n",
      "Epoch 67 - Loss: 0.39588233828544617 - Accuracy: 88.79%\n",
      "Epoch 68 - Loss: 0.3879367709159851 - Accuracy: 88.79%\n",
      "Epoch 69 - Loss: 0.38008224964141846 - Accuracy: 88.79%\n",
      "Epoch 70 - Loss: 0.372344046831131 - Accuracy: 88.79%\n",
      "Epoch 71 - Loss: 0.3647098243236542 - Accuracy: 88.79%\n",
      "Epoch 72 - Loss: 0.35716989636421204 - Accuracy: 88.79%\n",
      "Epoch 73 - Loss: 0.3497332036495209 - Accuracy: 88.79%\n",
      "Epoch 74 - Loss: 0.3424244225025177 - Accuracy: 89.72%\n",
      "Epoch 75 - Loss: 0.33527135848999023 - Accuracy: 89.72%\n",
      "Epoch 76 - Loss: 0.3282439112663269 - Accuracy: 90.65%\n",
      "Epoch 77 - Loss: 0.32136210799217224 - Accuracy: 91.59%\n",
      "Epoch 78 - Loss: 0.31462812423706055 - Accuracy: 91.59%\n",
      "Epoch 79 - Loss: 0.3080608546733856 - Accuracy: 91.59%\n",
      "Epoch 80 - Loss: 0.30160942673683167 - Accuracy: 92.52%\n",
      "Epoch 81 - Loss: 0.29530903697013855 - Accuracy: 92.52%\n",
      "Epoch 82 - Loss: 0.289184033870697 - Accuracy: 93.46%\n",
      "Epoch 83 - Loss: 0.28323423862457275 - Accuracy: 93.46%\n",
      "Epoch 84 - Loss: 0.277437686920166 - Accuracy: 93.46%\n",
      "Epoch 85 - Loss: 0.2717607915401459 - Accuracy: 93.46%\n",
      "Epoch 86 - Loss: 0.2662205696105957 - Accuracy: 93.46%\n",
      "Epoch 87 - Loss: 0.26082390546798706 - Accuracy: 93.46%\n",
      "Epoch 88 - Loss: 0.25556886196136475 - Accuracy: 93.46%\n",
      "Epoch 89 - Loss: 0.2504365146160126 - Accuracy: 93.46%\n",
      "Epoch 90 - Loss: 0.24543528258800507 - Accuracy: 93.46%\n",
      "Epoch 91 - Loss: 0.24058634042739868 - Accuracy: 93.46%\n",
      "Epoch 92 - Loss: 0.23588958382606506 - Accuracy: 93.46%\n",
      "Epoch 93 - Loss: 0.23132649064064026 - Accuracy: 93.46%\n",
      "Epoch 94 - Loss: 0.22685730457305908 - Accuracy: 94.39%\n",
      "Epoch 95 - Loss: 0.22250685095787048 - Accuracy: 94.39%\n",
      "Epoch 96 - Loss: 0.2182663381099701 - Accuracy: 94.39%\n",
      "Epoch 97 - Loss: 0.21415412425994873 - Accuracy: 94.39%\n",
      "Epoch 98 - Loss: 0.2101486772298813 - Accuracy: 94.39%\n",
      "Epoch 99 - Loss: 0.2062244713306427 - Accuracy: 94.39%\n",
      "MLP model test accuracy: 73.53%\n",
      "Seed 7 - Test Accuracy: 73.53%\n",
      "Epoch 0 - Loss: 0.6975694894790649 - Accuracy: 50.47%\n",
      "Epoch 1 - Loss: 0.696281909942627 - Accuracy: 50.47%\n",
      "Epoch 2 - Loss: 0.6950472593307495 - Accuracy: 50.47%\n",
      "Epoch 3 - Loss: 0.6938542723655701 - Accuracy: 50.47%\n",
      "Epoch 4 - Loss: 0.6926584839820862 - Accuracy: 50.47%\n",
      "Epoch 5 - Loss: 0.6914591789245605 - Accuracy: 50.47%\n",
      "Epoch 6 - Loss: 0.6902572512626648 - Accuracy: 50.47%\n",
      "Epoch 7 - Loss: 0.6890422701835632 - Accuracy: 50.47%\n",
      "Epoch 8 - Loss: 0.6878048181533813 - Accuracy: 50.47%\n",
      "Epoch 9 - Loss: 0.6865540742874146 - Accuracy: 50.47%\n",
      "Epoch 10 - Loss: 0.6852592825889587 - Accuracy: 50.47%\n",
      "Epoch 11 - Loss: 0.6838840842247009 - Accuracy: 52.34%\n",
      "Epoch 12 - Loss: 0.6824494004249573 - Accuracy: 53.27%\n",
      "Epoch 13 - Loss: 0.6809622645378113 - Accuracy: 54.21%\n",
      "Epoch 14 - Loss: 0.6793937087059021 - Accuracy: 58.88%\n",
      "Epoch 15 - Loss: 0.6777321696281433 - Accuracy: 58.88%\n",
      "Epoch 16 - Loss: 0.6759749054908752 - Accuracy: 58.88%\n",
      "Epoch 17 - Loss: 0.6741142868995667 - Accuracy: 59.81%\n",
      "Epoch 18 - Loss: 0.6721531748771667 - Accuracy: 59.81%\n",
      "Epoch 19 - Loss: 0.670056939125061 - Accuracy: 64.49%\n",
      "Epoch 20 - Loss: 0.6678499579429626 - Accuracy: 64.49%\n",
      "Epoch 21 - Loss: 0.6655223369598389 - Accuracy: 67.29%\n",
      "Epoch 22 - Loss: 0.6630698442459106 - Accuracy: 67.29%\n",
      "Epoch 23 - Loss: 0.6604828238487244 - Accuracy: 68.22%\n",
      "Epoch 24 - Loss: 0.6577653288841248 - Accuracy: 67.29%\n",
      "Epoch 25 - Loss: 0.6549054980278015 - Accuracy: 69.16%\n",
      "Epoch 26 - Loss: 0.651906430721283 - Accuracy: 68.22%\n",
      "Epoch 27 - Loss: 0.6487392783164978 - Accuracy: 70.09%\n",
      "Epoch 28 - Loss: 0.6454029679298401 - Accuracy: 70.09%\n",
      "Epoch 29 - Loss: 0.6419008374214172 - Accuracy: 71.03%\n",
      "Epoch 30 - Loss: 0.6382262110710144 - Accuracy: 72.90%\n",
      "Epoch 31 - Loss: 0.6343697309494019 - Accuracy: 73.83%\n",
      "Epoch 32 - Loss: 0.6303418874740601 - Accuracy: 75.70%\n",
      "Epoch 33 - Loss: 0.6261513233184814 - Accuracy: 76.64%\n",
      "Epoch 34 - Loss: 0.6217681169509888 - Accuracy: 77.57%\n",
      "Epoch 35 - Loss: 0.617175281047821 - Accuracy: 77.57%\n",
      "Epoch 36 - Loss: 0.6124162673950195 - Accuracy: 77.57%\n",
      "Epoch 37 - Loss: 0.6074812412261963 - Accuracy: 78.50%\n",
      "Epoch 38 - Loss: 0.6023628115653992 - Accuracy: 78.50%\n",
      "Epoch 39 - Loss: 0.5970728993415833 - Accuracy: 79.44%\n",
      "Epoch 40 - Loss: 0.5915879607200623 - Accuracy: 79.44%\n",
      "Epoch 41 - Loss: 0.5859312415122986 - Accuracy: 79.44%\n",
      "Epoch 42 - Loss: 0.580091655254364 - Accuracy: 79.44%\n",
      "Epoch 43 - Loss: 0.5740506052970886 - Accuracy: 79.44%\n",
      "Epoch 44 - Loss: 0.5678651928901672 - Accuracy: 82.24%\n",
      "Epoch 45 - Loss: 0.5615652799606323 - Accuracy: 82.24%\n",
      "Epoch 46 - Loss: 0.55511873960495 - Accuracy: 82.24%\n",
      "Epoch 47 - Loss: 0.5484964847564697 - Accuracy: 82.24%\n",
      "Epoch 48 - Loss: 0.5417733788490295 - Accuracy: 82.24%\n",
      "Epoch 49 - Loss: 0.5349143743515015 - Accuracy: 82.24%\n",
      "Epoch 50 - Loss: 0.527946949005127 - Accuracy: 81.31%\n",
      "Epoch 51 - Loss: 0.520851731300354 - Accuracy: 82.24%\n",
      "Epoch 52 - Loss: 0.5136144161224365 - Accuracy: 82.24%\n",
      "Epoch 53 - Loss: 0.5062921047210693 - Accuracy: 82.24%\n",
      "Epoch 54 - Loss: 0.4988876283168793 - Accuracy: 82.24%\n",
      "Epoch 55 - Loss: 0.4913727939128876 - Accuracy: 82.24%\n",
      "Epoch 56 - Loss: 0.4836970865726471 - Accuracy: 82.24%\n",
      "Epoch 57 - Loss: 0.47593364119529724 - Accuracy: 82.24%\n",
      "Epoch 58 - Loss: 0.4681478440761566 - Accuracy: 82.24%\n",
      "Epoch 59 - Loss: 0.4602823257446289 - Accuracy: 83.18%\n",
      "Epoch 60 - Loss: 0.4523336589336395 - Accuracy: 82.24%\n",
      "Epoch 61 - Loss: 0.4443717896938324 - Accuracy: 82.24%\n",
      "Epoch 62 - Loss: 0.4364067018032074 - Accuracy: 85.05%\n",
      "Epoch 63 - Loss: 0.4284892678260803 - Accuracy: 85.05%\n",
      "Epoch 64 - Loss: 0.4205796420574188 - Accuracy: 85.98%\n",
      "Epoch 65 - Loss: 0.41268324851989746 - Accuracy: 85.98%\n",
      "Epoch 66 - Loss: 0.4048210680484772 - Accuracy: 86.92%\n",
      "Epoch 67 - Loss: 0.397027850151062 - Accuracy: 86.92%\n",
      "Epoch 68 - Loss: 0.3893018960952759 - Accuracy: 86.92%\n",
      "Epoch 69 - Loss: 0.3816406726837158 - Accuracy: 86.92%\n",
      "Epoch 70 - Loss: 0.37403735518455505 - Accuracy: 86.92%\n",
      "Epoch 71 - Loss: 0.3665112257003784 - Accuracy: 86.92%\n",
      "Epoch 72 - Loss: 0.35909920930862427 - Accuracy: 86.92%\n",
      "Epoch 73 - Loss: 0.3517936170101166 - Accuracy: 87.85%\n",
      "Epoch 74 - Loss: 0.34458354115486145 - Accuracy: 87.85%\n",
      "Epoch 75 - Loss: 0.33748501539230347 - Accuracy: 88.79%\n",
      "Epoch 76 - Loss: 0.3305246829986572 - Accuracy: 88.79%\n",
      "Epoch 77 - Loss: 0.3237333595752716 - Accuracy: 89.72%\n",
      "Epoch 78 - Loss: 0.31708672642707825 - Accuracy: 89.72%\n",
      "Epoch 79 - Loss: 0.3105924427509308 - Accuracy: 89.72%\n",
      "Epoch 80 - Loss: 0.3042449355125427 - Accuracy: 90.65%\n",
      "Epoch 81 - Loss: 0.2980595827102661 - Accuracy: 90.65%\n",
      "Epoch 82 - Loss: 0.2920330762863159 - Accuracy: 91.59%\n",
      "Epoch 83 - Loss: 0.28615602850914 - Accuracy: 91.59%\n",
      "Epoch 84 - Loss: 0.2804132401943207 - Accuracy: 91.59%\n",
      "Epoch 85 - Loss: 0.2748105823993683 - Accuracy: 92.52%\n",
      "Epoch 86 - Loss: 0.2693708837032318 - Accuracy: 92.52%\n",
      "Epoch 87 - Loss: 0.26409009099006653 - Accuracy: 92.52%\n",
      "Epoch 88 - Loss: 0.2589552700519562 - Accuracy: 92.52%\n",
      "Epoch 89 - Loss: 0.2539515495300293 - Accuracy: 92.52%\n",
      "Epoch 90 - Loss: 0.24909362196922302 - Accuracy: 92.52%\n",
      "Epoch 91 - Loss: 0.24436385929584503 - Accuracy: 92.52%\n",
      "Epoch 92 - Loss: 0.2397574484348297 - Accuracy: 92.52%\n",
      "Epoch 93 - Loss: 0.2352532595396042 - Accuracy: 92.52%\n",
      "Epoch 94 - Loss: 0.23084048926830292 - Accuracy: 94.39%\n",
      "Epoch 95 - Loss: 0.22653105854988098 - Accuracy: 94.39%\n",
      "Epoch 96 - Loss: 0.22235672175884247 - Accuracy: 94.39%\n",
      "Epoch 97 - Loss: 0.2182624340057373 - Accuracy: 94.39%\n",
      "Epoch 98 - Loss: 0.21426424384117126 - Accuracy: 94.39%\n",
      "Epoch 99 - Loss: 0.21037204563617706 - Accuracy: 94.39%\n",
      "MLP model test accuracy: 73.53%\n",
      "Seed 21 - Test Accuracy: 73.53%\n",
      "Average Test Accuracy over seeds: 73.53%\n",
      "Running MLP experiments on PCNet data\n",
      "Epoch 0 - Loss: 0.6941725611686707 - Accuracy: 49.59%\n",
      "Epoch 1 - Loss: 0.6935703754425049 - Accuracy: 49.59%\n",
      "Epoch 2 - Loss: 0.692969024181366 - Accuracy: 49.59%\n",
      "Epoch 3 - Loss: 0.69236820936203 - Accuracy: 50.41%\n",
      "Epoch 4 - Loss: 0.6917689442634583 - Accuracy: 51.24%\n",
      "Epoch 5 - Loss: 0.6911662220954895 - Accuracy: 52.07%\n",
      "Epoch 6 - Loss: 0.6905422210693359 - Accuracy: 53.72%\n",
      "Epoch 7 - Loss: 0.689899742603302 - Accuracy: 55.37%\n",
      "Epoch 8 - Loss: 0.6892248392105103 - Accuracy: 57.85%\n",
      "Epoch 9 - Loss: 0.6885173916816711 - Accuracy: 61.16%\n",
      "Epoch 10 - Loss: 0.6877690553665161 - Accuracy: 61.16%\n",
      "Epoch 11 - Loss: 0.6869781017303467 - Accuracy: 64.46%\n",
      "Epoch 12 - Loss: 0.6861346960067749 - Accuracy: 63.64%\n",
      "Epoch 13 - Loss: 0.6852446794509888 - Accuracy: 67.77%\n",
      "Epoch 14 - Loss: 0.6842878460884094 - Accuracy: 70.25%\n",
      "Epoch 15 - Loss: 0.6832573413848877 - Accuracy: 71.07%\n",
      "Epoch 16 - Loss: 0.6821357607841492 - Accuracy: 71.90%\n",
      "Epoch 17 - Loss: 0.6809234619140625 - Accuracy: 71.90%\n",
      "Epoch 18 - Loss: 0.6796101927757263 - Accuracy: 74.38%\n",
      "Epoch 19 - Loss: 0.6782016158103943 - Accuracy: 75.21%\n",
      "Epoch 20 - Loss: 0.6767039895057678 - Accuracy: 76.03%\n",
      "Epoch 21 - Loss: 0.675101637840271 - Accuracy: 76.03%\n",
      "Epoch 22 - Loss: 0.6733551025390625 - Accuracy: 74.38%\n",
      "Epoch 23 - Loss: 0.6714791059494019 - Accuracy: 74.38%\n",
      "Epoch 24 - Loss: 0.6694664359092712 - Accuracy: 73.55%\n",
      "Epoch 25 - Loss: 0.6673247814178467 - Accuracy: 73.55%\n",
      "Epoch 26 - Loss: 0.6650344133377075 - Accuracy: 74.38%\n",
      "Epoch 27 - Loss: 0.6625900864601135 - Accuracy: 76.03%\n",
      "Epoch 28 - Loss: 0.6599881649017334 - Accuracy: 76.03%\n",
      "Epoch 29 - Loss: 0.6572407484054565 - Accuracy: 76.86%\n",
      "Epoch 30 - Loss: 0.6543265581130981 - Accuracy: 77.69%\n",
      "Epoch 31 - Loss: 0.6512571573257446 - Accuracy: 77.69%\n",
      "Epoch 32 - Loss: 0.648011326789856 - Accuracy: 77.69%\n",
      "Epoch 33 - Loss: 0.6445726752281189 - Accuracy: 77.69%\n",
      "Epoch 34 - Loss: 0.6409574151039124 - Accuracy: 76.86%\n",
      "Epoch 35 - Loss: 0.6371364593505859 - Accuracy: 76.86%\n",
      "Epoch 36 - Loss: 0.6331024169921875 - Accuracy: 76.86%\n",
      "Epoch 37 - Loss: 0.6288848519325256 - Accuracy: 78.51%\n",
      "Epoch 38 - Loss: 0.624468982219696 - Accuracy: 78.51%\n",
      "Epoch 39 - Loss: 0.6198974251747131 - Accuracy: 77.69%\n",
      "Epoch 40 - Loss: 0.6151407361030579 - Accuracy: 76.86%\n",
      "Epoch 41 - Loss: 0.6102135181427002 - Accuracy: 75.21%\n",
      "Epoch 42 - Loss: 0.6051072478294373 - Accuracy: 75.21%\n",
      "Epoch 43 - Loss: 0.5998229384422302 - Accuracy: 76.03%\n",
      "Epoch 44 - Loss: 0.594353199005127 - Accuracy: 76.03%\n",
      "Epoch 45 - Loss: 0.5886675119400024 - Accuracy: 76.86%\n",
      "Epoch 46 - Loss: 0.5827603340148926 - Accuracy: 76.86%\n",
      "Epoch 47 - Loss: 0.5766391754150391 - Accuracy: 76.86%\n",
      "Epoch 48 - Loss: 0.5703190565109253 - Accuracy: 76.03%\n",
      "Epoch 49 - Loss: 0.5638500452041626 - Accuracy: 76.03%\n",
      "Epoch 50 - Loss: 0.5572284460067749 - Accuracy: 76.03%\n",
      "Epoch 51 - Loss: 0.5504595041275024 - Accuracy: 76.03%\n",
      "Epoch 52 - Loss: 0.5435819029808044 - Accuracy: 76.03%\n",
      "Epoch 53 - Loss: 0.5365833640098572 - Accuracy: 76.86%\n",
      "Epoch 54 - Loss: 0.5295164585113525 - Accuracy: 76.86%\n",
      "Epoch 55 - Loss: 0.5223614573478699 - Accuracy: 76.86%\n",
      "Epoch 56 - Loss: 0.5150999426841736 - Accuracy: 78.51%\n",
      "Epoch 57 - Loss: 0.50772625207901 - Accuracy: 79.34%\n",
      "Epoch 58 - Loss: 0.500286340713501 - Accuracy: 80.17%\n",
      "Epoch 59 - Loss: 0.4927848279476166 - Accuracy: 80.99%\n",
      "Epoch 60 - Loss: 0.4851919412612915 - Accuracy: 80.99%\n",
      "Epoch 61 - Loss: 0.47753340005874634 - Accuracy: 80.99%\n",
      "Epoch 62 - Loss: 0.4697914123535156 - Accuracy: 81.82%\n",
      "Epoch 63 - Loss: 0.4620073437690735 - Accuracy: 82.64%\n",
      "Epoch 64 - Loss: 0.45420193672180176 - Accuracy: 83.47%\n",
      "Epoch 65 - Loss: 0.446390300989151 - Accuracy: 83.47%\n",
      "Epoch 66 - Loss: 0.4385901391506195 - Accuracy: 85.95%\n",
      "Epoch 67 - Loss: 0.4308120608329773 - Accuracy: 85.95%\n",
      "Epoch 68 - Loss: 0.4230842590332031 - Accuracy: 86.78%\n",
      "Epoch 69 - Loss: 0.4154054522514343 - Accuracy: 86.78%\n",
      "Epoch 70 - Loss: 0.4077872335910797 - Accuracy: 87.60%\n",
      "Epoch 71 - Loss: 0.4002276062965393 - Accuracy: 87.60%\n",
      "Epoch 72 - Loss: 0.39275357127189636 - Accuracy: 87.60%\n",
      "Epoch 73 - Loss: 0.38535454869270325 - Accuracy: 87.60%\n",
      "Epoch 74 - Loss: 0.37803977727890015 - Accuracy: 88.43%\n",
      "Epoch 75 - Loss: 0.3708426356315613 - Accuracy: 88.43%\n",
      "Epoch 76 - Loss: 0.3637835681438446 - Accuracy: 88.43%\n",
      "Epoch 77 - Loss: 0.35685235261917114 - Accuracy: 88.43%\n",
      "Epoch 78 - Loss: 0.35003969073295593 - Accuracy: 89.26%\n",
      "Epoch 79 - Loss: 0.34333860874176025 - Accuracy: 89.26%\n",
      "Epoch 80 - Loss: 0.33678126335144043 - Accuracy: 90.08%\n",
      "Epoch 81 - Loss: 0.330355167388916 - Accuracy: 90.08%\n",
      "Epoch 82 - Loss: 0.3240804076194763 - Accuracy: 90.91%\n",
      "Epoch 83 - Loss: 0.317945659160614 - Accuracy: 91.74%\n",
      "Epoch 84 - Loss: 0.3119431436061859 - Accuracy: 91.74%\n",
      "Epoch 85 - Loss: 0.3060983717441559 - Accuracy: 92.56%\n",
      "Epoch 86 - Loss: 0.30040666460990906 - Accuracy: 92.56%\n",
      "Epoch 87 - Loss: 0.29484137892723083 - Accuracy: 92.56%\n",
      "Epoch 88 - Loss: 0.28939035534858704 - Accuracy: 92.56%\n",
      "Epoch 89 - Loss: 0.2840827405452728 - Accuracy: 92.56%\n",
      "Epoch 90 - Loss: 0.2789178788661957 - Accuracy: 92.56%\n",
      "Epoch 91 - Loss: 0.27388906478881836 - Accuracy: 92.56%\n",
      "Epoch 92 - Loss: 0.2689850628376007 - Accuracy: 92.56%\n",
      "Epoch 93 - Loss: 0.2641906440258026 - Accuracy: 92.56%\n",
      "Epoch 94 - Loss: 0.2594864070415497 - Accuracy: 92.56%\n",
      "Epoch 95 - Loss: 0.2548917829990387 - Accuracy: 92.56%\n",
      "Epoch 96 - Loss: 0.25040385127067566 - Accuracy: 93.39%\n",
      "Epoch 97 - Loss: 0.2459581196308136 - Accuracy: 93.39%\n",
      "Epoch 98 - Loss: 0.24158112704753876 - Accuracy: 93.39%\n",
      "Epoch 99 - Loss: 0.23726074397563934 - Accuracy: 93.39%\n",
      "MLP model test accuracy: 65.79%\n",
      "Seed 42 - Test Accuracy: 65.79%\n",
      "Epoch 0 - Loss: 0.6949073076248169 - Accuracy: 50.41%\n",
      "Epoch 1 - Loss: 0.69381183385849 - Accuracy: 50.41%\n",
      "Epoch 2 - Loss: 0.6927816271781921 - Accuracy: 50.41%\n",
      "Epoch 3 - Loss: 0.691811203956604 - Accuracy: 50.41%\n",
      "Epoch 4 - Loss: 0.6908712983131409 - Accuracy: 50.41%\n",
      "Epoch 5 - Loss: 0.6899598240852356 - Accuracy: 50.41%\n",
      "Epoch 6 - Loss: 0.6890434622764587 - Accuracy: 50.41%\n",
      "Epoch 7 - Loss: 0.6881126761436462 - Accuracy: 50.41%\n",
      "Epoch 8 - Loss: 0.6871567368507385 - Accuracy: 50.41%\n",
      "Epoch 9 - Loss: 0.6861605048179626 - Accuracy: 50.41%\n",
      "Epoch 10 - Loss: 0.6851059198379517 - Accuracy: 50.41%\n",
      "Epoch 11 - Loss: 0.6839799880981445 - Accuracy: 50.41%\n",
      "Epoch 12 - Loss: 0.6827859878540039 - Accuracy: 50.41%\n",
      "Epoch 13 - Loss: 0.6815199851989746 - Accuracy: 50.41%\n",
      "Epoch 14 - Loss: 0.6801792979240417 - Accuracy: 50.41%\n",
      "Epoch 15 - Loss: 0.6787533164024353 - Accuracy: 50.41%\n",
      "Epoch 16 - Loss: 0.677248477935791 - Accuracy: 52.07%\n",
      "Epoch 17 - Loss: 0.6756370663642883 - Accuracy: 53.72%\n",
      "Epoch 18 - Loss: 0.6739077568054199 - Accuracy: 57.02%\n",
      "Epoch 19 - Loss: 0.6720491051673889 - Accuracy: 58.68%\n",
      "Epoch 20 - Loss: 0.6700561046600342 - Accuracy: 62.81%\n",
      "Epoch 21 - Loss: 0.6678956747055054 - Accuracy: 64.46%\n",
      "Epoch 22 - Loss: 0.6655614376068115 - Accuracy: 66.12%\n",
      "Epoch 23 - Loss: 0.6631033420562744 - Accuracy: 69.42%\n",
      "Epoch 24 - Loss: 0.660496711730957 - Accuracy: 71.07%\n",
      "Epoch 25 - Loss: 0.657763659954071 - Accuracy: 71.90%\n",
      "Epoch 26 - Loss: 0.6548524498939514 - Accuracy: 72.73%\n",
      "Epoch 27 - Loss: 0.6517704725265503 - Accuracy: 72.73%\n",
      "Epoch 28 - Loss: 0.648531973361969 - Accuracy: 72.73%\n",
      "Epoch 29 - Loss: 0.6450681090354919 - Accuracy: 73.55%\n",
      "Epoch 30 - Loss: 0.641395092010498 - Accuracy: 73.55%\n",
      "Epoch 31 - Loss: 0.6375510096549988 - Accuracy: 75.21%\n",
      "Epoch 32 - Loss: 0.6335305571556091 - Accuracy: 75.21%\n",
      "Epoch 33 - Loss: 0.629327118396759 - Accuracy: 79.34%\n",
      "Epoch 34 - Loss: 0.6249250769615173 - Accuracy: 79.34%\n",
      "Epoch 35 - Loss: 0.6203321218490601 - Accuracy: 80.17%\n",
      "Epoch 36 - Loss: 0.6155710220336914 - Accuracy: 78.51%\n",
      "Epoch 37 - Loss: 0.610633373260498 - Accuracy: 79.34%\n",
      "Epoch 38 - Loss: 0.6055185198783875 - Accuracy: 80.17%\n",
      "Epoch 39 - Loss: 0.6002355813980103 - Accuracy: 79.34%\n",
      "Epoch 40 - Loss: 0.5948116779327393 - Accuracy: 79.34%\n",
      "Epoch 41 - Loss: 0.5892621874809265 - Accuracy: 79.34%\n",
      "Epoch 42 - Loss: 0.5835708379745483 - Accuracy: 80.17%\n",
      "Epoch 43 - Loss: 0.577725350856781 - Accuracy: 79.34%\n",
      "Epoch 44 - Loss: 0.5717186331748962 - Accuracy: 79.34%\n",
      "Epoch 45 - Loss: 0.5655928254127502 - Accuracy: 79.34%\n",
      "Epoch 46 - Loss: 0.5593339800834656 - Accuracy: 79.34%\n",
      "Epoch 47 - Loss: 0.5529335737228394 - Accuracy: 80.17%\n",
      "Epoch 48 - Loss: 0.5464009642601013 - Accuracy: 80.17%\n",
      "Epoch 49 - Loss: 0.5397238731384277 - Accuracy: 81.82%\n",
      "Epoch 50 - Loss: 0.5329074859619141 - Accuracy: 80.99%\n",
      "Epoch 51 - Loss: 0.5259668231010437 - Accuracy: 80.99%\n",
      "Epoch 52 - Loss: 0.5189279317855835 - Accuracy: 80.99%\n",
      "Epoch 53 - Loss: 0.5118017196655273 - Accuracy: 80.99%\n",
      "Epoch 54 - Loss: 0.5045440793037415 - Accuracy: 81.82%\n",
      "Epoch 55 - Loss: 0.4971888065338135 - Accuracy: 81.82%\n",
      "Epoch 56 - Loss: 0.48975807428359985 - Accuracy: 80.99%\n",
      "Epoch 57 - Loss: 0.48224854469299316 - Accuracy: 81.82%\n",
      "Epoch 58 - Loss: 0.4746701717376709 - Accuracy: 82.64%\n",
      "Epoch 59 - Loss: 0.46702659130096436 - Accuracy: 82.64%\n",
      "Epoch 60 - Loss: 0.459332138299942 - Accuracy: 85.12%\n",
      "Epoch 61 - Loss: 0.4516068696975708 - Accuracy: 85.12%\n",
      "Epoch 62 - Loss: 0.4438472390174866 - Accuracy: 85.12%\n",
      "Epoch 63 - Loss: 0.43610045313835144 - Accuracy: 85.12%\n",
      "Epoch 64 - Loss: 0.42835989594459534 - Accuracy: 85.12%\n",
      "Epoch 65 - Loss: 0.420624315738678 - Accuracy: 85.95%\n",
      "Epoch 66 - Loss: 0.41293609142303467 - Accuracy: 87.60%\n",
      "Epoch 67 - Loss: 0.4053272008895874 - Accuracy: 87.60%\n",
      "Epoch 68 - Loss: 0.39779168367385864 - Accuracy: 87.60%\n",
      "Epoch 69 - Loss: 0.39034754037857056 - Accuracy: 87.60%\n",
      "Epoch 70 - Loss: 0.3829905688762665 - Accuracy: 87.60%\n",
      "Epoch 71 - Loss: 0.3757345676422119 - Accuracy: 87.60%\n",
      "Epoch 72 - Loss: 0.36859530210494995 - Accuracy: 88.43%\n",
      "Epoch 73 - Loss: 0.3615628480911255 - Accuracy: 88.43%\n",
      "Epoch 74 - Loss: 0.3546849191188812 - Accuracy: 88.43%\n",
      "Epoch 75 - Loss: 0.34794512391090393 - Accuracy: 89.26%\n",
      "Epoch 76 - Loss: 0.3413570523262024 - Accuracy: 89.26%\n",
      "Epoch 77 - Loss: 0.33490628004074097 - Accuracy: 89.26%\n",
      "Epoch 78 - Loss: 0.3285664916038513 - Accuracy: 89.26%\n",
      "Epoch 79 - Loss: 0.3223723769187927 - Accuracy: 89.26%\n",
      "Epoch 80 - Loss: 0.31633901596069336 - Accuracy: 90.08%\n",
      "Epoch 81 - Loss: 0.31046006083488464 - Accuracy: 90.91%\n",
      "Epoch 82 - Loss: 0.3047395944595337 - Accuracy: 90.91%\n",
      "Epoch 83 - Loss: 0.2991673946380615 - Accuracy: 90.91%\n",
      "Epoch 84 - Loss: 0.2937341630458832 - Accuracy: 90.91%\n",
      "Epoch 85 - Loss: 0.28842267394065857 - Accuracy: 90.91%\n",
      "Epoch 86 - Loss: 0.2832511067390442 - Accuracy: 91.74%\n",
      "Epoch 87 - Loss: 0.278207391500473 - Accuracy: 91.74%\n",
      "Epoch 88 - Loss: 0.27327269315719604 - Accuracy: 91.74%\n",
      "Epoch 89 - Loss: 0.26846617460250854 - Accuracy: 91.74%\n",
      "Epoch 90 - Loss: 0.2637677490711212 - Accuracy: 91.74%\n",
      "Epoch 91 - Loss: 0.2591637969017029 - Accuracy: 91.74%\n",
      "Epoch 92 - Loss: 0.2546951472759247 - Accuracy: 91.74%\n",
      "Epoch 93 - Loss: 0.25033897161483765 - Accuracy: 93.39%\n",
      "Epoch 94 - Loss: 0.24607311189174652 - Accuracy: 93.39%\n",
      "Epoch 95 - Loss: 0.24190908670425415 - Accuracy: 94.21%\n",
      "Epoch 96 - Loss: 0.23783613741397858 - Accuracy: 94.21%\n",
      "Epoch 97 - Loss: 0.23386889696121216 - Accuracy: 94.21%\n",
      "Epoch 98 - Loss: 0.22997376322746277 - Accuracy: 94.21%\n",
      "Epoch 99 - Loss: 0.22615055739879608 - Accuracy: 94.21%\n",
      "MLP model test accuracy: 65.79%\n",
      "Seed 7 - Test Accuracy: 65.79%\n",
      "Epoch 0 - Loss: 0.6969027519226074 - Accuracy: 50.41%\n",
      "Epoch 1 - Loss: 0.6957265138626099 - Accuracy: 50.41%\n",
      "Epoch 2 - Loss: 0.6946055293083191 - Accuracy: 50.41%\n",
      "Epoch 3 - Loss: 0.6935099959373474 - Accuracy: 50.41%\n",
      "Epoch 4 - Loss: 0.6924353837966919 - Accuracy: 50.41%\n",
      "Epoch 5 - Loss: 0.6913549900054932 - Accuracy: 50.41%\n",
      "Epoch 6 - Loss: 0.6902531385421753 - Accuracy: 50.41%\n",
      "Epoch 7 - Loss: 0.6891130208969116 - Accuracy: 50.41%\n",
      "Epoch 8 - Loss: 0.687938392162323 - Accuracy: 50.41%\n",
      "Epoch 9 - Loss: 0.6867080926895142 - Accuracy: 50.41%\n",
      "Epoch 10 - Loss: 0.6854127645492554 - Accuracy: 50.41%\n",
      "Epoch 11 - Loss: 0.6840437650680542 - Accuracy: 50.41%\n",
      "Epoch 12 - Loss: 0.6825935244560242 - Accuracy: 51.24%\n",
      "Epoch 13 - Loss: 0.6810368895530701 - Accuracy: 52.89%\n",
      "Epoch 14 - Loss: 0.6793836951255798 - Accuracy: 53.72%\n",
      "Epoch 15 - Loss: 0.677625298500061 - Accuracy: 57.02%\n",
      "Epoch 16 - Loss: 0.6757519245147705 - Accuracy: 58.68%\n",
      "Epoch 17 - Loss: 0.67376309633255 - Accuracy: 59.50%\n",
      "Epoch 18 - Loss: 0.6716598272323608 - Accuracy: 61.16%\n",
      "Epoch 19 - Loss: 0.6694590449333191 - Accuracy: 61.98%\n",
      "Epoch 20 - Loss: 0.6671244502067566 - Accuracy: 65.29%\n",
      "Epoch 21 - Loss: 0.6646615266799927 - Accuracy: 66.12%\n",
      "Epoch 22 - Loss: 0.6620157957077026 - Accuracy: 67.77%\n",
      "Epoch 23 - Loss: 0.6592006683349609 - Accuracy: 68.60%\n",
      "Epoch 24 - Loss: 0.6562108397483826 - Accuracy: 73.55%\n",
      "Epoch 25 - Loss: 0.6530398726463318 - Accuracy: 75.21%\n",
      "Epoch 26 - Loss: 0.6496872305870056 - Accuracy: 75.21%\n",
      "Epoch 27 - Loss: 0.6461290717124939 - Accuracy: 75.21%\n",
      "Epoch 28 - Loss: 0.6423540711402893 - Accuracy: 73.55%\n",
      "Epoch 29 - Loss: 0.6383614540100098 - Accuracy: 74.38%\n",
      "Epoch 30 - Loss: 0.6341756582260132 - Accuracy: 73.55%\n",
      "Epoch 31 - Loss: 0.6298165321350098 - Accuracy: 74.38%\n",
      "Epoch 32 - Loss: 0.6252195835113525 - Accuracy: 75.21%\n",
      "Epoch 33 - Loss: 0.6204400658607483 - Accuracy: 76.86%\n",
      "Epoch 34 - Loss: 0.6154360771179199 - Accuracy: 76.86%\n",
      "Epoch 35 - Loss: 0.6102091073989868 - Accuracy: 76.86%\n",
      "Epoch 36 - Loss: 0.6047669053077698 - Accuracy: 76.03%\n",
      "Epoch 37 - Loss: 0.5991215705871582 - Accuracy: 76.03%\n",
      "Epoch 38 - Loss: 0.5933199524879456 - Accuracy: 76.03%\n",
      "Epoch 39 - Loss: 0.5873045325279236 - Accuracy: 76.03%\n",
      "Epoch 40 - Loss: 0.581109344959259 - Accuracy: 76.03%\n",
      "Epoch 41 - Loss: 0.5747888684272766 - Accuracy: 77.69%\n",
      "Epoch 42 - Loss: 0.5683587193489075 - Accuracy: 77.69%\n",
      "Epoch 43 - Loss: 0.5617362856864929 - Accuracy: 77.69%\n",
      "Epoch 44 - Loss: 0.554957389831543 - Accuracy: 77.69%\n",
      "Epoch 45 - Loss: 0.5480527877807617 - Accuracy: 78.51%\n",
      "Epoch 46 - Loss: 0.5410112142562866 - Accuracy: 79.34%\n",
      "Epoch 47 - Loss: 0.5338098406791687 - Accuracy: 79.34%\n",
      "Epoch 48 - Loss: 0.5264769196510315 - Accuracy: 80.17%\n",
      "Epoch 49 - Loss: 0.5190327167510986 - Accuracy: 80.17%\n",
      "Epoch 50 - Loss: 0.5114803314208984 - Accuracy: 80.99%\n",
      "Epoch 51 - Loss: 0.5038266777992249 - Accuracy: 80.99%\n",
      "Epoch 52 - Loss: 0.496102511882782 - Accuracy: 81.82%\n",
      "Epoch 53 - Loss: 0.4883090853691101 - Accuracy: 81.82%\n",
      "Epoch 54 - Loss: 0.4804667830467224 - Accuracy: 81.82%\n",
      "Epoch 55 - Loss: 0.4725934565067291 - Accuracy: 80.99%\n",
      "Epoch 56 - Loss: 0.46469298005104065 - Accuracy: 80.99%\n",
      "Epoch 57 - Loss: 0.45678800344467163 - Accuracy: 81.82%\n",
      "Epoch 58 - Loss: 0.44888240098953247 - Accuracy: 82.64%\n",
      "Epoch 59 - Loss: 0.4410085678100586 - Accuracy: 82.64%\n",
      "Epoch 60 - Loss: 0.4331720769405365 - Accuracy: 84.30%\n",
      "Epoch 61 - Loss: 0.425348162651062 - Accuracy: 84.30%\n",
      "Epoch 62 - Loss: 0.41757333278656006 - Accuracy: 84.30%\n",
      "Epoch 63 - Loss: 0.4098576605319977 - Accuracy: 84.30%\n",
      "Epoch 64 - Loss: 0.40220439434051514 - Accuracy: 85.12%\n",
      "Epoch 65 - Loss: 0.3946484625339508 - Accuracy: 85.95%\n",
      "Epoch 66 - Loss: 0.3871973752975464 - Accuracy: 86.78%\n",
      "Epoch 67 - Loss: 0.3798212707042694 - Accuracy: 87.60%\n",
      "Epoch 68 - Loss: 0.37253835797309875 - Accuracy: 87.60%\n",
      "Epoch 69 - Loss: 0.36536476016044617 - Accuracy: 87.60%\n",
      "Epoch 70 - Loss: 0.358334481716156 - Accuracy: 87.60%\n",
      "Epoch 71 - Loss: 0.3514249622821808 - Accuracy: 87.60%\n",
      "Epoch 72 - Loss: 0.3446162939071655 - Accuracy: 88.43%\n",
      "Epoch 73 - Loss: 0.33796679973602295 - Accuracy: 89.26%\n",
      "Epoch 74 - Loss: 0.3314609229564667 - Accuracy: 90.08%\n",
      "Epoch 75 - Loss: 0.3251076936721802 - Accuracy: 90.08%\n",
      "Epoch 76 - Loss: 0.3188726007938385 - Accuracy: 90.08%\n",
      "Epoch 77 - Loss: 0.31276819109916687 - Accuracy: 90.08%\n",
      "Epoch 78 - Loss: 0.3067854344844818 - Accuracy: 90.91%\n",
      "Epoch 79 - Loss: 0.3009353578090668 - Accuracy: 90.91%\n",
      "Epoch 80 - Loss: 0.2952217161655426 - Accuracy: 90.91%\n",
      "Epoch 81 - Loss: 0.28962329030036926 - Accuracy: 90.91%\n",
      "Epoch 82 - Loss: 0.28414154052734375 - Accuracy: 91.74%\n",
      "Epoch 83 - Loss: 0.27876538038253784 - Accuracy: 91.74%\n",
      "Epoch 84 - Loss: 0.2734806537628174 - Accuracy: 92.56%\n",
      "Epoch 85 - Loss: 0.26832976937294006 - Accuracy: 92.56%\n",
      "Epoch 86 - Loss: 0.26329514384269714 - Accuracy: 92.56%\n",
      "Epoch 87 - Loss: 0.2583758533000946 - Accuracy: 92.56%\n",
      "Epoch 88 - Loss: 0.2535672187805176 - Accuracy: 93.39%\n",
      "Epoch 89 - Loss: 0.2488698661327362 - Accuracy: 93.39%\n",
      "Epoch 90 - Loss: 0.24426068365573883 - Accuracy: 94.21%\n",
      "Epoch 91 - Loss: 0.23972798883914948 - Accuracy: 94.21%\n",
      "Epoch 92 - Loss: 0.23529040813446045 - Accuracy: 95.04%\n",
      "Epoch 93 - Loss: 0.23096305131912231 - Accuracy: 95.04%\n",
      "Epoch 94 - Loss: 0.22674031555652618 - Accuracy: 94.21%\n",
      "Epoch 95 - Loss: 0.22259925305843353 - Accuracy: 94.21%\n",
      "Epoch 96 - Loss: 0.21853774785995483 - Accuracy: 94.21%\n",
      "Epoch 97 - Loss: 0.21454089879989624 - Accuracy: 94.21%\n",
      "Epoch 98 - Loss: 0.2106238454580307 - Accuracy: 94.21%\n",
      "Epoch 99 - Loss: 0.20676523447036743 - Accuracy: 94.21%\n",
      "MLP model test accuracy: 65.79%\n",
      "Seed 21 - Test Accuracy: 65.79%\n",
      "Average Test Accuracy over seeds: 65.79%\n",
      "Running MLP experiments on STRINGdb data\n",
      "Epoch 0 - Loss: 0.6930416822433472 - Accuracy: 49.55%\n",
      "Epoch 1 - Loss: 0.692447304725647 - Accuracy: 50.45%\n",
      "Epoch 2 - Loss: 0.6918586492538452 - Accuracy: 50.45%\n",
      "Epoch 3 - Loss: 0.6912766695022583 - Accuracy: 51.35%\n",
      "Epoch 4 - Loss: 0.690692126750946 - Accuracy: 53.15%\n",
      "Epoch 5 - Loss: 0.6900977492332458 - Accuracy: 55.86%\n",
      "Epoch 6 - Loss: 0.6894907355308533 - Accuracy: 62.16%\n",
      "Epoch 7 - Loss: 0.6888604164123535 - Accuracy: 66.67%\n",
      "Epoch 8 - Loss: 0.6881839036941528 - Accuracy: 70.27%\n",
      "Epoch 9 - Loss: 0.687481164932251 - Accuracy: 72.07%\n",
      "Epoch 10 - Loss: 0.6867308020591736 - Accuracy: 75.68%\n",
      "Epoch 11 - Loss: 0.6859418749809265 - Accuracy: 70.27%\n",
      "Epoch 12 - Loss: 0.6851222515106201 - Accuracy: 69.37%\n",
      "Epoch 13 - Loss: 0.6842509508132935 - Accuracy: 68.47%\n",
      "Epoch 14 - Loss: 0.6833235621452332 - Accuracy: 63.96%\n",
      "Epoch 15 - Loss: 0.6823307871818542 - Accuracy: 63.06%\n",
      "Epoch 16 - Loss: 0.6812631487846375 - Accuracy: 63.06%\n",
      "Epoch 17 - Loss: 0.6801177859306335 - Accuracy: 62.16%\n",
      "Epoch 18 - Loss: 0.678898811340332 - Accuracy: 62.16%\n",
      "Epoch 19 - Loss: 0.6775873303413391 - Accuracy: 63.06%\n",
      "Epoch 20 - Loss: 0.6761536002159119 - Accuracy: 64.86%\n",
      "Epoch 21 - Loss: 0.6746070981025696 - Accuracy: 65.77%\n",
      "Epoch 22 - Loss: 0.6729337573051453 - Accuracy: 65.77%\n",
      "Epoch 23 - Loss: 0.6711258888244629 - Accuracy: 66.67%\n",
      "Epoch 24 - Loss: 0.6691727638244629 - Accuracy: 66.67%\n",
      "Epoch 25 - Loss: 0.6670801639556885 - Accuracy: 67.57%\n",
      "Epoch 26 - Loss: 0.6648368239402771 - Accuracy: 72.07%\n",
      "Epoch 27 - Loss: 0.6624447703361511 - Accuracy: 73.87%\n",
      "Epoch 28 - Loss: 0.6599164605140686 - Accuracy: 75.68%\n",
      "Epoch 29 - Loss: 0.6572411060333252 - Accuracy: 75.68%\n",
      "Epoch 30 - Loss: 0.6544081568717957 - Accuracy: 78.38%\n",
      "Epoch 31 - Loss: 0.6514241099357605 - Accuracy: 77.48%\n",
      "Epoch 32 - Loss: 0.6482537984848022 - Accuracy: 77.48%\n",
      "Epoch 33 - Loss: 0.6448765397071838 - Accuracy: 77.48%\n",
      "Epoch 34 - Loss: 0.6413009762763977 - Accuracy: 78.38%\n",
      "Epoch 35 - Loss: 0.6375365853309631 - Accuracy: 78.38%\n",
      "Epoch 36 - Loss: 0.6335799694061279 - Accuracy: 74.77%\n",
      "Epoch 37 - Loss: 0.6294362545013428 - Accuracy: 74.77%\n",
      "Epoch 38 - Loss: 0.6250610947608948 - Accuracy: 74.77%\n",
      "Epoch 39 - Loss: 0.6205182671546936 - Accuracy: 75.68%\n",
      "Epoch 40 - Loss: 0.6157849431037903 - Accuracy: 75.68%\n",
      "Epoch 41 - Loss: 0.6108461022377014 - Accuracy: 76.58%\n",
      "Epoch 42 - Loss: 0.605689287185669 - Accuracy: 77.48%\n",
      "Epoch 43 - Loss: 0.600288450717926 - Accuracy: 77.48%\n",
      "Epoch 44 - Loss: 0.5946692824363708 - Accuracy: 77.48%\n",
      "Epoch 45 - Loss: 0.5888504981994629 - Accuracy: 77.48%\n",
      "Epoch 46 - Loss: 0.5828111171722412 - Accuracy: 77.48%\n",
      "Epoch 47 - Loss: 0.5765316486358643 - Accuracy: 77.48%\n",
      "Epoch 48 - Loss: 0.5700316429138184 - Accuracy: 78.38%\n",
      "Epoch 49 - Loss: 0.5633593201637268 - Accuracy: 78.38%\n",
      "Epoch 50 - Loss: 0.5565518140792847 - Accuracy: 79.28%\n",
      "Epoch 51 - Loss: 0.5496071577072144 - Accuracy: 79.28%\n",
      "Epoch 52 - Loss: 0.5425223708152771 - Accuracy: 79.28%\n",
      "Epoch 53 - Loss: 0.535317599773407 - Accuracy: 81.08%\n",
      "Epoch 54 - Loss: 0.5279917120933533 - Accuracy: 81.98%\n",
      "Epoch 55 - Loss: 0.5205661058425903 - Accuracy: 84.68%\n",
      "Epoch 56 - Loss: 0.5130497217178345 - Accuracy: 84.68%\n",
      "Epoch 57 - Loss: 0.5054567456245422 - Accuracy: 84.68%\n",
      "Epoch 58 - Loss: 0.49780383706092834 - Accuracy: 84.68%\n",
      "Epoch 59 - Loss: 0.4900971055030823 - Accuracy: 84.68%\n",
      "Epoch 60 - Loss: 0.48234716057777405 - Accuracy: 85.59%\n",
      "Epoch 61 - Loss: 0.47454833984375 - Accuracy: 85.59%\n",
      "Epoch 62 - Loss: 0.46672216057777405 - Accuracy: 85.59%\n",
      "Epoch 63 - Loss: 0.4589105546474457 - Accuracy: 85.59%\n",
      "Epoch 64 - Loss: 0.4511198103427887 - Accuracy: 85.59%\n",
      "Epoch 65 - Loss: 0.44334694743156433 - Accuracy: 86.49%\n",
      "Epoch 66 - Loss: 0.4356270134449005 - Accuracy: 86.49%\n",
      "Epoch 67 - Loss: 0.42794349789619446 - Accuracy: 86.49%\n",
      "Epoch 68 - Loss: 0.42033103108406067 - Accuracy: 86.49%\n",
      "Epoch 69 - Loss: 0.41278061270713806 - Accuracy: 87.39%\n",
      "Epoch 70 - Loss: 0.4053049087524414 - Accuracy: 87.39%\n",
      "Epoch 71 - Loss: 0.3979155123233795 - Accuracy: 87.39%\n",
      "Epoch 72 - Loss: 0.39059582352638245 - Accuracy: 88.29%\n",
      "Epoch 73 - Loss: 0.3833623230457306 - Accuracy: 88.29%\n",
      "Epoch 74 - Loss: 0.3762325942516327 - Accuracy: 88.29%\n",
      "Epoch 75 - Loss: 0.36919155716896057 - Accuracy: 89.19%\n",
      "Epoch 76 - Loss: 0.3622380197048187 - Accuracy: 89.19%\n",
      "Epoch 77 - Loss: 0.3554053008556366 - Accuracy: 89.19%\n",
      "Epoch 78 - Loss: 0.3486665189266205 - Accuracy: 90.09%\n",
      "Epoch 79 - Loss: 0.34203583002090454 - Accuracy: 90.99%\n",
      "Epoch 80 - Loss: 0.3354998528957367 - Accuracy: 90.99%\n",
      "Epoch 81 - Loss: 0.3290654122829437 - Accuracy: 90.99%\n",
      "Epoch 82 - Loss: 0.32273924350738525 - Accuracy: 90.99%\n",
      "Epoch 83 - Loss: 0.3165281414985657 - Accuracy: 91.89%\n",
      "Epoch 84 - Loss: 0.31044259667396545 - Accuracy: 91.89%\n",
      "Epoch 85 - Loss: 0.3044706881046295 - Accuracy: 91.89%\n",
      "Epoch 86 - Loss: 0.2985767424106598 - Accuracy: 91.89%\n",
      "Epoch 87 - Loss: 0.2927637994289398 - Accuracy: 91.89%\n",
      "Epoch 88 - Loss: 0.2870695888996124 - Accuracy: 91.89%\n",
      "Epoch 89 - Loss: 0.2814755439758301 - Accuracy: 91.89%\n",
      "Epoch 90 - Loss: 0.275983989238739 - Accuracy: 91.89%\n",
      "Epoch 91 - Loss: 0.2705959379673004 - Accuracy: 91.89%\n",
      "Epoch 92 - Loss: 0.26532480120658875 - Accuracy: 91.89%\n",
      "Epoch 93 - Loss: 0.2601701319217682 - Accuracy: 91.89%\n",
      "Epoch 94 - Loss: 0.2550949454307556 - Accuracy: 90.99%\n",
      "Epoch 95 - Loss: 0.25011393427848816 - Accuracy: 91.89%\n",
      "Epoch 96 - Loss: 0.24524712562561035 - Accuracy: 91.89%\n",
      "Epoch 97 - Loss: 0.24048039317131042 - Accuracy: 92.79%\n",
      "Epoch 98 - Loss: 0.23578430712223053 - Accuracy: 92.79%\n",
      "Epoch 99 - Loss: 0.23116883635520935 - Accuracy: 93.69%\n",
      "MLP model test accuracy: 80.00%\n",
      "Seed 42 - Test Accuracy: 80.00%\n",
      "Epoch 0 - Loss: 0.6937410235404968 - Accuracy: 50.45%\n",
      "Epoch 1 - Loss: 0.6927396059036255 - Accuracy: 50.45%\n",
      "Epoch 2 - Loss: 0.6917938590049744 - Accuracy: 50.45%\n",
      "Epoch 3 - Loss: 0.6908641457557678 - Accuracy: 50.45%\n",
      "Epoch 4 - Loss: 0.6899381279945374 - Accuracy: 50.45%\n",
      "Epoch 5 - Loss: 0.6889669299125671 - Accuracy: 50.45%\n",
      "Epoch 6 - Loss: 0.6879739165306091 - Accuracy: 50.45%\n",
      "Epoch 7 - Loss: 0.6869673728942871 - Accuracy: 50.45%\n",
      "Epoch 8 - Loss: 0.6859444975852966 - Accuracy: 50.45%\n",
      "Epoch 9 - Loss: 0.6848439574241638 - Accuracy: 50.45%\n",
      "Epoch 10 - Loss: 0.6836860775947571 - Accuracy: 50.45%\n",
      "Epoch 11 - Loss: 0.6824330687522888 - Accuracy: 51.35%\n",
      "Epoch 12 - Loss: 0.6810913681983948 - Accuracy: 51.35%\n",
      "Epoch 13 - Loss: 0.6796755194664001 - Accuracy: 51.35%\n",
      "Epoch 14 - Loss: 0.6781626343727112 - Accuracy: 52.25%\n",
      "Epoch 15 - Loss: 0.6765449643135071 - Accuracy: 56.76%\n",
      "Epoch 16 - Loss: 0.6748064756393433 - Accuracy: 60.36%\n",
      "Epoch 17 - Loss: 0.6729534268379211 - Accuracy: 63.96%\n",
      "Epoch 18 - Loss: 0.6709715723991394 - Accuracy: 67.57%\n",
      "Epoch 19 - Loss: 0.6688610911369324 - Accuracy: 71.17%\n",
      "Epoch 20 - Loss: 0.6665962338447571 - Accuracy: 74.77%\n",
      "Epoch 21 - Loss: 0.6641610860824585 - Accuracy: 78.38%\n",
      "Epoch 22 - Loss: 0.6615718007087708 - Accuracy: 80.18%\n",
      "Epoch 23 - Loss: 0.6588448286056519 - Accuracy: 77.48%\n",
      "Epoch 24 - Loss: 0.6559551954269409 - Accuracy: 78.38%\n",
      "Epoch 25 - Loss: 0.6528761386871338 - Accuracy: 79.28%\n",
      "Epoch 26 - Loss: 0.6496163606643677 - Accuracy: 79.28%\n",
      "Epoch 27 - Loss: 0.6461414098739624 - Accuracy: 79.28%\n",
      "Epoch 28 - Loss: 0.6424925327301025 - Accuracy: 79.28%\n",
      "Epoch 29 - Loss: 0.6386720538139343 - Accuracy: 80.18%\n",
      "Epoch 30 - Loss: 0.6346641182899475 - Accuracy: 80.18%\n",
      "Epoch 31 - Loss: 0.6304645538330078 - Accuracy: 81.08%\n",
      "Epoch 32 - Loss: 0.6260614991188049 - Accuracy: 81.98%\n",
      "Epoch 33 - Loss: 0.6214648485183716 - Accuracy: 81.98%\n",
      "Epoch 34 - Loss: 0.6166657209396362 - Accuracy: 81.98%\n",
      "Epoch 35 - Loss: 0.611657977104187 - Accuracy: 82.88%\n",
      "Epoch 36 - Loss: 0.6064560413360596 - Accuracy: 82.88%\n",
      "Epoch 37 - Loss: 0.6010605692863464 - Accuracy: 82.88%\n",
      "Epoch 38 - Loss: 0.595459520816803 - Accuracy: 83.78%\n",
      "Epoch 39 - Loss: 0.589660108089447 - Accuracy: 84.68%\n",
      "Epoch 40 - Loss: 0.5836670994758606 - Accuracy: 84.68%\n",
      "Epoch 41 - Loss: 0.577495813369751 - Accuracy: 85.59%\n",
      "Epoch 42 - Loss: 0.5711769461631775 - Accuracy: 85.59%\n",
      "Epoch 43 - Loss: 0.5646949410438538 - Accuracy: 85.59%\n",
      "Epoch 44 - Loss: 0.5580683946609497 - Accuracy: 85.59%\n",
      "Epoch 45 - Loss: 0.551283061504364 - Accuracy: 85.59%\n",
      "Epoch 46 - Loss: 0.5443699359893799 - Accuracy: 85.59%\n",
      "Epoch 47 - Loss: 0.5373457074165344 - Accuracy: 85.59%\n",
      "Epoch 48 - Loss: 0.5302098393440247 - Accuracy: 85.59%\n",
      "Epoch 49 - Loss: 0.5229703783988953 - Accuracy: 85.59%\n",
      "Epoch 50 - Loss: 0.5156447887420654 - Accuracy: 85.59%\n",
      "Epoch 51 - Loss: 0.5082380771636963 - Accuracy: 85.59%\n",
      "Epoch 52 - Loss: 0.5007870197296143 - Accuracy: 85.59%\n",
      "Epoch 53 - Loss: 0.49328458309173584 - Accuracy: 85.59%\n",
      "Epoch 54 - Loss: 0.48576128482818604 - Accuracy: 85.59%\n",
      "Epoch 55 - Loss: 0.47821295261383057 - Accuracy: 85.59%\n",
      "Epoch 56 - Loss: 0.47061866521835327 - Accuracy: 85.59%\n",
      "Epoch 57 - Loss: 0.4630015194416046 - Accuracy: 86.49%\n",
      "Epoch 58 - Loss: 0.4553747773170471 - Accuracy: 86.49%\n",
      "Epoch 59 - Loss: 0.447775274515152 - Accuracy: 86.49%\n",
      "Epoch 60 - Loss: 0.4402162432670593 - Accuracy: 86.49%\n",
      "Epoch 61 - Loss: 0.4326836168766022 - Accuracy: 86.49%\n",
      "Epoch 62 - Loss: 0.42522338032722473 - Accuracy: 86.49%\n",
      "Epoch 63 - Loss: 0.4178072512149811 - Accuracy: 86.49%\n",
      "Epoch 64 - Loss: 0.4104107916355133 - Accuracy: 86.49%\n",
      "Epoch 65 - Loss: 0.4030963182449341 - Accuracy: 86.49%\n",
      "Epoch 66 - Loss: 0.3958769738674164 - Accuracy: 86.49%\n",
      "Epoch 67 - Loss: 0.3887767493724823 - Accuracy: 87.39%\n",
      "Epoch 68 - Loss: 0.3817455470561981 - Accuracy: 88.29%\n",
      "Epoch 69 - Loss: 0.3747861087322235 - Accuracy: 88.29%\n",
      "Epoch 70 - Loss: 0.36793017387390137 - Accuracy: 88.29%\n",
      "Epoch 71 - Loss: 0.3611948788166046 - Accuracy: 89.19%\n",
      "Epoch 72 - Loss: 0.35454878211021423 - Accuracy: 89.19%\n",
      "Epoch 73 - Loss: 0.34798359870910645 - Accuracy: 89.19%\n",
      "Epoch 74 - Loss: 0.34153348207473755 - Accuracy: 89.19%\n",
      "Epoch 75 - Loss: 0.33516260981559753 - Accuracy: 89.19%\n",
      "Epoch 76 - Loss: 0.32889485359191895 - Accuracy: 90.99%\n",
      "Epoch 77 - Loss: 0.3227268159389496 - Accuracy: 90.99%\n",
      "Epoch 78 - Loss: 0.3166617453098297 - Accuracy: 90.99%\n",
      "Epoch 79 - Loss: 0.3107238709926605 - Accuracy: 90.99%\n",
      "Epoch 80 - Loss: 0.3048824667930603 - Accuracy: 90.99%\n",
      "Epoch 81 - Loss: 0.29913800954818726 - Accuracy: 90.09%\n",
      "Epoch 82 - Loss: 0.2934891879558563 - Accuracy: 90.09%\n",
      "Epoch 83 - Loss: 0.28795480728149414 - Accuracy: 90.09%\n",
      "Epoch 84 - Loss: 0.28253617882728577 - Accuracy: 90.09%\n",
      "Epoch 85 - Loss: 0.2771989703178406 - Accuracy: 90.09%\n",
      "Epoch 86 - Loss: 0.27196240425109863 - Accuracy: 90.09%\n",
      "Epoch 87 - Loss: 0.2668309509754181 - Accuracy: 90.09%\n",
      "Epoch 88 - Loss: 0.26177799701690674 - Accuracy: 90.09%\n",
      "Epoch 89 - Loss: 0.25682735443115234 - Accuracy: 90.09%\n",
      "Epoch 90 - Loss: 0.2519899606704712 - Accuracy: 90.09%\n",
      "Epoch 91 - Loss: 0.2472178190946579 - Accuracy: 90.99%\n",
      "Epoch 92 - Loss: 0.24251316487789154 - Accuracy: 90.99%\n",
      "Epoch 93 - Loss: 0.2379073053598404 - Accuracy: 90.99%\n",
      "Epoch 94 - Loss: 0.23339541256427765 - Accuracy: 92.79%\n",
      "Epoch 95 - Loss: 0.22895662486553192 - Accuracy: 92.79%\n",
      "Epoch 96 - Loss: 0.22460989654064178 - Accuracy: 93.69%\n",
      "Epoch 97 - Loss: 0.22034704685211182 - Accuracy: 93.69%\n",
      "Epoch 98 - Loss: 0.21615873277187347 - Accuracy: 93.69%\n",
      "Epoch 99 - Loss: 0.21207019686698914 - Accuracy: 93.69%\n",
      "MLP model test accuracy: 82.86%\n",
      "Seed 7 - Test Accuracy: 82.86%\n",
      "Epoch 0 - Loss: 0.6978693604469299 - Accuracy: 50.45%\n",
      "Epoch 1 - Loss: 0.6966243386268616 - Accuracy: 50.45%\n",
      "Epoch 2 - Loss: 0.6954225897789001 - Accuracy: 50.45%\n",
      "Epoch 3 - Loss: 0.6942403316497803 - Accuracy: 50.45%\n",
      "Epoch 4 - Loss: 0.693067729473114 - Accuracy: 50.45%\n",
      "Epoch 5 - Loss: 0.6919316649436951 - Accuracy: 50.45%\n",
      "Epoch 6 - Loss: 0.6908172965049744 - Accuracy: 50.45%\n",
      "Epoch 7 - Loss: 0.6897169947624207 - Accuracy: 50.45%\n",
      "Epoch 8 - Loss: 0.6886401772499084 - Accuracy: 50.45%\n",
      "Epoch 9 - Loss: 0.687558650970459 - Accuracy: 50.45%\n",
      "Epoch 10 - Loss: 0.686445951461792 - Accuracy: 50.45%\n",
      "Epoch 11 - Loss: 0.6852889060974121 - Accuracy: 50.45%\n",
      "Epoch 12 - Loss: 0.684034526348114 - Accuracy: 51.35%\n",
      "Epoch 13 - Loss: 0.682689368724823 - Accuracy: 51.35%\n",
      "Epoch 14 - Loss: 0.6812642812728882 - Accuracy: 53.15%\n",
      "Epoch 15 - Loss: 0.6797616481781006 - Accuracy: 54.95%\n",
      "Epoch 16 - Loss: 0.6781485676765442 - Accuracy: 55.86%\n",
      "Epoch 17 - Loss: 0.6764389872550964 - Accuracy: 59.46%\n",
      "Epoch 18 - Loss: 0.6746237874031067 - Accuracy: 63.06%\n",
      "Epoch 19 - Loss: 0.6726344227790833 - Accuracy: 63.06%\n",
      "Epoch 20 - Loss: 0.6705292463302612 - Accuracy: 72.07%\n",
      "Epoch 21 - Loss: 0.6682618856430054 - Accuracy: 75.68%\n",
      "Epoch 22 - Loss: 0.6658068299293518 - Accuracy: 76.58%\n",
      "Epoch 23 - Loss: 0.6631808876991272 - Accuracy: 77.48%\n",
      "Epoch 24 - Loss: 0.6603965163230896 - Accuracy: 76.58%\n",
      "Epoch 25 - Loss: 0.6574124693870544 - Accuracy: 79.28%\n",
      "Epoch 26 - Loss: 0.6542436480522156 - Accuracy: 81.98%\n",
      "Epoch 27 - Loss: 0.6508219242095947 - Accuracy: 81.08%\n",
      "Epoch 28 - Loss: 0.6471893191337585 - Accuracy: 81.08%\n",
      "Epoch 29 - Loss: 0.6433335542678833 - Accuracy: 81.08%\n",
      "Epoch 30 - Loss: 0.6392349600791931 - Accuracy: 80.18%\n",
      "Epoch 31 - Loss: 0.6349092125892639 - Accuracy: 80.18%\n",
      "Epoch 32 - Loss: 0.6303473711013794 - Accuracy: 80.18%\n",
      "Epoch 33 - Loss: 0.6255333423614502 - Accuracy: 80.18%\n",
      "Epoch 34 - Loss: 0.6204802989959717 - Accuracy: 81.08%\n",
      "Epoch 35 - Loss: 0.6151637434959412 - Accuracy: 81.98%\n",
      "Epoch 36 - Loss: 0.6096040606498718 - Accuracy: 81.98%\n",
      "Epoch 37 - Loss: 0.6037839651107788 - Accuracy: 81.98%\n",
      "Epoch 38 - Loss: 0.5977146625518799 - Accuracy: 82.88%\n",
      "Epoch 39 - Loss: 0.5914030075073242 - Accuracy: 84.68%\n",
      "Epoch 40 - Loss: 0.5848425030708313 - Accuracy: 84.68%\n",
      "Epoch 41 - Loss: 0.5780243873596191 - Accuracy: 84.68%\n",
      "Epoch 42 - Loss: 0.5709641575813293 - Accuracy: 84.68%\n",
      "Epoch 43 - Loss: 0.5636990070343018 - Accuracy: 84.68%\n",
      "Epoch 44 - Loss: 0.5562077164649963 - Accuracy: 84.68%\n",
      "Epoch 45 - Loss: 0.5485385060310364 - Accuracy: 84.68%\n",
      "Epoch 46 - Loss: 0.5406967997550964 - Accuracy: 84.68%\n",
      "Epoch 47 - Loss: 0.5327178239822388 - Accuracy: 84.68%\n",
      "Epoch 48 - Loss: 0.5246212482452393 - Accuracy: 84.68%\n",
      "Epoch 49 - Loss: 0.5164191722869873 - Accuracy: 84.68%\n",
      "Epoch 50 - Loss: 0.5081591010093689 - Accuracy: 84.68%\n",
      "Epoch 51 - Loss: 0.49983394145965576 - Accuracy: 84.68%\n",
      "Epoch 52 - Loss: 0.49142348766326904 - Accuracy: 84.68%\n",
      "Epoch 53 - Loss: 0.4829546809196472 - Accuracy: 84.68%\n",
      "Epoch 54 - Loss: 0.4744681715965271 - Accuracy: 85.59%\n",
      "Epoch 55 - Loss: 0.46600431203842163 - Accuracy: 85.59%\n",
      "Epoch 56 - Loss: 0.45755451917648315 - Accuracy: 85.59%\n",
      "Epoch 57 - Loss: 0.4491167962551117 - Accuracy: 85.59%\n",
      "Epoch 58 - Loss: 0.4407443404197693 - Accuracy: 86.49%\n",
      "Epoch 59 - Loss: 0.43245598673820496 - Accuracy: 86.49%\n",
      "Epoch 60 - Loss: 0.4242178201675415 - Accuracy: 85.59%\n",
      "Epoch 61 - Loss: 0.4160650372505188 - Accuracy: 85.59%\n",
      "Epoch 62 - Loss: 0.40800535678863525 - Accuracy: 85.59%\n",
      "Epoch 63 - Loss: 0.4000442922115326 - Accuracy: 85.59%\n",
      "Epoch 64 - Loss: 0.3921845257282257 - Accuracy: 85.59%\n",
      "Epoch 65 - Loss: 0.38439878821372986 - Accuracy: 85.59%\n",
      "Epoch 66 - Loss: 0.37673208117485046 - Accuracy: 85.59%\n",
      "Epoch 67 - Loss: 0.3691932260990143 - Accuracy: 86.49%\n",
      "Epoch 68 - Loss: 0.3617735505104065 - Accuracy: 87.39%\n",
      "Epoch 69 - Loss: 0.35449010133743286 - Accuracy: 89.19%\n",
      "Epoch 70 - Loss: 0.34734046459198 - Accuracy: 89.19%\n",
      "Epoch 71 - Loss: 0.340335875749588 - Accuracy: 90.09%\n",
      "Epoch 72 - Loss: 0.3334522545337677 - Accuracy: 90.09%\n",
      "Epoch 73 - Loss: 0.3267005681991577 - Accuracy: 90.09%\n",
      "Epoch 74 - Loss: 0.32006821036338806 - Accuracy: 90.09%\n",
      "Epoch 75 - Loss: 0.31357255578041077 - Accuracy: 90.09%\n",
      "Epoch 76 - Loss: 0.30720746517181396 - Accuracy: 90.09%\n",
      "Epoch 77 - Loss: 0.3009685277938843 - Accuracy: 90.99%\n",
      "Epoch 78 - Loss: 0.29487454891204834 - Accuracy: 90.99%\n",
      "Epoch 79 - Loss: 0.2889368534088135 - Accuracy: 90.99%\n",
      "Epoch 80 - Loss: 0.2831181287765503 - Accuracy: 90.99%\n",
      "Epoch 81 - Loss: 0.27739566564559937 - Accuracy: 90.09%\n",
      "Epoch 82 - Loss: 0.27178752422332764 - Accuracy: 90.09%\n",
      "Epoch 83 - Loss: 0.2662976086139679 - Accuracy: 90.09%\n",
      "Epoch 84 - Loss: 0.26089394092559814 - Accuracy: 90.99%\n",
      "Epoch 85 - Loss: 0.25559002161026 - Accuracy: 90.99%\n",
      "Epoch 86 - Loss: 0.25041043758392334 - Accuracy: 90.99%\n",
      "Epoch 87 - Loss: 0.24532122910022736 - Accuracy: 90.99%\n",
      "Epoch 88 - Loss: 0.24033325910568237 - Accuracy: 91.89%\n",
      "Epoch 89 - Loss: 0.23548854887485504 - Accuracy: 91.89%\n",
      "Epoch 90 - Loss: 0.23074696958065033 - Accuracy: 92.79%\n",
      "Epoch 91 - Loss: 0.22608736157417297 - Accuracy: 92.79%\n",
      "Epoch 92 - Loss: 0.22151046991348267 - Accuracy: 93.69%\n",
      "Epoch 93 - Loss: 0.21701973676681519 - Accuracy: 93.69%\n",
      "Epoch 94 - Loss: 0.21264725923538208 - Accuracy: 93.69%\n",
      "Epoch 95 - Loss: 0.20838257670402527 - Accuracy: 93.69%\n",
      "Epoch 96 - Loss: 0.20420463383197784 - Accuracy: 93.69%\n",
      "Epoch 97 - Loss: 0.20012107491493225 - Accuracy: 93.69%\n",
      "Epoch 98 - Loss: 0.196135014295578 - Accuracy: 94.59%\n",
      "Epoch 99 - Loss: 0.1922244131565094 - Accuracy: 95.50%\n",
      "MLP model test accuracy: 80.00%\n",
      "Seed 21 - Test Accuracy: 80.00%\n",
      "Average Test Accuracy over seeds: 80.95%\n"
     ]
    }
   ],
   "source": [
    "mlp_results_multi_seed = {}\n",
    "for ppi in ppis:\n",
    "    mask_train = data[ppi].train_mask.squeeze()  \n",
    "    mask_test = data[ppi].test_mask.squeeze()\n",
    "\n",
    "    X_train = torch.tensor(data[ppi].x[mask_train].numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor([y.item() for yz in data[ppi].y[mask_train] for y in yz], dtype=torch.long)\n",
    "    X_test = torch.tensor(data[ppi].x[mask_test].numpy(), dtype=torch.float32)  \n",
    "    y_test = torch.tensor([y.item() for yz in data[ppi].y[mask_test] for y in yz], dtype=torch.long)\n",
    "\n",
    "    print(f\"Running MLP experiments on {ppi} data\")\n",
    "    models, accuracies = run_mlp_experiment(X_train, X_test, y_train, y_test)\n",
    "    mlp_results_multi_seed[ppi] = (models, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
